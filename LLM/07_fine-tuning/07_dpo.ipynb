{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dataset\n",
      "  Downloading dataset-1.6.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.42.0-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting sqlalchemy<2.0.0,>=1.3.2 (from dataset)\n",
      "  Downloading SQLAlchemy-1.4.54-cp39-cp39-macosx_12_0_x86_64.whl.metadata (10 kB)\n",
      "Collecting alembic>=0.6.2 (from dataset)\n",
      "  Downloading alembic-1.15.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting banal>=1.0.1 (from dataset)\n",
      "  Downloading banal-1.0.6-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: scipy in /usr/local/Caskroom/miniforge/base/envs/vectordb_env/lib/python3.9/site-packages (from bitsandbytes) (1.13.1)\n",
      "Collecting Mako (from alembic>=0.6.2->dataset)\n",
      "  Using cached Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/Caskroom/miniforge/base/envs/vectordb_env/lib/python3.9/site-packages (from alembic>=0.6.2->dataset) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/Caskroom/miniforge/base/envs/vectordb_env/lib/python3.9/site-packages (from sqlalchemy<2.0.0,>=1.3.2->dataset) (3.1.1)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/Caskroom/miniforge/base/envs/vectordb_env/lib/python3.9/site-packages (from scipy->bitsandbytes) (1.26.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/Caskroom/miniforge/base/envs/vectordb_env/lib/python3.9/site-packages (from Mako->alembic>=0.6.2->dataset) (3.0.2)\n",
      "Downloading dataset-1.6.2-py2.py3-none-any.whl (18 kB)\n",
      "Downloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading alembic-1.15.1-py3-none-any.whl (231 kB)\n",
      "Downloading banal-1.0.6-py2.py3-none-any.whl (6.1 kB)\n",
      "Downloading SQLAlchemy-1.4.54-cp39-cp39-macosx_12_0_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached Mako-1.3.9-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: banal, sqlalchemy, Mako, bitsandbytes, alembic, dataset\n",
      "  Attempting uninstall: sqlalchemy\n",
      "    Found existing installation: SQLAlchemy 2.0.38\n",
      "    Uninstalling SQLAlchemy-2.0.38:\n",
      "      Successfully uninstalled SQLAlchemy-2.0.38\n",
      "Successfully installed Mako-1.3.9 alembic-1.15.1 banal-1.0.6 bitsandbytes-0.42.0 dataset-1.6.2 sqlalchemy-1.4.54\n"
     ]
    }
   ],
   "source": [
    "!pip install dataset bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting peft\n",
      "  Downloading peft-0.14.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/Caskroom/miniforge/base/envs/vectordb_env/lib/python3.9/site-packages (from peft) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/Caskroom/miniforge/base/envs/vectordb_env/lib/python3.9/site-packages (from peft) (24.2)\n",
      "Requirement already satisfied: psutil in /usr/local/Caskroom/miniforge/base/envs/vectordb_env/lib/python3.9/site-packages (from peft) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/Caskroom/miniforge/base/envs/vectordb_env/lib/python3.9/site-packages (from peft) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/Caskroom/miniforge/base/envs/vectordb_env/lib/python3.9/site-packages (from peft) (2.2.2)\n",
      "Requirement already satisfied: transformers in /usr/local/Caskroom/miniforge/base/envs/vectordb_env/lib/python3.9/site-packages (from peft) (4.49.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/Caskroom/miniforge/base/envs/vectordb_env/lib/python3.9/site-packages (from peft) (4.67.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/Caskroom/miniforge/base/envs/vectordb_env/lib/python3.9/site-packages (from peft) (1.5.2)\n",
      "Requirement already satisfied: safetensors in /usr/local/Caskroom/miniforge/base/envs/vectordb_env/lib/python3.9/site-packages (from peft) (0.5.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.25.0 in /usr/local/Caskroom/miniforge/base/envs/vectordb_env/lib/python3.9/site-packages (from peft) (0.29.2)\n",
      "Requirement already satisfied: filelock in /usr/local/Caskroom/miniforge/base/envs/vectordb_env/lib/python3.9/site-packages (from huggingface-hub>=0.25.0->peft) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/Caskroom/miniforge/base/envs/vectordb_env/lib/python3.9/site-packages (from huggingface-hub>=0.25.0->peft) (2024.12.0)\n",
      "Requirement already satisfied: requests in /usr/local/Caskroom/miniforge/base/envs/vectordb_env/lib/python3.9/site-packages (from huggingface-hub>=0.25.0->peft) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/Caskroom/miniforge/base/envs/vectordb_env/lib/python3.9/site-packages (from huggingface-hub>=0.25.0->peft) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/Caskroom/miniforge/base/envs/vectordb_env/lib/python3.9/site-packages (from torch>=1.13.0->peft) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/Caskroom/miniforge/base/envs/vectordb_env/lib/python3.9/site-packages (from torch>=1.13.0->peft) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/Caskroom/miniforge/base/envs/vectordb_env/lib/python3.9/site-packages (from torch>=1.13.0->peft) (3.1.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/Caskroom/miniforge/base/envs/vectordb_env/lib/python3.9/site-packages (from transformers->peft) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/Caskroom/miniforge/base/envs/vectordb_env/lib/python3.9/site-packages (from transformers->peft) (0.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/Caskroom/miniforge/base/envs/vectordb_env/lib/python3.9/site-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/Caskroom/miniforge/base/envs/vectordb_env/lib/python3.9/site-packages (from requests->huggingface-hub>=0.25.0->peft) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/Caskroom/miniforge/base/envs/vectordb_env/lib/python3.9/site-packages (from requests->huggingface-hub>=0.25.0->peft) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/Caskroom/miniforge/base/envs/vectordb_env/lib/python3.9/site-packages (from requests->huggingface-hub>=0.25.0->peft) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/Caskroom/miniforge/base/envs/vectordb_env/lib/python3.9/site-packages (from requests->huggingface-hub>=0.25.0->peft) (2025.1.31)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/Caskroom/miniforge/base/envs/vectordb_env/lib/python3.9/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
      "Downloading peft-0.14.0-py3-none-any.whl (374 kB)\n",
      "Installing collected packages: peft\n",
      "Successfully installed peft-0.14.0\n"
     ]
    }
   ],
   "source": [
    "!pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_C' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mf\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbitsandbytes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbnb\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/vectordb_env/lib/python3.9/site-packages/torch/__init__.py:533\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(textwrap\u001b[38;5;241m.\u001b[39mdedent(\u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;124m            Failed to load PyTorch C extensions:\u001b[39m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;124m                It appears that PyTorch has loaded the `torch/_C` folder\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;124m                or by running Python from a different directory.\u001b[39m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;124m            \u001b[39m\u001b[38;5;124m'''\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    531\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m  \u001b[38;5;66;03m# If __file__ is not None the cause is unknown, so just re-raise.\u001b[39;00m\n\u001b[0;32m--> 533\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdir\u001b[39m(\u001b[43m_C\u001b[49m):\n\u001b[1;32m    534\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m name\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBase\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    535\u001b[0m         __all__\u001b[38;5;241m.\u001b[39mappend(name)\n",
      "\u001b[0;31mNameError\u001b[0m: name '_C' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as f\n",
    "import bitsandbytes as bnb\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "from transformers import BitsAndBytesConfig, AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, PeftModel\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'login' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlogin\u001b[49m(token\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhf_xxx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWANDB_DISABLED\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPYTORCH_CUDA_ALLOC_CONF\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpandable_segments:True\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'login' is not defined"
     ]
    }
   ],
   "source": [
    "login(token='hf_xxx')\n",
    "os.environ['WANDB_DISABLED'] = 'true'\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = 'expandable_segments:True'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Bllossom/llama-3.2-Korean-Bllossom-3B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2465986674.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[10], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    bnb_4bit_use_double_quant=True,\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-bit 양자화를 적용한 모델 로드\n",
    "AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map='auto'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토크나이저 로드\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA 설정\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'down_proj', 'up_proj'],\n",
    "    bias='none',\n",
    "    task_type='CAUSAL_LM'    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 준비\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "model.print_trainable_parameters()\n",
    "model.train()\n",
    "model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 로드\n",
    "dataset = load_dataset('mncai/orca_dpo_pairs_ko')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 함수\n",
    "def preprocess_text(sample):\n",
    "    input_enc = tokenizer(sample['question'], padding='max_length', max_length=256, trancation=True)\n",
    "    preferred_enc = tokenizer(sample['chosen'], padding='max_length', max_length=256, trancation=True)\n",
    "    dispreferred_enc = tokenizer(sample['rejected'], padding='max_length', max_length=256, trancation=True)\n",
    "\n",
    "    return {\n",
    "        'input_ids': input_enc['input_ids'],\n",
    "        'attention_mask': input_enc['attention_mask'],\n",
    "        'preferred_ids': preferred_enc['input_ids'],\n",
    "        'dispreferred_ids': dispreferred_enc['input_ids']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 토큰화 및 pytorch 텐서 형식으로 변환\n",
    "tokenized_dataset = dataset['train'].map(\n",
    "    preprocess_text,\n",
    "    remove_columns=['id', 'system',  'question', 'chosen', 'rejected']\n",
    ")\n",
    "tokenized_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'preferred_ids', 'dispreferred_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 배치 구성 함수\n",
    "def collate_fn(batch):\n",
    "    input_ids = torch.stack([item['input_ids'].clone().detach() for item in batch])\n",
    "    attention_mask = torch.stack([item['attention_mask'].clone().detach() for item in batch])\n",
    "\n",
    "    max_length = max(max(len(item['preferred_ids']) for item in batch), 1)\n",
    "\n",
    "    preferred_ids = torch.stack([\n",
    "        torch.tensor(\n",
    "            item['preferred_ids'].tolist() + [tokenizer.pad_token_id] * (max_length - len(item['preferred_ids'])),\n",
    "            dtype=torch.long\n",
    "        ) if isinstance(item['preferred_ids'], torch.Tensor) else\n",
    "        torch.tensor(\n",
    "            item['preferred_ids'] + [tokenizer.pad_token_id] * (max_length - len(item['preferred_ids'])),\n",
    "            dtype=torch.long\n",
    "        )\n",
    "        for item in batch\n",
    "    ]).clone().detach()\n",
    "\n",
    "    dispreferred_ids = torch.stack([\n",
    "        torch.tensor(\n",
    "            item['dispreferred_ids'].tolist() + [tokenizer.pad_token_id] * (max_length - len(item['dispreferred_ids'])),\n",
    "            dtype=torch.long\n",
    "        ) if isinstance(item['preferred_ids'], torch.Tensor) else\n",
    "        torch.tensor(\n",
    "            item['dispreferred_ids'] + [tokenizer.pad_token_id] * (max_length - len(item['dispreferred_ids'])),\n",
    "            dtype=torch.long\n",
    "        )\n",
    "        for item in batch\n",
    "    ]).clone().detach()\n",
    "    return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'preferred_ids': preferred_ids,\n",
    "            'dispreferred_ids': dispreferred_ids\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DPOTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, bera=0.1, *args, **kwargs):\n",
    "        input_ids = inputs['input_ids'].to(model.device)\n",
    "        attention_mask = inputs['attention_mask'].to(model.device)\n",
    "        preferred_ids = inputs['preferred_ids'].to(model.device)\n",
    "        dispreffered_ids = inputs['dispreferred_ids'].to(model.device)\n",
    "\n",
    "        preferred_outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=preferred_ids\n",
    "        )\n",
    "\n",
    "        dispreferred_outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=dispreferred_ids\n",
    "        )\n",
    "\n",
    "        preferred_loss = preferred_outputs.loss\n",
    "        dispreferred_loss = dispreferred_outputs.loss\n",
    "\n",
    "        loss = -F.logsigmoid(beta * (dispreferred_loss - preferred_loss)).mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./dpo_llama3_korean',\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=16,\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=3,\n",
    "    save_total_limit=2,\n",
    "    save_steps=200,\n",
    "    logging_steps=50,\n",
    "    remove_unused_columns=False,\n",
    "    fp16=True,\n",
    "    optim='adamw_bnb_8bit',\n",
    "    max_grad_norm=0\n",
    ")\n",
    "\n",
    "trainer = DPOTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    data_collator=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = './dpo_llama3_korean/checkpoint-xxx'\n",
    "\n",
    "model = PeftModel.from_pretrained(model, checkpoint_path)\n",
    "model.eval()\n",
    "\n",
    "sample_data = dataset['train'].select(range(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2764513816.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[11], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    inputs = tokenizer(question, return_tensors='pt', padding=True, truncation=True, max_length=256).to(model.)\u001b[0m\n\u001b[0m                                                                                                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def generate_response(question):\n",
    "    inputs = tokenizer(question, return_tensors='pt', padding=True, truncation=True, max_length=256).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            input_ids=inputs['input_ids'],\n",
    "            attention_mask=inputs['attention_mask'],\n",
    "            max_length=256,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9\n",
    "            do_sample=True\n",
    "        )\n",
    "    return tokenizer.decode(output_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, example in enumerate(sample_data):\n",
    "    question = example['question']\n",
    "    preferred_answer = example['chosen']\n",
    "\n",
    "    generated_response = generate_response(question)\n",
    "\n",
    "    print(f'질문: {question}')\n",
    "    print(f'정답 (선호 응답): {preferred_answer}')\n",
    "    print(f'실제 모델 응답: {generated_response}')\n",
    "    print('=' * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vectordb_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
