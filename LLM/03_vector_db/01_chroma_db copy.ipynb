{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chroma DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'distractor3', 'distractor1', 'distractor2', 'correct_answer', 'support'],\n",
       "    num_rows: 10481\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋 로드 \n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('sciq', split='train')    # sciq : 과학 관련 질문 \n",
    "dataset = dataset.filter(lambda x: x['support'] != \"\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': [['61', '80']], 'embeddings': None, 'documents': [[None, None]], 'uris': None, 'data': None, 'metadatas': [[{'text': 'Mariana Ruiz Villarreal (LadyofHats) for CK-12 Foundation. The nitrogen cycle tracks the flow of nitrogen through an ecosystem . CC BY-NC 3.0.', 'type': 'support'}, {'text': 'All of the changes of state that occur between solid, liquid and gas are summarized in the diagram in the figure below. Freezing is the opposite of melting and both represent the equilibrium between the solid and liquid states. Evaporation occurs when a liquid turns to a gas. Condensation is the opposite of vaporization and both represent the equilibrium between the liquid and gas states. Deposition is the opposite of sublimation and both represent the equilibrium between the solid and gas states.', 'type': 'support'}]], 'distances': [[1.6950156688690186, 1.695570707321167]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n"
     ]
    }
   ],
   "source": [
    "# 필요한 모듈 임포트\n",
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "# 1. 임베딩 모델 초기화 (올바른 인터페이스 사용)\n",
    "class CustomEmbeddingFunction:\n",
    "    def __init__(self, model_name):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "    \n",
    "    def __call__(self, input):  # 'texts' 대신 'input' 사용\n",
    "        # NumPy 변환을 건너뛰고 텐서에서 직접 리스트로 변환\n",
    "        embeddings = self.model.encode(input, convert_to_numpy=False)\n",
    "        return [tensor.cpu().detach().tolist() for tensor in embeddings]\n",
    "\n",
    "# 2. 임베딩 함수 생성\n",
    "embedding_function = CustomEmbeddingFunction('all-MiniLM-L6-v2')\n",
    "\n",
    "# 3. ChromaDB 클라이언트 초기화\n",
    "client = chromadb.Client()\n",
    "\n",
    "# 4. 기존 컬렉션이 있다면 삭제\n",
    "try:\n",
    "    client.delete_collection(\"my_collection\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# 5. 새 컬렉션 생성 (임베딩 함수 지정)\n",
    "collection = client.create_collection(\n",
    "    name=\"my_collection\",\n",
    "    embedding_function=embedding_function\n",
    ")\n",
    "\n",
    "# 6. 데이터 준비\n",
    "supports = dataset['support'][:100]\n",
    "\n",
    "# 7. 임베딩 계산 (같은 커스텀 임베딩 함수 사용)\n",
    "support_embeddings = embedding_function(supports)\n",
    "\n",
    "# 8. 데이터 추가\n",
    "collection.add(\n",
    "    ids=[str(i) for i in range(100)],\n",
    "    embeddings=support_embeddings,\n",
    "    metadatas=[{'type': 'support', 'text': text} for text in supports]\n",
    ")\n",
    "\n",
    "# 9. 쿼리 실행\n",
    "query_text = ['This is a query document about vietnam']\n",
    "query_embedding = embedding_function(query_text)\n",
    "\n",
    "# 10. 임베딩을 직접 사용하여 쿼리\n",
    "results = collection.query(\n",
    "    query_embeddings=query_embedding,\n",
    "    n_results=2\n",
    ")\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SciQ dataset 활용 ChromaDB 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('sciq', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chroma db 클라이언트 객체 및 콜렉션 생성\n",
    "import chromadb\n",
    "\n",
    "client = chromadb.Client()\n",
    "collection = client.create_collection(name=\"sciq_support\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 모델 로드\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "supports = dataset['support'][:100]\n",
    "\n",
    "# NumPy 변환 과정을 건너뛰고 직접 텐서에서 리스트로 변환합니다\n",
    "embeddings = embedding_model.encode(supports, convert_to_numpy=False)\n",
    "support_embeddings = [tensor.cpu().detach().tolist() for tensor in embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(support_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    ids=[str(i) for i in range(0, 100)],\n",
    "    embeddings=support_embeddings,\n",
    "    metadatas=[{'type': 'support', 'text': text} for text in supports]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앞서 정의한 CustomEmbeddingFunction 사용\n",
    "questions = dataset['question'][:3]\n",
    "question_embeddings = embedding_function(questions)\n",
    "\n",
    "results = collection.query(\n",
    "    query_embeddings=question_embeddings,\n",
    "    n_results=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['38'], ['1'], ['2']],\n",
       " 'embeddings': None,\n",
       " 'documents': [[None], [None], [None]],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': [[{'text': 'Agents of Decomposition The fungus-like protist saprobes are specialized to absorb nutrients from nonliving organic matter, such as dead organisms or their wastes. For instance, many types of oomycetes grow on dead animals or algae. Saprobic protists have the essential function of returning inorganic nutrients to the soil and water. This process allows for new plant growth, which in turn generates sustenance for other organisms along the food chain. Indeed, without saprobe species, such as protists, fungi, and bacteria, life would cease to exist as all organic carbon became “tied up” in dead organisms.',\n",
       "    'type': 'support'}],\n",
       "  [{'text': 'Without Coriolis Effect the global winds would blow north to south or south to north. But Coriolis makes them blow northeast to southwest or the reverse in the Northern Hemisphere. The winds blow northwest to southeast or the reverse in the southern hemisphere.',\n",
       "    'type': 'support'}],\n",
       "  [{'text': 'Summary Changes of state are examples of phase changes, or phase transitions. All phase changes are accompanied by changes in the energy of a system. Changes from a more-ordered state to a less-ordered state (such as a liquid to a gas) areendothermic. Changes from a less-ordered state to a more-ordered state (such as a liquid to a solid) are always exothermic. The conversion of a solid to a liquid is called fusion (or melting). The energy required to melt 1 mol of a substance is its enthalpy of fusion (ΔHfus). The energy change required to vaporize 1 mol of a substance is the enthalpy of vaporization (ΔHvap). The direct conversion of a solid to a gas is sublimation. The amount of energy needed to sublime 1 mol of a substance is its enthalpy of sublimation (ΔHsub) and is the sum of the enthalpies of fusion and vaporization. Plots of the temperature of a substance versus heat added or versus heating time at a constant rate of heating are calledheating curves. Heating curves relate temperature changes to phase transitions. A superheated liquid, a liquid at a temperature and pressure at which it should be a gas, is not stable. A cooling curve is not exactly the reverse of the heating curve because many liquids do not freeze at the expected temperature. Instead, they form a supercooled liquid, a metastable liquid phase that exists below the normal melting point. Supercooled liquids usually crystallize on standing, or adding a seed crystal of the same or another substance can induce crystallization.',\n",
       "    'type': 'support'}]],\n",
       " 'distances': [[1.1048439741134644],\n",
       "  [0.4666745662689209],\n",
       "  [0.9318017363548279]],\n",
       " 'included': [<IncludeEnum.distances: 'distances'>,\n",
       "  <IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What type of organism is commonly used in preparation of foods such as cheese and yogurt?\n",
      "Support: Agents of Decomposition The fungus-like protist saprobes are specialized to absorb nutrients from nonliving organic matter, such as dead organisms or their wastes. For instance, many types of oomycetes grow on dead animals or algae. Saprobic protists have the essential function of returning inorganic nutrients to the soil and water. This process allows for new plant growth, which in turn generates sustenance for other organisms along the food chain. Indeed, without saprobe species, such as protists, fungi, and bacteria, life would cease to exist as all organic carbon became “tied up” in dead organisms.\n",
      "Question: What phenomenon makes global winds blow northeast to southwest or the reverse in the northern hemisphere and northwest to southeast or the reverse in the southern hemisphere?\n",
      "Support: Without Coriolis Effect the global winds would blow north to south or south to north. But Coriolis makes them blow northeast to southwest or the reverse in the Northern Hemisphere. The winds blow northwest to southeast or the reverse in the southern hemisphere.\n",
      "Question: Changes from a less-ordered state to a more-ordered state (such as a liquid to a solid) are always what?\n",
      "Support: Summary Changes of state are examples of phase changes, or phase transitions. All phase changes are accompanied by changes in the energy of a system. Changes from a more-ordered state to a less-ordered state (such as a liquid to a gas) areendothermic. Changes from a less-ordered state to a more-ordered state (such as a liquid to a solid) are always exothermic. The conversion of a solid to a liquid is called fusion (or melting). The energy required to melt 1 mol of a substance is its enthalpy of fusion (ΔHfus). The energy change required to vaporize 1 mol of a substance is the enthalpy of vaporization (ΔHvap). The direct conversion of a solid to a gas is sublimation. The amount of energy needed to sublime 1 mol of a substance is its enthalpy of sublimation (ΔHsub) and is the sum of the enthalpies of fusion and vaporization. Plots of the temperature of a substance versus heat added or versus heating time at a constant rate of heating are calledheating curves. Heating curves relate temperature changes to phase transitions. A superheated liquid, a liquid at a temperature and pressure at which it should be a gas, is not stable. A cooling curve is not exactly the reverse of the heating curve because many liquids do not freeze at the expected temperature. Instead, they form a supercooled liquid, a metastable liquid phase that exists below the normal melting point. Supercooled liquids usually crystallize on standing, or adding a seed crystal of the same or another substance can induce crystallization.\n"
     ]
    }
   ],
   "source": [
    "for i, q in enumerate(questions):\n",
    "    print('Question:', q)\n",
    "    print('Support:', results['metadatas'][i][0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chroma DB를 활용한 키워드 기반 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    '인공지능은 인간의 작업을 자동화하는 기술이다.',\n",
    "    '기계 학습은 데이터에서 패턴을 학습하여 예측하는 기술이다.',\n",
    "    '벡터 데이터베이스는 유사도를 기반으로 데이터를 겁색하는 DB이다.'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# ChromaDB 클라이언트, 컬렉션 생성\n",
    "client = chromadb.PersistentClient(path='./chroma_db')      # 해당 데이터에 경로를 지정\n",
    "collection = client.get_or_create_collection(name='ai_documents')\n",
    "\n",
    "# 텍스트 임베딩 모델 생성\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: 0\n",
      "Add of existing embedding ID: 1\n",
      "Add of existing embedding ID: 2\n",
      "Add of existing embedding ID: 0\n",
      "Add of existing embedding ID: 1\n",
      "Add of existing embedding ID: 2\n",
      "Insert of existing embedding ID: 0\n",
      "Add of existing embedding ID: 0\n",
      "Insert of existing embedding ID: 1\n",
      "Add of existing embedding ID: 1\n",
      "Insert of existing embedding ID: 2\n",
      "Add of existing embedding ID: 2\n"
     ]
    }
   ],
   "source": [
    "# NumPy 변환을 건너뛰는 함수\n",
    "def encode_to_list(text):\n",
    "    # convert_to_numpy=False로 설정하여 텐서 반환\n",
    "    embedding_tensor = model.encode(text, convert_to_numpy=False)\n",
    "    # 텐서를 리스트로 직접 변환\n",
    "    if isinstance(embedding_tensor, list):\n",
    "        return [t.cpu().detach().tolist() for t in embedding_tensor]\n",
    "    else:\n",
    "        return embedding_tensor.cpu().detach().tolist()\n",
    "\n",
    "# 문서 추가\n",
    "for i, doc in enumerate(documents):\n",
    "    embedding = encode_to_list(doc)\n",
    "    collection.add(ids=[str(i)], embeddings=[embedding], metadatas=[{'text': doc}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색된 문서: As humanity picks up the pieces, following the conclusion of \"Transformers: Dark of the Moon,\" Autobots and Decepticons have all but vanished from the face of the planet. However, a group of powerful, ingenious businessman and scientists attempt to learn from past Transformer incursions and push the boundaries of technology beyond what they can control - all while an ancient, powerful Transformer menace sets Earth in his cross-hairs.\n",
      "검색된 문서: WALL·E is the last robot left on an Earth that has been overrun with garbage and all humans have fled to outer space. For 700 years he has continued to try and clean up the mess, but has developed some rather interesting human-like qualities. When a ship arrives with a sleek new type of robot, WALL·E thinks he's finally found a friend and stows away on the ship when it leaves.\n"
     ]
    }
   ],
   "source": [
    "query_keyword = 'AI'\n",
    "query_embedding = encode_to_list(query_keyword)\n",
    "results = collection.query(query_embeddings=query_embedding, n_results=2)\n",
    "\n",
    "for result in results['metadatas'][0]:\n",
    "    print('검색된 문서:', result['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 영화 추천 시스템"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- title = 이걸로 찾기, overview = 유사도 파악(임베딩)\n",
    "- vector db에서 검색 시 추천영화 나오도록 하게 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['budget', 'genres', 'homepage', 'id', 'keywords', 'original_language',\n",
       "       'original_title', 'overview', 'popularity', 'production_companies',\n",
       "       'production_countries', 'release_date', 'revenue', 'runtime',\n",
       "       'spoken_languages', 'status', 'tagline', 'title', 'vote_average',\n",
       "       'vote_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋 로드\n",
    "import pandas as pd\n",
    "df = pd.read_csv('./data/tmdb_5000_movies.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chroma db 클라이언트 객체 및 콜렉션 생성\n",
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "client = chromadb.PersistentClient()\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 모델 로드\n",
    "movies = [\n",
    "    {\n",
    "        'id': str(index),\n",
    "        'title': row['title'],\n",
    "        'overview': row['overview'] if pd.notna(row['overview']) else \"\"  \n",
    "    } for index, row in df.iterrows()    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for movie in movies:\n",
    "    if movie['overview']:\n",
    "        overview_embedding = model.encode(movie['overview'], convert_to_numpy=False).tolist()\n",
    "        collection.add(\n",
    "            ids=[movie['id']],\n",
    "            embeddings=[overview_embedding],\n",
    "            metadatas=[{'title': movie['title'], 'text': movie['overview']}]    \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 제목 입력 -> 줄거리를 찾아 -> 줄거리로 유사도 검색\n",
    "input_title = 'Inception'\n",
    "query_text = df.loc[df['title'] == input_title, 'overview'].iloc[0]\n",
    "\n",
    "query_embedding = model.encode(query_text, convert_to_numpy=False).tolist()\n",
    "\n",
    "results = collection.query(query_embeddings = [query_embedding], n_results=5)\n",
    "\n",
    "for result in results['metadatas'][0]:\n",
    "    print(result['title'])\n",
    "    print(result['text'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Insert of existing embedding ID: 0\n",
      "Insert of existing embedding ID: 1\n",
      "Insert of existing embedding ID: 2\n",
      "Add of existing embedding ID: 0\n",
      "Add of existing embedding ID: 1\n",
      "Add of existing embedding ID: 2\n"
     ]
    }
   ],
   "source": [
    "# 2. 원하는 줄거리 입력 -> 유사도 검색\n",
    "query_text = 'Korea'\n",
    "\n",
    "query_embedding = model.encode(query_text, convert_to_numpy=False).tolist()\n",
    "\n",
    "results = collection.query(query_embeddings = [query_embedding], n_results=5)\n",
    "\n",
    "for result in results['metadatas'][0]:\n",
    "    print(result['title'])\n",
    "    print(result['text'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 논문 PDF 내용 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "client = chromadb.PersistentClient(path='./chroma_db')\n",
    "# client.delete_collection('papers')    # 컬렉션 삭제\n",
    "collection = client.get_or_create_collection(name='pdf_documents')\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = [\n",
    "    {'id': '1', 'title': '딥러닝', 'path': './data/deep_learning.pdf'},\n",
    "    {'id': '2', 'title': '자연어처리', 'path': './data/nlp_paper.pdf'},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "\n",
    "def extract_text_from_pdf(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        reader = PyPDF2.PdfReader(f)\n",
    "        text = ' '.join([page.extract_text() for page in reader.pages if page.extract_text()])\n",
    "\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for paper in papers:\n",
    "    text = extract_text_from_pdf(paper['path'])\n",
    "    embedding = model.encode(text).tolist()\n",
    "    collection.add(\n",
    "        ids=[paper['id']],    \n",
    "        embeddings=[embedding],\n",
    "        metadatas=[{'title': paper['title']}],\n",
    "        documents=[text]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['1', '2'],\n",
       " 'embeddings': None,\n",
       " 'documents': ['Deep Learning:\\nMethods and Applications\\nLi Deng\\nMicrosoft Research\\nOne Microsoft Way\\nRedmond, WA 98052; USA\\ndeng@microsoft.com\\nDong Yu\\nMicrosoft Research\\nOne Microsoft Way\\nRedmond, WA 98052; USA\\nDong.Yu@microsoft.com\\nBoston — Delft\\nFull text available at: http://dx.doi.org/10.1561/2000000039 Foundations and TrendsR/circlecopyrtin Signal Processing\\nPublished, sold and distributed by:\\nnow Publishers Inc.\\nPO Box 1024Hanover, MA 02339\\nUnited States\\nTel. +1-781-985-4510www.nowpublishers.com\\nsales@nowpublishers.com\\nOutside North America:\\nnow Publishers Inc.PO Box 179\\n2600 AD Delft\\nThe NetherlandsTel. +31-6-51115274\\nThe preferred citation for this publication is\\nL. Deng and D. Yu. Deep Learning: Methods and Applications . Foundations and\\nTrends\\nR/circlecopyrtin Signal Processing, vol. 7, nos. 3–4, pp. 197–387, 2013.\\nThis Foundations and TrendsR/circlecopyrtissue was typeset in LATEX using a class ﬁle designed\\nby Neal Parikh. Printed on acid-free paper.ISBN: 978-1-60198-81 5-7\\nc/circlecopyrt2014 L. Deng and D. Yu\\nAll rights reserved. No part of this publication may be reproduced, stored in a retrieval\\nsystem, or transmitted in any form or by any means, mechanical, photocopying, recordingor otherwise, without prior written permission of the publishers.\\nPhotocopying. In the USA: This journal is registered at the Copyright Clearance Cen-\\nter, Inc., 222 Rosewood Drive, Danvers, MA 01923. Authorization to photocopy items forinternal or personal use, or the internal or personal use of speciﬁc clients, is granted bynow Publishers Inc for users registered with the Copyright Clearance Center (CCC). The\\n‘services’ for users can be found on the internet at: www.copyright.com\\nFor those organizations that have been granted a photocopy license, a separate system\\nof payment has been arranged. Authorization does not extend to other kinds of copy-\\ning, such as that for general distribution, for advertising or promotional purposes, for\\ncreating new collective works, or for resale. In the rest of the world: Permission to pho-tocopy must be obtained from the copyright owner. Please apply to now Publishers Inc.,\\nPO Box 1024, Hanover, MA 02339, USA; Tel. +1 781 871 0245; www.nowpublishers.com;\\nsales@nowpublishers.com\\nnow Publishers Inc. has an exclusive license to publish this material worldwide. Permission\\nto use this content must be obtained from the copyright license holder. Please apply to\\nnow Publishers, PO Box 179, 2600 AD Delft, The Netherlands, www.nowpublishers.com;e-mail: sales@nowpublishers.com\\nFull text available at: http://dx.doi.org/10.1561/2000000039 Foundations and TrendsR/circlecopyrtin Signal Processing\\nVolume 7, Issues 3–4, 2013\\nEditorial Board\\nEditor-in-Chief\\nYonina Eldar\\nTechnion - Israel Institute of Technology\\nIsrael\\nEditors\\nRobert M. GrayFounding Editor-in-Chief\\nStanford University\\nPao-Chi Chang\\nNCU, Taiwan\\nPamela Cosman\\nUC San Diego\\nMichelle Eﬀros\\nCaltech\\nYariv Ephraim\\nGMU\\nAlfonso Farina\\nSelex ES\\nSadaoki Furui\\nTokyo Tech\\nGeorgios Giannakis\\nUniversity of Minnesota\\nVivek Goyal\\nBoston University\\nSinan Gunturk\\nCourant Institute\\nChristine Guillemot\\nINRIA\\nRobert W. Heath, Jr.\\nUT AustinSheila HemamiCornell University\\nLina Karam\\nArizona State U\\nNick Kingsbury\\nUniversity of Cambridge\\nAlex Kot\\nNTU, Singapore\\nJelena Kovacevic\\nCMU\\nGeert Leus\\nTU Delft\\nJia Li\\nPenn State\\nHenrique Malvar\\nMicrosoft Research\\nB.S. Manjunath\\nUC Santa Barbara\\nUrbashi Mitra\\nUSC\\nBjörn Ottersten\\nKTH Stockholm\\nThrasos Pappas\\nNorthwestern UniversityVincent Poor\\nPrinceton University\\nAnna Scaglione\\nUC Davis\\nMihaela van der Shaar\\nUCLA\\nNicholas D. Sidiropoulos\\nTU Crete\\nMichael Unser\\nEPFL\\nP. P. Vaidyanathan\\nCaltech\\nAmi Wiesel\\nHebrew U\\nMin Wu\\nUniversity of Maryland\\nJosiane Zerubia\\nINRIA\\nFull text available at: http://dx.doi.org/10.1561/2000000039 Editorial Scope\\nTopics\\nFoundations and TrendsR/circlecopyrtin Signal Processing publishes survey and\\ntutorial articles in the following topics:\\n•Adaptive signal processing\\n•Audio signal processing\\n•Biological and biomedical signal\\nprocessing\\n•Complexity in signal processing\\n•D i g i t a ls i g n a lp r o c e s s i n g\\n•Distributed and network signalprocessing\\n•Image and video processing\\n•Linear and nonlinear ﬁltering\\n•Multidimensional signalprocessing\\n•Multimodal signal processing\\n•Multirate signal processing\\n•Multiresolution signal processing\\n•Nonlinear signal processing\\n•Randomized algorithms in signalprocessing\\n•Sensor and multiple source signal\\nprocessing, source separation•Signal decompositions, subband\\nand transform methods, sparse\\nrepresentations\\n•Signal processing for\\ncommunications\\n•Signal processing for security andforensic analysis, biometric signal\\nprocessing\\n•Signal quantization, sampling,\\nanalog-to-digital conversion,coding and compression\\n•Signal reconstruction,\\ndigital-to-analog conversion,\\nenhancement, decoding andinverse problems\\n•Speech/audio/image/videocompression\\n•Speech and spoken language\\nprocessing\\n•Statistical/machine learning\\n•Statistical signal processing\\nInformation for Librarians\\nFoundations and TrendsR/circlecopyrtin Signal Processing, 2013, Volume 7, 4 issues. ISSN\\npaper version 1932-8346. ISSN online version 1932-8354. Also available as a\\ncombined paper and online subscription.\\nFull text available at: http://dx.doi.org/10.1561/2000000039 Foundations and TrendsR/circlecopyrtin Signal Processing\\nVol. 7, Nos. 3–4 (2013) 197–387\\nc/circlecopyrt2014 L. Deng and D. Yu\\nDOI: 10.1561/2000000039\\nDeep Learning: Methods and Applications\\nLi Deng\\nMicrosoft Research\\nOne Microsoft Way\\nRedmond, WA 98052; USA\\ndeng@microsoft.comDong Yu\\nMicrosoft Research\\nOne Microsoft Way\\nRedmond, WA 98052; USA\\nDong.Yu@microsoft.com\\nFull text available at: http://dx.doi.org/10.1561/2000000039 Contents\\nEndorsement 1\\n1 Introduction 3\\n1 . 1 D e ﬁ n i t i o n s a n d b a c k g r o u n d................. 3\\n1 . 2 O r g a n i z a t i o n o f t h i s m o n o g r a p h .............. 7\\n2 Some Historical Context of Deep Learning 10\\n3 Three Classes of Deep Learning Networks 19\\n3 . 1 A t h r e e - w a y c a t e g o r i z a t i o n ................. 19\\n3.2 Deep networks for unsupervised or generative learning . . . 21\\n3 . 3 D e e p n e t w o r k s f o r s u p e r v i s e d l e a r n i n g ........... 28\\n3 . 4 H y b r i d d e e p n e t w o r k s .................... 31\\n4 Deep Autoencoders — Unsupervised Learning 35\\n4 . 1 I n t r o d u c t i o n ......................... 35\\n4.2 Use of deep autoencoders to extract speech features . . . 36\\n4 . 3 S t a c k e d d e n o i s i n g a u t o e n c o d e r s ............... 40\\n4 . 4 T r a n s f o r m i n g a u t o e n c o d e r s ................. 44\\n5 Pre-Trained Deep Neural Networks — A Hybrid 46\\n5 . 1 R e s t r i c t e d B o l t z m a n n m a c h i n e s ............... 46\\nii\\nFull text available at: http://dx.doi.org/10.1561/2000000039 iii\\n5 . 2 U n s u p e r v i s e d l a y e r - w i s e p r e - t r a i n i n g ............ 50\\n5 . 3 I n t e r f a c i n g D N N s w i t h H M M s ............... 53\\n6 Deep Stacking Networks and Variants —\\nSupervised Learning 55\\n6 . 1 I n t r o d u c t i o n ......................... 55\\n6.2 A basic architecture of the deep stacking network . . . . . 57\\n6 . 3 A m e t h o d f o r l e a r n i n g t h e D S N w e i g h t s .......... 59\\n6 . 4 T h e t e n s o r d e e p s t a c k i n g n e t w o r k .............. 60\\n6 . 5 T h e K e r n e l i z e d d e e p s t a c k i n g n e t w o r k ........... 62\\n7 Selected Applications in Sp eech and Audio Processing 67\\n7.1 Acoustic modeling for speech recognition . ......... 67\\n7.2 Speech synthesis . . . . ................... 91\\n7 . 3 A u d i o a n d m u s i c p r o c e s s i n g................. 93\\n8 Selected Applications in Language\\nModeling and Natural Language Processing 978 . 1 L a n g u a g e m o d e l i n g ..................... 98\\n8 . 2 N a t u r a l l a n g u a g e p r o c e s s i n g ................. 104\\n9 Selected Applications in Information Retrieval 113\\n9 . 1 A b r i e f i n t r o d u c t i o n t o i n f o r m a t i o n r e t r i e v a l ........ 113\\n9 . 2 S H D A f o r d o c u m e n t i n d e x i n g a n d r e t r i e v a l ......... 115\\n9 . 3 D S S M f o r d o c u m e n t r e t r i e v a l................ 116\\n9.4 Use of deep stacking networks for information retrieval . . 122\\n10 Selected Applications in Object Recognition\\nand Computer Vision 125\\n10.1 Unsupervised or generative feature learning . . . . . . . . 126\\n1 0 . 2S u p e r v i s e d f e a t u r e l e a r n i n g a n d c l a s s i ﬁ c a t i o n ........ 129\\n11 Selected Applications in Multimodal\\nand Multi-task Learning 1361 1 . 1M u l t i - m o d a l i t i e s : T e x t a n d i m a g e.............. 137\\n11.2 Multi-modalities: Speech and image . . . ......... 141\\n11.3 Multi-task learning within the speech, NLP or image . . . 144\\nFull text available at: http://dx.doi.org/10.1561/2000000039 iv\\n12 Conclusion 148\\nReferences 154\\nFull text available at: http://dx.doi.org/10.1561/2000000039 Endorsement\\n“In the past few years, deep learning has rapidly evolved into the\\nde-facto approach for acoustic modeling in automatic speech recogni-\\ntion (ASR), showing tremendous improvement in accuracy ,robustness ,\\nand cross-language generalizability over conventional approaches. Thistimely book is written by the pioneers of deep learning innovations\\nand applications to ASR, who, as early as 2010 ,ﬁrst succeeded in large\\nvocabulary speech recognition using deep learning. This was accom-plished using a special form of the deep neural net ,developed by the\\nauthors ,perfectly ﬁt for fast decoding as required by industrial deploy-\\nment of ASR technology. In addition to recounting this remarkableadvance which ignited the industry-scale adoption of deep learning in\\nASR,this book also provides an overview of a sweeping range of up-\\nto-date deep learning methodologies and its application to a variety ofsignal and information processing tasks ,including not only ASR but\\nalso computer vision ,language modeling ,text processing ,multimodal\\nlearning, and information retrieval. This is the ﬁrst and the most valu-\\nable book for “deep and wide learning” of deep learning ,not to be\\nmissed by anyone who wants to know the breath taking impact of deep\\nlearning in many facets of information processing ,especially ASR ,all\\nof vital importance to our modern technological society. ”\\n— Sadaoki Furui, President of Toyota Technological Institute at\\nChicago, and Professor at the Tokyo Institute of Technology\\nFull text available at: http://dx.doi.org/10.1561/2000000039 Abstract\\nThis monograph provides an overview of general deep learning method-\\nology and its applications to a variety of signal and information pro-\\ncessing tasks. The application areas are chosen with the following three\\ncriteria in mind: (1) expertise or knowledge of the authors; (2) the\\napplication areas that have already been transformed by the successful\\nuse of deep learning technology, such as speech recognition and com-\\nputer vision; and (3) the application areas that have the potential to be\\nimpacted signiﬁcantly by deep learning and that have been experienc-\\ning research growth, including natural language and text processing,information retrieval, and multimodal information processing empow-\\nered by multi-task deep learning.\\nL. Deng and D. Yu. Deep Learning: Methods and Applications . Foundations and\\nTrendsR/circlecopyrtin Signal Processing, vol. 7, nos. 3–4, pp. 197–387, 2013.\\nDOI: 10.1561/2000000039.\\nFull text available at: http://dx.doi.org/10.1561/2000000039 1\\nIntroduction\\n1.1 Deﬁnitions and background\\nSince 2006, deep structured learning, or more commonly called deep\\nlearning or hierarchical learning, has emerged as a new area of machine\\nlearning research [20, 163]. During the past several years, the techniques\\ndeveloped from deep learning research have already been impacting\\na wide range of signal and information processing work within the\\ntraditional and the new, widened scopes including key aspects of\\nmachine learning and artiﬁcial intelligence; see overview articles in\\n[7, 20, 24, 77, 94, 161, 412], and also the media coverage of this progressin [6, 237]. A series of workshops, tutorials, and special issues or con-\\nference special sessions in recent years have been devoted exclusively\\nto deep learning and its applications to various signal and information\\nprocessing areas. These include:\\n•2008 NIPS Deep Learning Workshop;\\n•2009 NIPS Workshop on Deep Learning for Speech Recognitionand Related Applications;\\n•2009 ICML Workshop on Learning Feature Hierarchies;\\n3\\nFull text available at: http://dx.doi.org/10.1561/2000000039 4 Introduction\\n•2011 ICML Workshop on Learning Architectures, Representa-\\ntions, and Optimization for Speech and Visual Information Pro-\\ncessing;\\n•2012 ICASSP Tutorial on Deep Learning for Signal and Informa-\\ntion Processing;\\n•2012 ICML Workshop on Representation Learning;\\n•2012 Special Section on Deep Learning for Speech and LanguageProcessing in IEEE Transactions on Audio, Speech, and Lan-\\nguage Processing (T-ASLP, January);\\n•2010, 2011, and 2012 NIPS Workshops on Deep Learning and\\nUnsupervised Feature Learning;\\n•2013 NIPS Workshops on Deep Learning and on Output Repre-sentation Learning;\\n•2013 Special Issue on Learning Deep Architectures in IEEE\\nTransactions on Pattern Analysis and Machine Intelligence\\n(T-PAMI, September).\\n•2013 International Conference on Learning Representations;\\n•2013 ICML Workshop on Representation Learning Challenges;\\n•2013 ICML Workshop on Deep Learning for Audio, Speech, andLanguage Processing;\\n•2013 ICASSP Special Session on New Types of Deep Neural Net-\\nwork Learning for Speech Recognition and Related Applications.\\nThe authors have been actively involved in deep learning research andin organizing or providing several of the above events, tutorials, and\\neditorials. In particular, they gave tutorials and invited lectures on\\nthis topic at various places. Part of this monograph is based on their\\ntutorials and lecture material.\\nBefore embarking on describing details of deep learning, let’s pro-\\nvide necessary deﬁnitions. Deep learning has various closely relateddeﬁnitions or high-level descriptions:\\n•Deﬁnition 1 : A class of machine learning techniques that\\nexploit many layers of non-linear information processing for\\nFull text available at: http://dx.doi.org/10.1561/2000000039 1.1. Deﬁnitions and background 5\\nsupervised or unsupervised feature extraction and transforma-\\ntion, and for pattern analysis and classiﬁcation.\\n•Deﬁnition 2 : “A sub-ﬁeld within machine learning that is based\\non algorithms for learning multiple levels of representation in\\norder to model complex relationships among data. Higher-level\\nfeatures and concepts are thus deﬁned in terms of lower-level\\nones, and such a hierarchy of features is called a deep architec-\\nture. Most of these models are based on unsupervised learning of\\nrepresentations. ” (Wikipedia on “Deep Learning” around March\\n2012.)\\n•Deﬁnition 3 : “A sub-ﬁeld of machine learning that is based\\non learning several levels of representations, corresponding to ahierarchy of features or factors or concepts, where higher-level\\nconcepts are deﬁned from lower-level ones, and the same lower-\\nlevel concepts can help to deﬁne many higher-level concepts. Deep\\nlearning is part of a broader family of machine learning methods\\nbased on learning representations. An observation (e.g., an image)\\ncan be represented in many ways (e.g., a vector of pixels), but\\nsome representations make it easier to learn tasks of interest (e.g.,\\nis this the image of a human face?) from examples, and research\\nin this area attempts to deﬁne what makes better representationsand how to learn them. ” (Wikipedia on “Deep Learning” around\\nFebruary 2013.)\\n•Deﬁnition 4 : “Deep learning is a set of algorithms in machine\\nlearning that attempt to learn in multiple levels, correspond-\\ning to diﬀerent levels of abstraction. It typically uses artiﬁcial\\nneural networks. The levels in these learned statistical models\\ncorrespond to distinct levels of concepts, where higher-level con-\\ncepts are deﬁned from lower-level ones, and the same lower-\\nlevel concepts can help to deﬁne many higher-level concepts. ”See Wikipedia http://en.wikipedia.org/wiki/Deep_learning on\\n“Deep Learning” as of this most recent update in October 2013.\\n•Deﬁnition 5 : “Deep Learning is a new area of Machine Learning\\nresearch, which has been introduced with the objective of moving\\nMachine Learning closer to one of its original goals: Artiﬁcial\\nFull text available at: http://dx.doi.org/10.1561/2000000039 6 Introduction\\nIntelligence. Deep Learning is about learning multiple levels of\\nrepresentation and abstraction that help to make sense of data\\nsuch as images, sound, and text. ” See https: //github.com/lisa-\\nlab/DeepLearningTutorials\\nNote that the deep learning that we discuss in this monograph is\\nabout learning with deep architectures for signal and information pro-\\ncessing. It is not about deep understanding of the signal or infor-\\nmation, although in many cases they may be related. It should also\\nbe distinguished from the overloaded term in educational psychology:\\n“Deep learning describes an approach to learning that is character-\\nized by active engagement, intrinsic motivation, and a personal search\\nfor meaning. ” http://www.blackwellreference.com/public/tocnode?id=g9781405161251_chunk_g97814051612516_ss1-1\\nCommon among the various high-level descriptions of deep learning\\nabove are two key aspects: (1) models consisting of multiple layers\\nor stages of nonlinear information processing; and (2) methods for\\nsupervised or unsupervised learning of feature representation at\\nsuccessively higher, more abstract layers. Deep learning is in the\\nintersections among the research areas of neural networks, artiﬁcial\\nintelligence, graphical modeling, optimization, pattern recognition,\\nand signal processing. Three important reasons for the popularityof deep learning today are the drastically increased chip processing\\nabilities (e.g., general-purpose graphical processing units or GPGPUs),\\nthe signiﬁcantly increased size of data used for training, and the recent\\nadvances in machine learning and signal/information processing\\nresearch. These advances have enabled the deep learning methods\\nto eﬀectively exploit complex, compositional nonlinear functions, to\\nlearn distributed and hierarchical feature representations, and to make\\neﬀective use of both labeled and unlabeled data.\\nActive researchers in this area include those at University of\\nToronto, New York University, University of Montreal, Stanford\\nUniversity, Microsoft Research (since 2009), Google (since about2011), IBM Research (since about 2011), Baidu (since 2012), Facebook\\n(since 2013), UC-Berkeley, UC-Irvine, IDIAP, IDSIA, University\\nCollege London, University of Michigan, Massachusetts Institute of\\nFull text available at: http://dx.doi.org/10.1561/2000000039 1.2. Organization of this monograph 7\\nTechnology, University of Washington, and numerous other places; see\\nhttp://deeplearning.net/deep-learning-research-groups-and-labs/ for\\na more detailed list. These researchers have demonstrated empirical\\nsuccesses of deep learning in diverse applications of computer vision,\\nphonetic recognition, voice search, conversational speech recognition,\\nspeech and image feature coding, semantic utterance classiﬁca-\\ntion, natural language understanding, hand-writing recognition, audio\\nprocessing, information retrieval, robotics, and even in the analysis of\\nmolecules that may lead to discovery of new drugs as reported recently\\nby [237].\\nIn addition to the reference list provided at the end of this mono-\\ngraph, which may be outdated not long after the publication of thismonograph, there are a number of excellent and frequently updated\\nreading lists, tutorials, software, and video lectures online at:\\n•http://deeplearning.net/reading-list/\\n•http://uﬂdl.stanford.edu/wiki/index.php/UFLDL_Recommended_Readings\\n•http://www.cs.toronto.edu/ ∼hinton/\\n•http://deeplearning.net/tutorial/\\n•http://uﬂdl.stanford.edu/wiki/index.php/UFLDL_Tutorial\\n1.2 Organization of this monograph\\nThe rest of the monograph is organized as follows:\\nIn Section 2, we provide a brief historical account of deep learning,\\nmainly from the perspective of how speech recognition technology has\\nbeen hugely impacted by deep learning, and how the revolution got\\nstarted and has gained and sustained immense momentum.\\nIn Section 3, a three-way categorization scheme for a majority of\\nthe work in deep learning is developed. They include unsupervised,\\nsupervised, and hybrid deep learning networks, where in the latter cat-egory unsupervised learning (or pre-training) is exploited to assist the\\nsubsequent stage of supervised learning when the ﬁnal tasks pertain to\\nclassiﬁcation. The supervised and hybrid deep networks often have the\\nFull text available at: http://dx.doi.org/10.1561/2000000039 8 Introduction\\nsame type of architectures or the structures in the deep networks, but\\nthe unsupervised deep networks tend to have diﬀerent architectures\\nfrom the others.\\nSections 4–6 are devoted, respectively, to three popular types of\\ndeep architectures, one from each of the classes in the three-way cat-\\negorization scheme reviewed in Section 3. In Section 4, we discuss\\nin detail deep autoencoders as a prominent example of the unsuper-\\nvised deep learning networks. No class labels are used in the learning,\\nalthough supervised learning methods such as back-propagation are\\ncleverly exploited when the input signal itself, instead of any labelinformation of interest to possible classiﬁcation tasks, is treated as the\\n“supervision” signal.\\nIn Section 5, as a major example in the hybrid deep network cate-\\ngory, we present in detail the deep neural networks with unsupervised\\nand largely generative pre-training to boost the eﬀectiveness of super-\\nvised training. This beneﬁt is found critical when the training data\\nare limited and no other appropriate regularization approaches (i.e.,\\ndropout) are exploited. The particular pre-training method based on\\nrestricted Boltzmann machines and the related deep belief networksdescribed in this section has been historically signiﬁcant as it ignited\\nthe intense interest in the early applications of deep learning to speech\\nrecognition and other information processing tasks. In addition to this\\nretrospective review, subsequent development and diﬀerent paths from\\nthe more recent perspective are discussed.\\nIn Section 6, the basic deep stacking networks and their several\\nextensions are discussed in detail, which exemplify the discrimina-\\ntive, supervised deep learning networks in the three-way classiﬁcation\\nscheme. This group of deep networks operate in many ways that aredistinct from the deep neural networks. Most notably, they use target\\nlabels in constructing each of many layers or modules in the overall\\ndeep networks. Assumptions made about part of the networks, such aslinear output units in each of the modules, simplify the learning algo-\\nrithms and enable a much wider variety of network architectures to\\nbe constructed and learned than the networks discussed in Sections 4\\nand 5.\\nFull text available at: http://dx.doi.org/10.1561/2000000039 1.2. Organization of this monograph 9\\nIn Sections 7–11, we select a set of typical and successful applica-\\ntions of deep learning in diverse areas of signal and information process-\\ning. In Section 7, we review the applications of deep learning to speech\\nrecognition, speech synthesis, and audio processing. Subsections sur-\\nrounding the main subject of speech recognition are created based on\\nseveral prominent themes on the topic in the literature.\\nIn Section 8, we present recent results of applying deep learning to\\nlanguage modeling and natural language processing, where we highlight\\nthe key recent development in embedding symbolic entities such as\\nwords into low-dimensional, continuous-valued vectors.\\nSection 9 is devoted to selected applications of deep learning to\\ninformation retrieval including web search.\\nIn Section 10, we cover selected applications of deep learning to\\nimage object recognition in computer vision. The section is divided totwo main classes of deep learning approaches: (1) unsupervised feature\\nlearning, and (2) supervised learning for end-to-end and joint feature\\nlearning and classiﬁcation.\\nSelected applications to multi-modal processing and multi-task\\nlearning are reviewed in Section 11, divided into three categoriesaccording to the nature of the multi-modal data as inputs to the deep\\nlearning systems. For single-modality data of speech, text, or image,\\na number of recent multi-task learning studies based on deep learning\\nmethods are reviewed in the literature.\\nFinally, conclusions are given in Section 12 to summarize the mono-\\ngraph and to discuss future challenges and directions.\\nThis short monograph contains the material expanded from two\\ntutorials that the authors gave, one at APSIPA in October 2011 and\\nthe other at ICASSP in March 2012. Substantial updates have been\\nmade based on the literature up to January 2014 (including the mate-\\nrials presented at NIPS-2013 and at IEEE-ASRU-2013 both held in\\nDecember of 2013), focusing on practical aspects in the fast develop-\\nment of deep learning research and technology during the interim years.\\nFull text available at: http://dx.doi.org/10.1561/2000000039 References\\n[1] O. Abdel-Hamid, L. Deng, and D. Yu. Exploring convolutional neural\\nnetwork structures and optimization for speech recognition. Proceedings\\nof Interspeech , 2013.\\n[ 2 ] O .A b d e l - H a m i d ,L .D e n g ,D .Y u ,a nd H. Jiang. Deep segmental neural\\nnetworks for speech recognition. In Proceedings of Interspeech . 2013.\\n[3] O. Abdel-Hamid, A. Mohamed, H. Jiang, and G. Penn. Applying convo-\\nlutional neural networks concepts to hybrid NN-HMM model for speech\\nrecognition. In Proceedings of International Conference on Acoustics\\nSpeech and Signal Processing (ICASSP) . 2012.\\n[4] A. Acero, L. Deng, T. Kristjansson, and J. Zhang. HMM adaptation\\nusing vector taylor series fo r noisy speech recognition. In Proceedings\\nof Interspeech . 2000.\\n[5] G. Alain and Y. Bengio. What regularized autoencoders learn from the\\ndata generating distribution. In Proceedings of International Conference\\non Learning Representations (ICLR) . 2013.\\n[6] G. Anthes. Deep learning comes of age. Communications of the Asso-\\nciation for Computing Machinery (ACM) , 56(6):13–15, June 2013.\\n[7] I. Arel, C. Rose, and T. Karnowski. Deep machine learning — a new\\nfrontier in artiﬁcial intelligence. IEEE Computational Intelligence Mag-\\nazine , 5:13–18, November 2010.\\n154\\nFull text available at: http://dx.doi.org/10.1561/2000000039 References 155\\n[8] E. Arisoy, T. Sainath, B. Kingsbury, and B. Ramabhadran. Deep neural\\nnetwork language models. In Proceedings of the Joint Human Language\\nTechnology Conference and the North American Chapter of the Associ-\\nation of Computational Linguistics (HLT-NAACL) Workshop . 2012.\\n[9] O. Aslan, H. Cheng, D. Schuurmans, and X. Zhang. Convex two-layer\\nmodeling. In Proceedings of Neural Information Processing Systems\\n(NIPS) . 2013.\\n[10] J. Ba and B. Frey. Adaptive dropout for training deep neural networks.\\nInProceedings of Neural Information Processing Systems (NIPS) . 2013.\\n[11] J. Baker, L. Deng, J. Glass, S. Khudanpur, C.-H. Lee, N. Morgan, and\\nD. O’Shaughnessy. Research developments and directions in speech\\nrecognition and understanding. IEEE Signal Processing Magazine ,\\n26(3):75–80, May 2009.\\n[12] J. Baker, L. Deng, J. Glass, S. Khudanpur, C.-H. Lee, N. Morgan, and\\nD. O’Shaughnessy. Updated MINS report on speech recognition and\\nunderstanding. IEEE Signal Processing Magazine , 26(4), July 2009.\\n[13] P. Baldi and P. Sadowski. Understanding dropout. In Proceedings of\\nNeural Information Processing Systems (NIPS) . 2013.\\n[14] E. Battenberg, E. Schmidt, and J. Bello. Deep learning for\\nmusic, special session at International Conference on Acoustics\\nSpeech and Signal Processing (ICASSP) (http://www.icassp2014.org/\\nspecial_sections.html#ss8), 2014.\\n[15] E. Batternberg and D. Wessel. Analyzing drum patterns using condi-\\ntional deep belief networks. In Proceedings of International Symposium\\non Music Information Retrieval (ISMIR) . 2012.\\n[16] P. Bell, P. Swietojanski, and S. Renals. Multi-level adaptive networks\\nin tandem and hybrid ASR systems. In Proceedings of International\\nConference on Acoustics Speech and Signal Processing (ICASSP) . 2013.\\n[17] Y. Bengio. Artiﬁcial neural networks and their application to sequence\\nrecognition. Ph.D. Thesis, McGill University, Montreal, Canada, 1991.\\n[18] Y. Bengio. New distributed probabilistic language models. Technical\\nReport, University of Montreal, 2002.\\n[19] Y. Bengio. Neural net language models. Scholarpedia, 3, 2008.\\n[20] Y. Bengio. Learning d eep architectures for AI. in Foundations and\\nTrends in Machine Learning , 2(1):1–127, 2009.\\nFull text available at: http://dx.doi.org/10.1561/2000000039 156 References\\n[21] Y. Bengio. Deep learning of representations for unsupervised and trans-\\nfer learning. Journal of Machine Learning Research Workshop and Con-\\nference Proceedings , 27:17–37, 2012.\\n[22] Y. Bengio. Deep learning of representations: Looking forward. In Sta-\\ntistical Language and Speech Processing , pages 1–37. Springer, 2013.\\n[23] Y. Bengio, N. Boulanger, and R. Pascanu. Advances in optimizing recur-\\nrent networks. In Proceedings of International Conference on Acoustics\\nSpeech and Signal Processing (ICASSP) . 2013.\\n[24] Y. Bengio, A. Courville, and P. Vincent. Representation learning: A\\nreview and new perspectives. IEEE Transactions on Pattern Analysis\\nand Machine Intelligence (PAMI) , 38:1798–1828, 2013.\\n[25] Y. Bengio, R. De Mori, G. Flammia, and R. Kompe. Global optimiza-\\ntion of a neural network-hidden markov model hybrid. IEEE Transac-\\ntions on Neural Networks , 3:252–259, 1992.\\n[26] Y. Bengio, R. Ducharme, P. Vincent, and C. Jauvin. A neural proba-\\nbilistic language model. In Proceedings of Neural Information Processing\\nSystems (NIPS) . 2000.\\n[27] Y. Bengio, R. Ducharme, P. Vincent, and C. Jauvin. A neural proba-\\nbilistic language model. Journal of Machine Learning Research , 3:1137–\\n1155, 2003.\\n[28] Y. Bengio, P. Lamblin, D. Popovici, and H. Larochelle. Greedy layer-\\nwise training of deep networks. In Proceedings of Neural Information\\nProcessing Systems (NIPS) . 2006.\\n[29] Y. Bengio, P. Simard, and P. Frasconi. Learning long-term dependen-\\ncies with gradient descent is diﬃcult. IEEE Transactions on Neural\\nNetworks , 5:157–166, 1994.\\n[30] Y. Bengio, E. Thibodeau-Laufer, and J. Yosinski. Deep generative\\nstochastic networks trainable by backprop. arXiv 1306:1091, 2013.\\nalso accepted to appear in Proceedings of International Conference on\\nMachine Learning (ICML), 2014.\\n[31] Y. Bengio, L. Yao, G. Alain, and P. Vincent. Generalized denoising\\nautoencoders as generative models. In Proceedings of Neural Informa-\\ntion Processing Systems (NIPS) . 2013.\\n[32] J. Bergstra and Y. Bengio. Random search for hyper-parameter opti-\\nmization. Journal on Machine Learning Research , 3:281–305, 2012.\\nFull text available at: http://dx.doi.org/10.1561/2000000039 References 157\\n[33] A. Biem, S. Katagiri, E. McDermott, and B. Juang. An application\\nof discriminative feature extractio n to ﬁlter-bank-based speech recog-\\nnition. IEEE Transactions on Speech and Audio Processing , 9:96–110,\\n2001.\\n[34] J. Bilmes. Dynamic graphical models. IEEE Signal Processing Maga-\\nzine, 33:29–42, 2010.\\n[35] J. Bilmes and C. Bartels. Graphi cal model architectures for speech\\nrecognition. IEEE Signal Processing Magazine , 22:89–100, 2005.\\n[36] A. Bordes, X. Glorot, J. Weston, and Y. Bengio. A semantic matching\\nenergy function for learning with multi-relational data — application\\nto word-sense disambiguation. Machine Learning , May 2013.\\n[37] A. Bordes, J. Weston, R. Collobert, and Y. Bengio. Learning structured\\nembeddings of knowledge bases. In Proceedings of Association for the\\nAdvancement of Artiﬁcial Intelligence (AAAI) . 2011.\\n[38] L. Bottou. From machine learning to machine reasoning: An essay.\\nJournal of Machine Learning Research , 14:3207–3260, 2013.\\n[39] L. Bottou and Y. LeCun. Large scale online learning. In Proceedings of\\nNeural Information Processing Systems (NIPS) . 2004.\\n[40] N. Boulanger-Lewandowski, Y. Bengio, and P. Vincent. Modeling\\nTemporal dependencies in high-dime nsional sequences: Application to\\npolyphonic music generation and transcription. In Proceedings of Inter-\\nnational Conference on Machine Learning (ICML) . 2012.\\n[41] N. Boulanger-Lewandowski, Y. Bengio, and P. Vincent. Audio chord\\nrecognition with recurrent neural networks. In Proceedings of Interna-\\ntional Symposium on Music Information Retrieval (ISMIR) . 2013.\\n[42] H. Bourlard and N. Morgan. Connectionist Speech Recognition: A\\nHybrid Approach. Kluwer, Norwell, MA, 1993.\\n[43] J. Bouvrie. Hierarchical learning: Theory with applications in speech\\nand vision. Ph.D. thesis, MIT, 2009.\\n[44] L. Breiman. Stacked regression. Machine Learning , 24:49–64, 1996.\\n[45] J. Bridle, L. Deng, J. Picone, H. Richards, J. Ma, T. Kamm, M. Schus-\\nter, S. Pike, and R. Reagan. An investigation of segmental hiddendynamic models of speech coarticula tion for automatic speech recogni-\\ntion. Final Report for 1998 Workshop on Language Engineering, CLSP,Johns Hopkins, 1998.\\n[46] P. Cardinal, P. Dumouchel, and G. Boulianne. Large vocabulary speech\\nrecognition on parallel architectures. IEEE Transactions on Audio,\\nSpeech, and Language Processing , 21(11):2290–2300, November 2013.\\nFull text available at: http://dx.doi.org/10.1561/2000000039 158 References\\n[47] R. Caruana. Multitask learning. Machine Learning , 28:41–75, 1997.\\n[48] J. Chen and L. Deng. A primal-dual method for training recurrent\\nneural networks constrained by the echo-state property. In Proceedings\\nof International Conference on Learning Representations . April 2014.\\n[ 4 9 ]X .C h e n ,A .E v e r s o l e ,G .L i ,D .Y u ,a n dF .S e i d e . P i p e l i n e db a c k -\\npropagation for context-dependent deep neural networks. In Proceedings\\nof Interspeech . 2012.\\n[50] R. Chengalvarayan and L. Deng. Hmm-based speech recognition using\\nstate-dependent, discriminatively derived transforms on Mel-warped\\nDFT features. IEEE Transactions on Speech and Audio Processing ,\\npages 243–256, 1997.\\n[51] R. Chengalvarayan and L. Deng. Use of generalized dynamic feature\\nparameters for speech recognition. IEEE Transactions on Speech and\\nAudio Processing , pages 232–242, 1997a.\\n[52] R. Chengalvarayan and L. Deng. Sp eech trajectory discrimination using\\nthe minimum classiﬁcation error learning. IEEE Transactions on Speech\\nand Audio Processing , 6(6):505–515, 1998.\\n[53] Y. Cho and L. Saul. Kernel methods for deep learning. In Proceedings of\\nNeural Information Processing Systems (NIPS) , pages 342–350. 2009.\\n[54] D. Ciresan, A. Giusti, L. Gambardella, and J. Schmidhuber. Deep neural\\nnetworks segment neuronal membran es in electron microscopy images.\\nInProceedings of Neural Information Processing Systems (NIPS) . 2012.\\n[55] D. Ciresan, U. Meier, L. Gambardella, and J. Schmidhuber. Deep, big,\\nsimple neural nets for handwritten digit recognition. Neural Computa-\\ntion, December 2010.\\n[56] D. Ciresan, U. Meier, J. Masci, and J. Schmidhuber. A committee of\\nneural networks for traﬃc sign classiﬁcation. In Proceedings of Interna-\\ntional Joint Conference on Neural Networks (IJCNN) . 2011.\\n[57] D. Ciresan, U. Meier, and J. Schmidhuber. Multi-column deep neural\\nnetworks for image classiﬁcation. In Proceedings of Computer Vision\\nand Pattern Recognition (CVPR) . 2012.\\n[58] D. C. Ciresan, U. Meier, and J. Schmidhuber. Transfer learning for Latin\\nand Chinese characters with deep neural networks. In Proceedings of\\nInternational Joint Conference on Neural Networks (IJCNN) . 2012.\\n[59] A. Coates, B. Huval, T. Wang, D. Wu, A. Ng, and B. Catanzaro. Deep\\nlearning with COTS HPC. In Proceedings of International Conference\\non Machine Learning (ICML) . 2013.\\nFull text available at: http://dx.doi.org/10.1561/2000000039 References 159\\n[60] W. Cohen and R. V. de Carvalho. Stacked sequential learning. In\\nProceedings of International Joint Conference on Artiﬁcial Intelligence\\n(IJCAI) , pages 671–676. 2005.\\n[61] R. Collobert. Deep learning for eﬃcient discriminative parsing. In\\nProceedings of Artiﬁcial Intelligence and Statistics (AISTATS) . 2011.\\n[62] R. Collobert and J. Weston. A uniﬁed architecture for natural language\\nprocessing: Deep neural networks with multitask learning. In Proceed-\\nings of International Conference on Machine Learning (ICML) . 2008.\\n[63] R. Collobert, J. Weston, L. Bottou, M. Karlen, K. Kavukcuoglu, and\\nP. Kuksa. Natural language processing (almost) from scratch. Journal\\non Machine Learning Research, 12:2493–2537, 2011.\\n[64] G. Dahl, M. Ranzato, A. Mohamed, and G. Hinton. Phone recognition\\nwith the mean-covariance rest ricted boltzmann machine. In Proceedings\\nof Neural Information Processing Systems (NIPS) , volume 23, pages\\n469–477. 2010.\\n[65] G. Dahl, T. Sainath, and G. Hinton. Improving deep neural networks\\nfor LVCSR using rectiﬁed linear units and dropout. In Proceedings\\nof International Conference on Acoustics Speech and Signal Processing\\n(ICASSP) . 2013.\\n[66] G. Dahl, J. Stokes, L. Deng, and D. Yu. Large-scale malware classiﬁ-\\ncation using random project ions and neural networks. In Proceedings\\nof International Conference on Acoustics Speech and Signal Processing(ICASSP) . 2013.\\n[67] G. Dahl, D. Yu, L. Deng, and A. Acero. Context-dependent DBN-\\nHMMs in large vocabulary continuous speech recognition. In Proceed-\\nings of International Conference on Acoustics Speech and Signal Pro-\\ncessing (ICASSP) . 2011.\\n[68] G. Dahl, D. Yu, L. Deng, and A. Acero. Context-dependent, pre-trained\\ndeep neural networks for large vocabulary speech recognition. IEEE\\nTransactions on Audio, Speech, & Language Processing , 20(1):30–42,\\nJanuary 2012.\\n[69] J. Dean, G. Corrado, R. Monga, K. Chen, M. Devin, Q. Le, M. Mao,\\nM. Ranzato, A. Senior, P. Tucker, K. Yang, and A. Ng. Large scale\\ndistributed deep networks. In Proceedings of Neural Information Pro-\\ncessing Systems (NIPS) . 2012.\\n[70] K. Demuynck and F. Triefenbach. Porting concepts from DNNs back\\nto GMMs. In Proceedings of the Automatic Speech Recognition and\\nUnderstanding Workshop (ASRU) . 2013.\\nFull text available at: http://dx.doi.org/10.1561/2000000039 160 References\\n[71] L. Deng. A generalized hidden Markov model with state-conditioned\\ntrend functions of time for the speech signal. Signal Processing ,\\n27(1):65–78, 1992.\\n[72] L. Deng. A stochastic model of speech incorporating hierarchical nonsta-\\ntionarity. IEEE Transactions on Speech and Audio Processing , 1(4):471–\\n475, 1993.\\n[73] L. Deng. A dynamic, feature-based approach to the interface between\\nphonology and phonetics for speech modeling and recognition. Speech\\nCommunication , 24(4):299–323, 1998.\\n[74] L. Deng. Computational models for speech production. In Compu-\\ntational Models of Speech Pattern Processing , pages 199–213. Springer\\nVerlag, 1999.\\n[75] L. Deng. Switching dynamic system models for speech articulation and\\nacoustics. In Mathematical Foundations of Speech and Language Pro-\\ncessing , pages 115–134. Springer-Verlag, New York, 2003.\\n[76] L. Deng. Dynamic Speech Models — Theory, Algorithm, and Applica-\\ntion. Morgan & Claypool, December 2006.\\n[77] L. Deng. An overview of deep-structured learning for information pro-\\ncessing. In Proceedings of Asian-Paciﬁc Signal & Information Process-\\ning Annual Summit and Conference (APSIPA-ASC) . October 2011.\\n[78] L. Deng. The MNIST database of handwritten digit images for machine\\nlearning research. IEEE Signal Processing Magazine , 29(6), November\\n2012.\\n[79] L. Deng. Design and learning of output representations for speech recog-\\nnition. In Neural Information Processing Systems (NIPS) Workshop on\\nLearning Output Representations . December 2013.\\n[80] L. Deng. A tutorial survey of architectures, algorithms, and applications\\nfor deep learning. In Asian-Paciﬁc Signal & Information Processing\\nAssociation Transactions on Signal and Information Processing . 2013.\\n[81] L. Deng, O. Abdel-Hamid, and D. Yu. A deep convolutional neural\\nnetwork using heterogeneous pooling for trading acoustic invariance\\nwith phonetic confusion. In Proceedings of International Conference\\non Acoustics Speech and Signal Processing (ICASSP) . 2013.\\n[82] L. Deng, A. Acero, L. Jiang, J. Droppo, and X. Huang. High perfor-\\nmance robust speech recognition using stereo training data. In Pro-\\nceedings of International Conference on Acoustics Speech and SignalProcessing (ICASSP) . 2001.\\nFull text available at: http://dx.doi.org/10.1561/2000000039 References 161\\n[83] L. Deng and M. Aksmanovic. Speaker-independent phonetic classiﬁ-\\ncation using hidden markov models with state-conditioned mixtures of\\ntrend functions. IEEE Transactions on Speech and Audio Processing ,\\n5:319–324, 1997.\\n[84] L. Deng, M. Aksmanovic, D. Sun, and J. Wu. Speech recognition using\\nhidden Markov models with polynomial regression functions as nonsta-\\ntionary states. IEEE Transactions on Speech and Audio Processing ,\\n2(4):507–520, 1994.\\n[85] L. Deng and J. Chen. Sequence classiﬁcation using the high-level fea-\\ntures extracted from d eep neural networks. In Proceedings of Interna-\\ntional Conference on Acoustics Speech and Signal Processing (ICASSP) .\\n2014.\\n[86] L. Deng and K. Erler. Structural design of a hidden Markov model\\nbased speech recognizer using multi-valued phonetic features: Compar-\\nison with segmental speech units. Journal of the Acoustical Society of\\nAmerica , 92(6):3058–3067, 1992.\\n[87] L. Deng, K. Hassanein, and M. Elmasry. Analysis of correlation struc-\\nture for a neural predictive model with application to speech recognition.\\nNeural Networks , 7(2):331–339, 1994.\\n[88] L. Deng, X. He, and J. Gao. Deep stacking networks for informa-\\ntion retrieval. In Proceedings of International Conference on Acoustics\\nSpeech and Signal Processing (ICASSP) . 2013c.\\n[89] L. Deng, G. Hinton, and B. Kingsbury. New types of deep neural\\nnetwork learning for speech recognition and related applications: Anoverview. In Proceedings of International Conference on Acoustics\\nSpeech and Signal Processing (ICASSP) . 2013b.\\n[90] L. Deng and X. D. Huang. Challenges in adopting speech recognition.\\nCommunications of the Association for Computing Machinery (ACM) ,\\n47(1):11–13, January 2004.\\n[91] L. Deng, B. Hutchinson, and D. Yu. Parallel training of deep stacking\\nnetworks. In Proceedings of Interspeech . 2012b.\\n[92] L. Deng, M. Lennig, V. Gupta, F. Seitz, P. Mermelstein, and P. Kenny.\\nPhonemic hidden Markov models with continuous mixture output den-sities for large vocabulary word recognition. IEEE Transactions on\\nSignal Processing , 39(7):1677–1681, 1991.\\n[93] L. Deng, M. Lennig, F. Seitz, and P. Mermelstein. Large vocabulary\\nword recognition using context-dependent allophonic hidden Markovmodels. Computer Speech and Language , 4(4):345–357, 1990.\\nFull text available at: http://dx.doi.org/10.1561/2000000039 162 References\\n[94] L. Deng, J. Li, K. Huang, Yao, D. Yu, F. Seide, M. Seltzer, G. Zweig,\\nX. He, J. Williams, Y. Gong, and A. Acero. Recent advances in deep\\nlearning for speech research at Microsoft. In Proceedings of Interna-\\ntional Conference on Acoustics Speech and Signal Processing (ICASSP) .\\n2013a.\\n[95] L. Deng and X. Li. Machine learning paradigms in speech recogni-\\ntion: An overview. IEEE Transactions on Audio, Speech, & Language ,\\n21:1060–1089, May 2013.\\n[96] L. Deng and J. Ma. Spontaneous speech recognition using a statistical\\ncoarticulatory model for the vocal tract resonance dynamics. Journal\\nof the Acoustical Society America , 108:3036–3048, 2000.\\n[97] L. Deng and D. O’Shaughnessy. Speech Processing — A Dynamic and\\nOptimization-Oriented Approach . Marcel Dekker, 2003.\\n[98] L. Deng, G. Ramsay, and D. Sun. Production models as a structural\\nbasis for automatic speech recognition. Speech Communication , 33(2–\\n3):93–111, August 1997.\\n[99] L. Deng and H. Sameti. Transitional speech units and their represen-\\ntation by regressive Markov states: Applications to speech recognition.\\nIEEE Transactions on speech and audio processing , 4(4):301–306, July\\n1996.\\n[100] L. Deng, M. Seltzer, D. Yu, A. Acero, A. Mohamed, and G. Hinton.\\nBinary coding of speech spectrogr ams using a deep autoencoder. In\\nProceedings of Interspeech . 2010.\\n[101] L. Deng and D. Sun. A statistical approach to automatic speech\\nrecognition using the atomic speech units constructed from overlap-ping articulatory features. Journal of the Acoustical Society of America ,\\n85(5):2702–2719, 1994.\\n[102] L. Deng, G. Tur, X. He, and D. Hakkani-Tur. Use of kernel deep convex\\nnetworks and end-to-end learning for spoken language understanding.\\nInProceedings of IEEE Workshop on Spoken Language Technologies .\\nDecember 2012.\\n[103] L. Deng, K. Wang, A. Acero, H. W. Hon, J. Droppo, C. Boulis, Y. Wang,\\nD. Jacoby, M. Mahajan, C. Chelba, and X. Huang. Distributed speech\\nprocessing in mipad’s multimodal user interface. IEEE Transactions on\\nSpeech and Audio Processing , 10(8):605–619, 2002.\\n[104] L. Deng, J. Wu, J. Droppo, and A. Acero. Dynamic compensation of\\nHMM variances using the feature enhancement uncertainty computedfrom a parametric model of speech distortion. IEEE Transactions on\\nSpeech and Audio Processing , 13(3):412–421, 2005.\\nFull text available at: http://dx.doi.org/10.1561/2000000039 References 163\\n[105] L. Deng and D. Yu. Use of diﬀerential cepstra as acoustic features\\nin hidden trajectory modeling for phonetic recognition. In Proceedings\\nof International Conference on Acoustics Speech and Signal Processing\\n(ICASSP) . 2007.\\n[106] L. Deng and D. Yu. Deep convex network: A scalable architecture for\\nspeech pattern classiﬁcation. In Proceedings of Interspeech . 2011.\\n[107] L. Deng, D. Yu, and A. Acero. A bidirectional target ﬁltering model of\\nspeech coarticulation: Two-stage implementation for phonetic recogni-\\ntion. IEEE Transactions on Audio and Speech Processing , 14(1):256–\\n265, January 2006.\\n[108] L. Deng, D. Yu, and A. Acero. Structured speech modeling. IEEE\\nTransactions on Audio, Speech and Language Processing , 14(5):1492–\\n1504, September 2006.\\n[109] L. Deng, D. Yu, and G. Hinton. Deep learning for speech recognition and\\nrelated applications. Neural Information Processing Systems (NIPS)\\nWorkshop, 2009.\\n[110] L. Deng, D. Yu, and J. Platt. Scalable stacking and learning for build-\\ning deep architectures. In Proceedings of International Conference on\\nAcoustics Speech and Signal Processing (ICASSP) . 2012a.\\n[111] T. Deselaers, S. Hasan, O. Bender, and H. Ney. A deep learning\\napproach to machine transliteration. In Proceedings of 4th Workshop on\\nStatistical Machine Translation , pages 233–241. Athens, Greece, March\\n2009.\\n[112] A. Diez. Automatic language recognition using deep neural networks.\\nThesis, Universidad Autonoma de Madrid, SPAIN, September 2013.\\n[113] P. Dognin and V. Goel. Combining stochastic average gradient and\\nhessian-free optimization for sequence training of deep neural networks.\\nInProceedings of the Automatic Speech Recognition and Understanding\\nWorkshop (ASRU) . 2013.\\n[114] D. Erhan, Y. Bengio, A. Courvelle, P. Manzagol, P. Vencent, and S. Ben-\\ngio. Why does unsupervised pre-training help deep learning? Journal\\non Machine Learning Research, pages 201–208, 2010.\\n[115] R. Fernandez, A. Rendel, B. Ramabhadran, and R. Hoory. F0 contour\\nprediction with a deep belief network -gaussian process hybrid model. In\\nProceedings of International Conference on Acoustics Speech and Signal\\nProcessing (ICASSP) , pages 6885–6889. 2013.\\n[116] S. Fine, Y. Singer, and N. Tishby. The hierarchical hidden Markov\\nmodel: Analysis and applications. Machine Learning , 32:41–62, 1998.\\nFull text available at: http://dx.doi.org/10.1561/2000000039 164 References\\n[117] A. Frome, G. Corrado, J. Shlens, S. Bengio, J. Dean, M. Ranzato, and\\nT. Mikolov. Devise: A deep visual-semantic embedding model. In Pro-\\nceedings of Neural Information Processing Systems (NIPS) . 2013.\\n[118] Q. Fu, X. He, and L. Deng. Phone-discriminating minimum classiﬁca-\\ntion error (p-mce) training for phonetic recognition. In Proceedings of\\nInterspeech . 2007.\\n[119] M. Gales. Model-based approaches to handling uncertainty. In Robust\\nSpeech Recognition of Uncertain or Missing Data: Theory and Applica-\\ntion, pages 101–125. Springer, 2011.\\n[120] J. Gao, X. He, and J.-Y. Nie. Clickthrough-based translation models\\nfor web search: From word models to phrase models. In Proceedings of\\nConference on Information and Knowledge Management (CIKM) . 2010.\\n[121] J. Gao, X. He, W. Yih, and L. Deng. Learning semantic representations\\nfor the phrase translation model. In Proceedings of Neural Informa-\\ntion Processing Systems (NIPS) Workshop on Deep Learning . December\\n2013.\\n[122] J. Gao, X. He, W. Yih, and L. Deng. Learning semantic representations\\nfor the phrase translation model. MSR-TR-2013-88, September 2013.\\n[123] J. Gao, X. He, W. Yih, and L. Deng. Learning continuous phrase rep-\\nresentations for translation modeling. In Proceedings of Association for\\nComputational Linguistics (ACL) . 2014.\\n[124] J. Gao, K. Toutanova, and W.-T. Yih. Clickthrough-based latent seman-\\ntic models for web search. In Proceedings of Special Interest Group on\\nInformation Retrieval (SIGIR) . 2011.\\n[125] R. Gens and P. Domingo. Discriminative learning of sum-product net-\\nworks. Neural Information Processing Systems (NIPS) , 2012.\\n[126] D. George. How the brain might work: A hierarchical and temporal\\nmodel for learning and recognition. Ph.D. thesis, Stanford University,\\n2008.\\n[127] M. Gibson and T. Hain. Error approximation and minimum phone error\\nacoustic model estimation. IEEE Transactions on Audio, Speech, and\\nLanguage Processing , 18(6):1269–1279, August 2010.\\n[128] R. Girshick, J. Donahue, T. Darrell, and J. Malik. Rich feature\\nhierarchies for accurate object det ection and semantic segmentation.\\narXiv:1311.2524v1, 2013.\\n[129] X. Glorot and Y. Bengio. Understanding the diﬃculty of training deep\\nfeed-forward neural networks. In Proceedings of Artiﬁcial Intelligence\\nand Statistics (AISTATS) . 2010.\\nFull text available at: http://dx.doi.org/10.1561/2000000039 References 165\\n[130] X. Glorot, A. Bordes, and Y. Bengio. Deep sparse rectiﬁer neural\\nnetworks. In Proceedings of Artiﬁcial Intelligence and Statistics (AIS-\\nTATS) . April 2011.\\n[131] I. Goodfellow, M. Mirza, A. Courv ille, and Y. Bengio. Multi-prediction\\ndeep boltzmann machines. In Proceedings of Neural Information Pro-\\ncessing Systems (NIPS) . 2013.\\n[132] E. Grais, M. Sen, and H. Erdogan. Deep neural networks for single\\nchannel source separation. arXiv:1311.2746v1, 2013.\\n[133] A. Graves. Sequence transduction with recurrent neural networks. Rep-\\nresentation Learning Workshop, International Conference on Machine\\nLearning (ICML) , 2012.\\n[134] A. Graves, S. Fernandez, F. Gomez, and J. Schmidhuber. Connection-\\nist temporal classiﬁcation: Labelin g unsegmented sequence data with\\nrecurrent neural networks. In Proceedings of International Conference\\non Machine Learning (ICML) . 2006.\\n[135] A. Graves, N. Jaitly, and A. Mohamed. Hybrid speech recognition with\\ndeep bidirectional LSTM. In Proceedings of the Automatic Speech Recog-\\nnition and Understanding Workshop (ASRU) . 2013.\\n[136] A. Graves, A. Mohamed, and G. Hinton. Speech recognition with deep\\nrecurrent neural networks. In Proceedings of International Conference\\non Acoustics Speech and Signal Processing (ICASSP) . 2013.\\n[137] F. Grezl and P. Fousek. Optimizing bottle-neck features for LVCSR. In\\nProceedings of International Conference on Acoustics Speech and Signal\\nProcessing (ICASSP) . 2008.\\n[138] C. Gulcehre, K. Cho, R. Pascanu, and Y. Bengio. Learned-\\nnorm pooling for deep feedforward and recurrent neural networks.http://arxiv.org/abs/1311.1780, 2014.\\n[139] M. Gutmann and A. Hyvarinen. Noise-contrastive estimation of unnor-\\nmalized statistical models, with applications to natural image statistics.Journal of Machine Learning Research , 13:307–361, 2012.\\n[140] T. Hain, L. Burget, J. Dines, P. Garner, F. Grezl, A. Hannani, M. Hui-\\njbregts, M. Karaﬁat, M. Lincoln, and V. Wan. Transcribing meetingswith the AMIDA systems. IEEE Transactions on Audio, Speech, and\\nLanguage Processing , 20:486–498, 2012.\\n[141] P. Hamel and D. Eck. Learning features from music audio with deep\\nbelief networks. In Proceedings of International Symposium on Music\\nInformation Retrieval (ISMIR) . 2010.\\nFull text available at: http://dx.doi.org/10.1561/2000000039 166 References\\n[142] G. Hawkins, S. Ahmad, and D. Dubinsky. Hierarchical temporal mem-\\nory including HTM cortical learning algorithms. Numenta Technical\\nReport, December 10 2010.\\n[143] J. Hawkins and S. Blakeslee. On Intelligence: How a New Understanding\\nof the Brain will lead to the Creation of Truly Intelligent Machines .\\nTimes Books, New York, 2004.\\n[144] X. He and L. Deng. Speech recognition, machine translation, and speech\\ntranslation — a unifying discriminative framework. IEEE Signal Pro-\\ncessing Magazine , 28, November 2011.\\n[145] X. He and L. Deng. Optimization in speech-centric information process-\\ning: Criteria and techniques. In Proceedings of International Conference\\non Acoustics Speech and Signal Processing (ICASSP) . 2012.\\n[146] X. He and L. Deng. Speech-centric information processing: An\\noptimization-oriented approach. In Proceedings of the IEEE . 2013.\\n[147] X. He, L. Deng, and W. Chou. Discriminative learning in sequential pat-\\ntern recognition — a unifying review f or optimization-oriented speech\\nrecognition. IEEE Signal Processing Magazine , 25:14–36, 2008.\\n[148] G. Heigold, H. Ney, P. Lehnen, T. Gass, and R. Schluter. Equivalence of\\ngenerative and log-liner models. IEEE Transactions on Audio, Speech,\\nand Language Processing , 19(5):1138–1148, February 2011.\\n[149] G. Heigold, H. Ney, and R. Schluter. Investigations on an EM-style opti-\\nmization algorithm for discriminative training of HMMs. IEEE Trans-\\nactions on Audio, Speech, and Language Processing , 21(12):2616–2626,\\nDecember 2013.\\n[150] G. Heigold, V. Vanhoucke, A. Senior, P. Nguyen, M. Ranzato, M. Devin,\\nand J. Dean. Multilingual acoustic models using distributed deep neu-ral networks. In Proceedings of International Conference on Acoustics\\nSpeech and Signal Processing (ICASSP) . 2013.\\n[151] I. Heintz, E. Fosler-Lussier, and C. Brew. Discriminative input stream\\ncombination for conditional random ﬁeld phone recognition. IEEE\\nTransactions on Audio, Speech, and Language Processing , 17(8):1533–\\n1546, November 2009.\\n[152] M. Henderson, B. Thomson, and S. Young. Deep neural network\\napproach for the dialog state tracking challenge. In Proceedings of Spe-\\ncial Interest Group on Disclosure and Dialogue (SIGDIAL) . 2013.\\n[153] M. Hermans and B. Schrauwen. Training and analysing deep recur-\\nrent neural networks. In Proceedings of Neural Information Processing\\nSystems (NIPS) . 2013.\\nFull text available at: http://dx.doi.org/10.1561/2000000039 References 167\\n[154] H. Hermansky, D. Ellis, and S. Sha rma. Tandem connectionist feature\\nextraction for conventional HMM systems. In Proceedings of Interna-\\ntional Conference on Acoustics Speech and Signal Processing (ICASSP) .\\n2000.\\n[155] Y. Hifny and S. Renals. Speech recognition using augmented conditional\\nrandom ﬁelds. IEEE Transactions on Audio, Speech, and Language\\nProcessing , 17(2):354–365, February 2009.\\n[156] G. Hinton. Mapping part-whole hierarchies into connectionist networks.\\nArtiﬁcial Intelligence , 46:47–75, 1990.\\n[157] G. Hinton. Preface to the special issue on connectionist symbol pro-\\ncessing. Artiﬁcial Intelligence , 46:1–4, 1990.\\n[158] G. Hinton. The ups and downs of Hebb synapses. Canadian Psychology,\\n44:10–13, 2003.\\n[159] G. Hinton. A practical guide to training restricted boltzmann machines.\\nUTML Tech Report 2010-003, Univ. Toronto, August 2010.\\n[160] G. Hinton. A better way to learn features. Communications of the\\nAssociation for Computing Machinery (ACM) , 54(10), October 2011.\\n[161] G. Hinton, L. Deng, D. Yu, G. Dahl, A. Mohamed, N. Jaitly, A. Senior,\\nV. Vanhoucke, P. Nguyen, T. Sainath, and B. Kingsbury. Deep neu-\\nral networks for acoustic modeling in speech recognition. IEEE Signal\\nProcessing Magazine , 29(6):82–97, November 2012.\\n[162] G. Hinton, A. Krizhevsky, and S. Wang. Transforming autoencoders. In\\nProceedings of International Conference on Artiﬁcial Neural Networks .\\n2011.\\n[163] G. Hinton, S. Osindero, and Y. Teh. A fast learning algorithm for deep\\nbelief nets. Neural Computation, 18:1527–1554, 2006.\\n[164] G. Hinton and R. Salakhutdinov. Reducing the dimensionality of data\\nwith neural networks. Science , 313(5786):504–507, July 2006.\\n[165] G. Hinton and R. Salakhutdinov. Discovering binary codes for docu-\\nments by learning deep generative models. Topics in Cognitive Science,\\npages 1–18, 2010.\\n[166] G. Hinton, N. Srivastava, A. Krizhevsky, I. Sutskever, and R. Salakhut-\\ndinov. Improving neural networks by preventing co-adaptation of fea-\\nture detectors. arXiv: 1207.0580v1, 2012.\\n[167] S. Hochreiter. Untersuchungen zu dynamischen neuronalen net-\\nzen. Diploma thesis, Institut fur Informatik, Technische UniversitatMunchen, 1991.\\nFull text available at: http://dx.doi.org/10.1561/2000000039 168 References\\n[168] S. Hochreiter and J. Schmidhuber. Long short-term memory. Neural\\nComputation , 9:1735–1780, 1997.\\n[169] E. Huang, R. Socher, C. Manning, and A. Ng. Improving word represen-\\ntations via global context and multiple word prototypes. In Proceedings\\nof Association for Computational Linguistics (ACL) . 2012.\\n[170] J. Huang, J. Li, L. Deng, and D. Yu. Cross-language knowledge transfer\\nusing multilingual deep neural networks with shared hidden layers. In\\nProceedings of International Conference on Acoustics Speech and Signal\\nProcessing (ICASSP) . 2013.\\n[171] P. Huang, L. Deng, M. Hasegawa-Johnson, and X. He. Random fea-\\ntures for kernel deep convex network. In Proceedings of International\\nConference on Acoustics Speech and Signal Processing (ICASSP) . 2013.\\n[172] P. Huang, X. He, J. Gao, L. Deng, A. Acero, and L. Heck. Learning\\ndeep structured semantic models for web search using clickthrough data.Association for Computing Machinery (ACM) International Conference\\nInformation and Knowledge Management (CIKM) , 2013.\\n[173] P. Huang, K. Kumar, C. Liu, Y. Gong, and L. Deng. Predicting speech\\nrecognition conﬁdence using deep learning with word identity and scorefeatures. In Proceedings of International Conference on Acoustics Speech\\nand Signal Processing (ICASSP) . 2013.\\n[174] S. Huang and S. Renals. Hierarchical bayesian language models for\\nconversational speech recognition. IEEE Transactions on Audio, Speech,\\nand Language Processing , 18(8):1941–1954, November 2010.\\n[175] X. Huang, A. Acero, C. Chelba, L. Deng, J. Droppo, D. Duchene,\\nJ. Goodman, and H. Hon. Mipad: A multimodal interaction proto-type. In Proceedings of International Conference on Acoustics Speech\\nand Signal Processing (ICASSP) . 2001.\\n[176] Y. Huang, D. Yu, Y. Gong, and C. Liu. Semi-supervised GMM and DNN\\nacoustic model training with multi-system combination and conﬁdence\\nre-calibration. In Proceedings of Interspeech , pages 2360–2364. 2013.\\n[177] E. Humphrey and J. Bello. Rethinking automatic chord recognition\\nwith convolutional neural networks. In Proceedings of International\\nConference on Machine Learning and Application (ICMLA) . 2012a.\\n[178] E. Humphrey, J. Bello, and Y. LeCun. Moving beyond feature design:\\nDeep architectures and automatic feature learning in music informat-ics. In Proceedings of International Symposium on Music Information\\nRetrieval (ISMIR). 2012.\\nFull text available at: http://dx.doi.org/10.1561/2000000039 References 169\\n[179] E. Humphrey, J. Bello, and Y. LeCun. Feature learning and deep archi-\\ntectures: New directions for music informatics. Journal of Intelligent\\nInformation Systems , 2013.\\n[180] B. Hutchinson, L. Deng, and D. Yu. A deep architecture with bilinear\\nmodeling of hidden representations: Applications to phonetic recogni-\\ntion. In Proceedings of International Conference on Acoustics Speech\\nand Signal Processing (ICASSP) . 2012.\\n[181] B. Hutchinson, L. Deng, and D. Yu. Tensor deep stacking net-\\nworks. IEEE Transactions on Pattern Analysis and Machine Intelli-\\ngence, 35:1944–1957, 2013.\\n[182] D. Imseng, P. Motlicek, P. Garner, and H. Bourlard. Impact of deep\\nMLP architecture on diﬀerent modeling techniques for under-resourced\\nspeech recognition. In Proceedings of the Automatic Speech Recognition\\nand Understanding Workshop (ASRU) . 2013.\\n[183] N. Jaitly and G. Hinton. Learning a better representation of speech\\nsound waves using restricted boltzmann machines. In Proceedings of\\nInternational Conference on Acoustics Speech and Signal Processing\\n(ICASSP) . 2011.\\n[184] N. Jaitly, P. Nguyen, and V. Vanhoucke. Application of pre-trained deep\\nneural networks to large vocabulary speech recognition. In Proceedings\\nof Interspeech . 2012.\\n[185] K. Jarrett, K. Kavukcuoglu, and Y. LeCun. What is the best multi-\\nstage architecture for object recognition? In Proceedings of International\\nConference on Computer Vision , pages 2146–2153. 2009.\\n[186] H. Jiang and X. Li. Parameter estimation of statistical models using\\nconvex optimization: An advanced method of discriminative trainingfor speech and language processing. IEEE Signal Processing Magazine ,\\n27(3):115–127, 2010.\\n[187] B. Juang, S. Levinson, and M. Sondhi. Maximum likelihood estimation\\nfor multivariate mixture observations of Markov chains. IEEE Trans-\\nactions on Information Theory , 32:307–309, 1986.\\n[188] B.-H. Juang, W. Chou, and C.-H. Lee. Minimum classiﬁcation error\\nrate methods for speech recognition. IEEE Transactions On Speech\\nand Audio Processing , 5:257–265, 1997.\\n[189] S. Kahou et al. Combining modality speciﬁc deep neural networks for\\nemotion recognition in video. In Proceedings of International Conference\\non Multimodal Interaction (ICMI) . 2013.\\nFull text available at: http://dx.doi.org/10.1561/2000000039 170 References\\n[190] S. Kang, X. Qian, and H. Meng. Multi-distribution deep belief network\\nfor speech synthesis. In Proceedings of International Conference on\\nAcoustics Speech and Signal Processing (ICASSP) , pages 8012–8016.\\n2013.\\n[191] Y. Kashiwagi, D. Saito, N. Minematsu, and K. Hirose. Discriminative\\npiecewise linear transformation based on deep learning for noise robust\\nautomatic speech recognition. In Proceedings of the Automatic Speech\\nRecognition and Understanding Workshop (ASRU) . 2013.\\n[192] K. Kavukcuoglu, P. Sermanet, Y. Boureau, K. Gregor, M. Mathieu,\\nand Y. LeCun. Learning convolutional feature hierarchies for visualrecognition. In Proceedings of Neural Information Processing Systems\\n(NIPS) . 2010.\\n[193] H. Ketabdar and H. Bourlard. Enhanced phone posteriors for improving\\nspeech recognition systems. IEEE Transactions on Audio, Speech, and\\nLanguage Processing , 18(6):1094–1106, August 2010.\\n[194] B. Kingsbury. Lattice-based optimization of sequence classiﬁcation cri-\\nteria for neural-network acoustic modeling. In Proceedings of Interna-\\ntional Conference on Acoustics Speech and Signal Processing (ICASSP) .\\n2009.\\n[195] B. Kingsbury, T. Sainath, and H. Soltau. Scalable minimum bayes\\nrisk training of deep neural network acoustic models using distributedhessian-free optimization. In Proceedings of Interspeech . 2012.\\n[196] R. Kiros, R. Zemel, and R. Salakhutdinov. Multimodal neural lan-\\nguage models. In Proceedings of Neural Information Processing Systems\\n(NIPS) Deep Learning Workshop . 2013.\\n[197] T. Ko and B. Mak. Eigentriphones for context-dependent acoustic mod-\\neling. IEEE Transactions on Audio, Speech, and Language Processing ,\\n21(6):1285–1294, 2013.\\n[198] A. Krizhevsky, I. Sutskever, and G. Hinton. Imagenet classiﬁcation with\\ndeep convolutional neural networks. In Proceedings of Neural Informa-\\ntion Processing Systems (NIPS) . 2012.\\n[199] Y. Kubo, T. Hori, and A. Nakamura. Integrating deep neural networks\\ninto structural classiﬁcation approach based on weighted ﬁnite-statetransducers. In Proceedings of Interspeech . 2012.\\n[200] R. Kurzweil. How to Create a Mind . Viking Books, December 2012.\\n[201] P. Lal and S. King. Cross-lingual automatic speech recognition using\\ntandem features. IEEE Transactions on Audio, Speech, and Language\\nProcessing , 21(12):2506–2515, December 2013.\\nFull text available at: http://dx.doi.org/10.1561/2000000039 References 171\\n[202] K. Lang, A. Waibel, and G. Hinton. A time-delay neural network archi-\\ntecture for isolated word recognition. Neural Networks , 3(1):23–43, 1990.\\n[203] H. Larochelle and Y. Bengio. Classiﬁcation using discriminative\\nrestricted boltzm ann machines. In Proceedings of International Con-\\nference on Machine Learning (ICML) . 2008.\\n[204] D. Le and P. Mower. Emotion recognition from spontaneous speech\\nusing hidden markov models with deep belief networks. In Proceed-\\nings of the Automatic Speech Recognition and Understanding Workshop\\n(ASRU) . 2013.\\n[205] H. Le, A. Allauzen, G. Wisniewski, and F. Yvon. Training continuous\\nspace language models: Some practical issues. In Proceedings of Empiri-\\ncal Methods in Natural Language Processing (EMNLP) , pages 778–788.\\n2010.\\n[206] H. Le, I. Oparin, A. Allauzen, J. Gauvain, and F. Yvon. Structured\\noutput layer neural network language model. In Proceedings of Interna-\\ntional Conference on Acoustics Speech and Signal Processing (ICASSP) .\\n2011.\\n[207] H. Le, I. Oparin, A. Allauzen, J.-L. Gauvain, and F. Yvon. Struc-\\ntured output layer neural network language models for speech recogni-\\ntion. IEEE Transactions on Audio, Speech, and Language Processing ,\\n21(1):197–206, January 2013.\\n[208] Q. Le, J. Ngiam, A. Coates, A. Lahiri, B. Prochnow, and A. Ng. On\\noptimization methods for deep learning. In Proceedings of International\\nConference on Machine Learning (ICML) . 2011.\\n[209] Q. Le, M. Ranzato, R. Monga, M. Devin, G. Corrado, K. Chen, J. Dean,\\nand A. Ng. Building high-level features using large scale unsupervised\\nlearning. In Proceedings of International Conference on Machine Learn-\\ning (ICML) . 2012.\\n[210] Y. LeCun. Learning invariant feature hierarchies. In Proceedings of\\nEuropean Conference on Computer Vision (ECCV) . 2012.\\n[211] Y. LeCun and Y. Bengio. Convolutional networks for images, speech,\\nand time series. In M. Arbib, editor, The Handbook of Brain The-\\nory and Neural Networks , pages 255–258. MIT Press, Cambridge, Mas-\\nsachusetts, 1995.\\n[212] Y. LeCun, L. Bottou, Y. Bengio, and P. Haﬀner. Gradient-based learn-\\ning applied to document recognition. Proceedings of the IEEE , 86:2278–\\n2324, 1998.\\nFull text available at: http://dx.doi.org/10.1561/2000000039 172 References\\n[213] Y. LeCun, S. Chopra, M. Ranzato, and F. Huang. Energy-based models\\nin document recognition and computer vision. In Proceedings of Inter-\\nnational Conference on Document Analysis and Recognition (ICDAR) .\\n2007.\\n[214] C.-H. Lee. From knowledge-ignorant to knowledge-rich modeling: A new\\nspeech research paradigm for next-g eneration autom atic speech recog-\\nnition. In Proceedings of International Conference on Spoken Language\\nProcessing (ICSLP) , pages 109–111. 2004.\\n[215] H. Lee, R. Grosse, R. Ranganath, and A. Ng. Convolutional deep belief\\nnetworks for scalable unsupervised learning of hierarchical representa-\\ntions. In Proceedings of International Conference on Machine Learning\\n(ICML). 2009.\\n[216] H. Lee, R. Grosse, R. Ranganath, and A. Ng. Unsupervised learning\\nof hierarchical representations with convolutional deep belief networks.\\nCommunications of the Association for Computing Machinery (ACM) ,\\n54(10):95–103, October 2011.\\n[217] H. Lee, Y. Largman, P. Pham, and A. Ng. Unsupervised feature learning\\nfor audio classiﬁcation using convolutional deep belief networks. In\\nProceedings of Neural Information Processing Systems (NIPS) . 2010.\\n[218] P. Lena, K. Nagata, and P. Baldi. Deep spatiotemporal architectures\\nand learning for protein structure prediction. In Proceedings of Neural\\nInformation Processing Systems (NIPS) . 2012.\\n[219] S. Levine. Exploring deep and recurrent architectures for optimal con-\\ntrol. arXiv:1311.1761v1.\\n[220] J. Li, L. Deng, Y. Gong, and R. Haeb-Umbach. An overview of\\nnoise-robust automatic speech recognition. IEEE/Association for Com-\\nputing Machinery (ACM) Transactions on Audio, Speech, and LanguageProcessing , pages 1–33, 2014.\\n[221] J. Li, D. Yu, J. Huang, and Y. Gong. Improving wideband speech\\nrecognition using mixed-bandwidth training data in CD-DNN-HMM.InProceedings of IEEE Spoken Language Technology (SLT) . 2012.\\n[222] L. Li, Y. Zhao, D. Jiang, and Y. Zhang etc. Hybrid deep neural network–\\nhidden markov model (DNN-HMM) based speech emotion recognition.InProceedings Conference on Aﬀective Computing and Intelligent Inter-\\naction (ACII) , pages 312–317. September 2013.\\n[223] H. Liao. Speaker adaptation of context dependent deep neural net-\\nworks. In Proceedings of International Conference on Acoustics Speech\\nand Signal Processing (ICASSP) . 2013.\\nFull text available at: http://dx.doi.org/10.1561/2000000039 References 173\\n[224] H. Liao, E. McDermott, and A. Senior. Large scale deep neural network\\nacoustic modeling with semi-supervised training data for youtube video\\ntranscription. In Proceedings of the Automatic Speech Recognition and\\nUnderstanding Workshop (ASRU) . 2013.\\n[225] H. Lin, L. Deng, D. Yu, Y. Gong, A. Acero, and C.-H. Lee. A study on\\nmultilingual acoustic modeling for large vocabulary ASR. In Proceedings\\nof International Conference on Acoustics Speech and Signal Processing\\n(ICASSP) . 2009.\\n[226] Y. Lin, F. Lv, S. Zhu, M. Yang, T. Cour, K. Yu, L. Cao, and T. Huang.\\nLarge-scale image classiﬁcation: Fast feature extraction and SVM train-ing. In Proceedings of Computer Vision and Pattern Recognition\\n(CVPR) . 2011.\\n[227] Z. Ling, L. Deng, and D. Yu. Modeling spectral envelopes using\\nrestricted boltzmann m achines and deep belief networks for statisti-\\ncal parametric speech synthesis. IEEE Transactions on Audio Speech\\nLanguage Processing , 21(10):2129–2139, 2013.\\n[228] Z. Ling, L. Deng, and D. Yu. Modeling spectral envelopes using\\nrestricted boltzm ann machines for statistical parametric speech synthe-\\nsis. In International Conference on Acoustics Speech and Signal Pro-\\ncessing (ICASSP) , pages 7825–7829. 2013.\\n[229] Z. Ling, K. Richmond, and J. Yamagishi. Articulatory control of HMM-\\nbased parametric speech synthesis us ing feature-space-switched multi-\\nple regression. IEEE Transactions on Audio, Speech, and Language\\nProcessing , 21, January 2013.\\n[230] L. Lu, K. Chin, A. Ghoshal, and S. Renals. Joint uncertainty decoding\\nfor noise robust subspace gaussian mixture models. IEEE Transactions\\non Audio, Speech, and Language Processing , 21(9):1791–1804, 2013.\\n[231] J. Ma and L. Deng. A path-stack algorithm for optimizing dynamic\\nregimes in a statistical hidden dynamical model of speech. Computer,\\nSpeech and Language , 2000.\\n[232] J. Ma and L. Deng. Eﬃcient decoding strategies for conversational\\nspeech recognition using a constrain ed nonlinear state-space model.\\nIEEE Transactions on Speech and Audio Processing , 11(6):590–602,\\n2003.\\n[233] J. Ma and L. Deng. Target-directed mixture dynamic models for spon-\\ntaneous speech recognition. IEEE Transactions on Speech and Audio\\nProcessing , 12(1):47–58, 2004.\\nFull text available at: http://dx.doi.org/10.1561/2000000039 174 References\\n[234] A. Maas, A. Hannun, and A. Ng. Rectiﬁer nonlinearities improve neural\\nnetwork acoustic models. International Conference on Machine Learn-\\ning (ICML) Workshop on Deep Learning for Audio, Speech, and Lan-\\nguage Processing , 2013.\\n[235] A. Maas, Q. Le, T. O’Neil, O. Vinyals, P. Nguyen, and P. Ng. Recurrent\\nneural networks for noise reduction in robust ASR. In Proceedings of\\nInterspeech . 2012.\\n[236] C. Manning, P. Raghavan, and H. Schütze. Introduction to Information\\nRetrieval . Cambridge University Press, 2009.\\n[237] J. Markoﬀ. Scientists see promise in deep-learning programs. New York\\nTimes , November 24 2012.\\n[238] J. Martens. Deep learning with hessian-free optimization. In Proceedings\\nof International Conference on Machine Learning (ICML) . 2010.\\n[239] J. Martens and I. Sutskever. Learning recurrent neural networks with\\nhessian-free optimization. In Proceedings of International Conference\\non Machine Learning (ICML) . 2011.\\n[240] D. McAllester. A PAC-bayesian tutorial with a dropout bound. ArX-\\nive1307.2118, July 2013.\\n[241] I. McGraw, I. Badr, and J. R. Glass. Learning lexicons from speech\\nusing a pronunciation mixture model. IEEE Transactions on Audio,\\nSpeech, and Language Processing , 21(2):357,366, February 2013.\\n[242] G. Mesnil, X. He, L. Deng, and Y. Bengio. Investigation of recurrent-\\nneural-network architectures and learning methods for spoken languageunderstanding. In Proceedings of Interspeech . 2013.\\n[243] Y. Miao and F. Metze. Improving low-resource CD-DNN-HMM using\\ndropout and multilingual DNN training. In Proceedings of Interspeech .\\n2013.\\n[244] Y. Miao, S. Rawat, and F. Metze. Deep maxout networks for low\\nresource speech recognition. In Proceedings of the Automatic Speech\\nRecognition and Understanding Workshop (ASRU) . 2013.\\n[245] T. Mikolov. Statistical language models based on neural networks.\\nPh.D. thesis, Brno University of Technology, 2012.\\n[246] T. Mikolov, K. Chen, G. Corrado, and J. Dean. Eﬃcient estimation of\\nword representations in vector space. In Proceedings of International\\nConference on Learning Representations (ICLR) . 2013.\\nFull text available at: http://dx.doi.org/10.1561/2000000039 References 175\\n[247] T. Mikolov, A. Deoras, D. Povey, L. Burget, and J. Cernocky. Strategies\\nfor training large scale neural network language models. In Proceedings\\nof the IEEE Automatic Speech Recognition and Understanding Work-\\nshop (ASRU) . 2011.\\n[248] T. Mikolov, M. Karaﬁat, L. Burg et, J. Cernocky, and S. Khudanpur.\\nRecurrent neural network based language model. In Proceedings of\\nInternational Conference on Acoustics Speech and Signal Processing(ICASSP) , pages 1045–1048. 2010.\\n[249] T. Mikolov, Q. Le, and I. Sutskever. Exploiting similarities among lan-\\nguages for machine translation. arXiv:1309.4168v1, 2013.\\n[250] T. Mikolov, I. Sutskever, K. Chen, G. Corrado, and J. Dean. Distributed\\nrepresentations of words and phrases and their compositionality. InProceedings of Neural Information Processing Systems (NIPS) . 2013.\\n[251] Y. Minami, E. McDermott, A. Nakamura, and S. Katagiri. A recogni-\\ntion method with parametric trajectory synthesized using direct rela-tions between static and dynamic feature vector time series. In Pro-\\nceedings of International Conference on Acoustics Speech and Signal\\nProcessing (ICASSP) , pages 957–960. 2002.\\n[252] A. Mnih and G. Hinton. Three new graphical models for statistical lan-\\nguage modeling. In Proceedings of International Conference on Machine\\nLearning (ICML) , pages 641–648. 2007.\\n[253] A. Mnih and G. Hinton. A scalable hierarchical distributed lan-\\nguage model. In Proceedings of Neural Information Processing Systems\\n(NIPS) , pages 1081–1088. 2008.\\n[254] A. Mnih and K. Kavukcuoglu. Learning word embeddings eﬃciently\\nwith noise-contrastive estimation. In Proceedings of Neural Information\\nProcessing Systems (NIPS) . 2013.\\n[255] A. Mnih and W.-T. Teh. A fast and simple algorithm for training\\nneural probabilistic language models. In Proceedings of International\\nConference on Machine Learning (ICML) , pages 1751–1758. 2012.\\n[256] V. Mnih, K. Kavukcuoglu, D. Silver, A. Graves, I. Antonoglou, D. Wier-\\nstra, and M. Riedmiller. Playing arari with deep reinforcement learning.Neural Information Processing Systems (NIPS) Deep Learning Work-\\nshop, 2013. also arXiv:1312.5602v1.\\n[257] A. Mohamed, G. Dahl, and G. Hinton. Deep belief networks for phone\\nrecognition. In Proceedings of Neural Information Processing Systems\\n(NIPS) Workshop Deep Learning for Speech Recognition and RelatedApplications . 2009.\\nFull text available at: http://dx.doi.org/10.1561/2000000039 176 References\\n[258] A. Mohamed, G. Dahl, and G. Hinton. Acoustic modeling using deep\\nbelief networks. IEEE Transactions on Audio, Speech, & Language Pro-\\ncessing , 20(1), January 2012.\\n[259] A. Mohamed, G. Hinton, and G. Penn. Understanding how deep belief\\nnetworks perform acoustic modelling. In Proceedings of International\\nConference on Acoustics Speech and Signal Processing (ICASSP) . 2012.\\n[260] A. Mohamed, D. Yu, and L. Deng. Investigation of full-sequence train-\\ning of deep belief networks for speech recognition. In Proceedings of\\nInterspeech . 2010.\\n[261] N. Morgan. Deep and wide: Multiple layers in automatic speech recog-\\nnition. IEEE Transactions on Audio, Speech, & Language Processing ,\\n20(1), January 2012.\\n[262] N. Morgan, Q. Zhu, A. Stolcke, K. Sonmez, S. Sivadas, T. Shinozaki,\\nM. Ostendorf, P. Jain, H. Hermansky, D. Ellis, G. Doddington, B. Chen,\\nO. Cretin, H. Bourlard, and M. Athineos. Pushing the envelope — aside\\n[speech recognition]. IEEE Signal Processing Magazine , 22(5):81–88,\\nSeptember 2005.\\n[263] F. Morin and Y. Bengio. Hierarchical probabilistic neural network lan-\\nguage models. In Proceedings of Artiﬁcial Intelligence and Statistics\\n(AISTATS) . 2005.\\n[264] K. Murphy. Machine Learning — A Probabilistic Perspective .T h eM I T\\nPress, 2012.\\n[265] V. Nair and G. Hinton. 3-d object recognition with deep belief nets. In\\nProceedings of Neural Information Processing Systems (NIPS) . 2009.\\n[266] T. Nakashika, R. Takashima, T. Takiguchi, and Y. Ariki. Voice conver-\\nsion in high-order eigen space using deep belief nets. In Proceedings of\\nInterspeech . 2013.\\n[267] H. Ney. Speech translation: Coupling of recognition and translation. In\\nProceedings of International Conference on Acoustics Speech and Signal\\nProcessing (ICASSP) . 1999.\\n[268] J. Ngiam, Z. Chen, P. Koh, and A. Ng. Learning deep energy models. In\\nProceedings of International Conference on Machine Learning (ICML) .\\n2011.\\n[269] J. Ngiam, A. Khosla, M. Kim, J. Nam, H. Lee, and A. Ng. Multimodal\\ndeep learning. In Proceedings of International Conference on Machine\\nLearning (ICML) . 2011.\\nFull text available at: http://dx.doi.org/10.1561/2000000039 References 177\\n[270] M. Norouzi, T. Mikolov, S. Bengio, J. Shlens, A. Frome, G. Corrado,\\nand J. Dean. Zero-shot learning by convex combination of semantic\\nembeddings. arXiv:1312.5650v2, 2013.\\n[271] N. Oliver, A. Garg, and E. Horvitz. Layered representations for learning\\nand inferring oﬃce activity from multiple sensory channels. Computer\\nVision and Image Understanding , 96:163–180, 2004.\\n[272] B. Olshausen. Can ‘deep learning’ oﬀer deep insights about visual rep-\\nresentation? Neural Information Processing Systems (NIPS) Workshop\\non Deep Learning and Unsupervised Feature Learning , 2012.\\n[273] M. Ostendorf. Moving beyond the ‘beads-on-a-string’ model of speech.\\nInProceedings of the Automatic Speech Recognition and Understanding\\nWorkshop (ASRU) . 1999.\\n[274] M. Ostendorf, V. Digalakis, and O. Kimball. From HMMs to segment\\nmodels: A uniﬁed view of stochastic modeling for speech recognition.IEEE Transactions on Speech and Audio Processing , 4(5), September\\n1996.\\n[275] L. Oudre, C. Fevotte, and Y. Gren ier. Probabilistic template-based\\nchord recognition. IEEE Transactions on Audio, Speech, and Language\\nProcessing , 19(8):2249–2259, November 2011.\\n[276] H. Palangi, L. Deng, and R. Ward . Learning input and recurrent weight\\nmatrices in echo state networks. Neural Information Processing Systems\\n(NIPS) Deep Learning Workshop , December 2013.\\n[277] H. Palangi, R. Ward, and L. Deng. Using deep stacking network to\\nimprove structured compressive sensing with multiple measurement vec-\\ntors. In Proceedings of International Conference on Acoustics Speech\\nand Signal Processing (ICASSP) . 2013.\\n[278] G. Papandreou, A. Katsamanis, V. Pitsikalis, and P. Maragos. Adap-\\ntive multimodal fusion by uncertainty compensation with application toaudiovisual speech recognition. IEEE Transactions on Audio, Speech,\\nand Language Processing , 17:423–435, 2009.\\n[279] R. Pascanu, C. Gulcehre, K. Cho, and Y. Bengio. How to construct deep\\nrecurrent neural networks. In Proceedings of International Conference\\non Learning Representations (ICLR) . 2014.\\n[280] R. Pascanu, T. Mikolov, and Y. Bengio. On the diﬃculty of training\\nrecurrent neural networks. In Proceedings of International Conference\\non Machine Learning (ICML) . 2013.\\n[281] J. Peng, L. Bo, and J. Xu. Conditional neural ﬁelds. In Proceedings of\\nNeural Information Processing Systems (NIPS) . 2009.\\nFull text available at: http://dx.doi.org/10.1561/2000000039 178 References\\n[282] P. Picone, S. Pike, R. Regan, T. Kamm, J. bridle, L. Deng, Z. Ma,\\nH. Richards, and M. Schuster. Initial evaluation of hidden dynamic\\nmodels on conversational speech. In Proceedings of International Con-\\nference on Acoustics Speech and Signal Processing (ICASSP) . 1999.\\n[283] J. Pinto, S. Garimella, M. Magimai-Doss, H. Hermansky, and\\nH. Bourlard. Analysis of MLP-based hierarchical phone posterior prob-\\nability estimators. IEEE Transactions on Audio, Speech, and Language\\nProcessing , 19(2), February 2011.\\n[284] C. Plahl, T. Sainath, B. Ramabhadran, and D. Nahamoo. Improved\\npre-training of deep belief networks using sparse encoding symmet-ric machines. In Proceedings of International Conference on Acoustics\\nSpeech and Signal Processing (ICASSP) . 2012.\\n[285] C. Plahl, R. Schlüter, and H. Ney. Hierarchical bottleneck features for\\nLVCSR. In Proceedings of Interspeech . 2010.\\n[286] T. Plate. Holographic reduced representations. IEEE Transactions on\\nNeural Networks , 6(3):623–641, May 1995.\\n[287] T. Poggio. How the brain might work: The role of information and\\nlearning in understanding and replicating intelligence. In G. Jacovitt,A. Pettorossi, R. Consolo, and V. Senni, editors, Information: Science\\nand Technology for the New Century, pages 45–61. Lateran University\\nPress, 2007.\\n[288] J. Pollack. Recursive distributed representations. Artiﬁcial Intelligence ,\\n46:77–105, 1990.\\n[289] H. Poon and P. Domingos. Sum-product networks: A new deep archi-\\ntecture. In Proceedings of Uncertainty in Artiﬁcial Intelligence . 2011.\\n[290] D. Povey and P. Woodland. Minimum phone error and I-smoothing\\nfor improved discriminative training. In Proceedings of International\\nConference on Acoustics Speech and Signal Processing (ICASSP) . 2002.\\n[291] R. Prabhavalkar and E. Fosler-Lussier. Backpropagation training for\\nmultilayer conditional random ﬁeld based phone recognition. In Pro-\\nceedings of International Conference on Acoustics Speech and Signal\\nProcessing (ICASSP) . 2010.\\n[292] A. Prince and P. Smolensky. Optimality: From neural networks to uni-\\nversal grammar. Science , 275:1604–1610, 1997.\\n[293] L. Rabiner. A tutorial on hidden markov models and selected applica-\\ntions in speech recognition. In Proceedings of the IEEE , pages 257–286.\\n1989.\\nFull text available at: http://dx.doi.org/10.1561/2000000039 References 179\\n[294] M. Ranzato, Y. Boureau, and Y. LeCun. Sparse feature learning for\\ndeep belief networks. In Proceedings of Neural Information Processing\\nSystems (NIPS) . 2007.\\n[295] M. Ranzato, S. Chopra, Y. LeCun, and F.-J. Huang. Energy-based\\nmodels in document recognition and computer vision. In Proceed-\\nings of International Conference on Document Analysis and Recognition\\n(ICDAR) . 2007.\\n[296] M. Ranzato and G. Hinton. Modeling pixel means and covariances using\\nfactorized third-order b oltzmann machines. In Proceedings of Computer\\nVision and Pattern Recognition (CVPR) . 2010.\\n[297] M. Ranzato, C. Poultney, S. Chopra, and Y. LeCun. Eﬃcient learning\\nof sparse representations with an energy-based model. In Proceedings\\nof Neural Information Processing Systems (NIPS) . 2006.\\n[298] M. Ranzato, J. Susskind, V. Mnih, and G. Hinton. On deep generative\\nmodels with applications to recognition. In Proceedings of Computer\\nVision and Pattern Recognition (CVPR) . 2011.\\n[299] C. Rathinavalu and L. Deng. Construction of state-dependent dynamic\\nparameters by maximum likelihood: Applications to speech recognition.Signal Processing , 55(2):149–165, 1997.\\n[300] S. Rennie, K. Fouset, and P. Dognin. Factorial hidden restricted boltz-\\nmann machines for noise ro bust speech recognition. In Proceedings\\nof International Conference on Acoustics Speech and Signal Processing(ICASSP) . 2012.\\n[301] S. Rennie, H. Hershey, and P. Olsen. Single-channel multi-talker speech\\nrecognition — graphical modeling approaches. IEEE Signal Processing\\nMagazine , 33:66–80, 2010.\\n[302] M. Riedmiller and H. Braun. A direct adaptive method for faster back-\\npropagation learning: The RPROP algorithm. In Proceedings of the\\nIEEE International Conference on Neural Networks . 1993.\\n[303] S. Rifai, P. Vincent, X. Muller, X. Glorot, and Y. Bengio. Contractive\\nautoencoders: Explicit invariance during feature extraction. In Proceed-\\nings of International Conference on Machine Learning (ICML) , pages\\n833–840. 2011.\\n[304] A. Robinson. An application o f recurrent nets to phone probability\\nestimation. IEEE Transactions on Neural Networks , 5:298–305, 1994.\\n[305] T. Sainath, L. Horesh, B. Kingsbury, A. Aravkin, and B. Ramabhad-\\nran. Accelerating hessian-free optim ization for deep neural networks by\\nimplicit pre-conditioning and sampling. arXiv: 1309.1508v3, 2013.\\nFull text available at: http://dx.doi.org/10.1561/2000000039 180 References\\n[306] T. Sainath, B. Kingsbury, A. Mohamed, G. Dahl, G. Saon, H. Soltau,\\nT. Beran, A. Aravkin, and B. Ramabhadran. Improvements to deep\\nconvolutional neural networks for LVCSR. In Proceedings of the Auto-\\nmatic Speech Recognition and Understanding Workshop (ASRU) . 2013.\\n[307] T. Sainath, B. Kingsbury, A. Mohamed, and B. Ramabhadran. Learn-\\ning ﬁlter banks within a deep neural network framework. In Proceed-\\nings of The Automatic Speech Recognition and Understanding Workshop\\n(ASRU) . 2013.\\n[308] T. Sainath, B. Kingsbury, and B. Ramabhadran. Autoencoder bottle-\\nneck features using deep belief networks. In Proceedings of International\\nConference on Acoustics Speech and Signal Processing (ICASSP) . 2012.\\n[309] T. Sainath, B. Kingsbury, B. Ramabhadran, P. Novak, and\\nA. Mohamed. Making deep belief net works eﬀective for large vocab-\\nulary continuous speech recognition. In Proceedings of the Automatic\\nSpeech Recognition and Understanding Workshop (ASRU) . 2011.\\n[310] T. Sainath, B. Kingsbury, V. Sindhwani, E. Arisoy, and B. Ramabhad-\\nran. Low-rank matrix factorization for deep neural network training\\nwith high-dimensional output targets. In Proceedings of International\\nConference on Acoustics Speech and Signal Processing (ICASSP) . 2013.\\n[311] T. Sainath, B. Kingsbury, H. Soltau, and B. Ramabhadran. Optimiza-\\ntion techniques to improve training speed of deep neural networks for\\nlarge speech tasks. IEEE Transactions on Audio, Speech, and Language\\nProcessing , 21(11):2267–2276, November 2013.\\n[312] T. Sainath, A. Mohamed, B. Kingsbury, and B. Ramabhadran. Con-\\nvolutional neural networks for LVCSR. In Proceedings of International\\nConference on Acoustics Speech and Signal Processing (ICASSP) . 2013.\\n[313] T. Sainath, B. Ramabhadran, M. Picheny, D. Nahamoo, and\\nD. Kanevsky. Exemplar-based sparse representation features: FromTIMIT to LVCSR. IEEE Transactions on Speech and Audio Processing ,\\nNovember 2011.\\n[314] R. Salakhutdinov and G. Hinton. Semantic hashing. In Proceedings of\\nSpecial Interest Group on Information Retrieval (SIGIR) Workshop on\\nInformation Retrieval and Applications of Graphical Models . 2007.\\n[315] R. Salakhutdinov and G. Hinton. Deep boltzmann machines. In Pro-\\nceedings of Artiﬁcial Intelligence and Statistics (AISTATS) . 2009.\\n[316] R. Salakhutdinov and G. Hinton. A better way to pretrain deep boltz-\\nmann machines. In Proceedings of Neural Information Processing Sys-\\ntems (NIPS) . 2012.\\nFull text available at: http://dx.doi.org/10.1561/2000000039 References 181\\n[317] G. Saon, H. Soltau, D. Nahamoo, and M. Picheny. Speaker adaptation\\nof neural network acoustic models using i-vectors. In Proceedings of the\\nAutomatic Speech Recognition and Understanding Workshop (ASRU) .\\n2013.\\n[318] R. Sarikaya, G. Hinton, and B. Ramabhadran. Deep belief nets for nat-\\nural language call-routing. In Proceedings of International Conference\\non Acoustics Speech and Signal Processing (ICASSP) , pages 5680–5683.\\n2011.\\n[319] E. Schmidt and Y. Kim. Learning emotion-based acoustic features with\\ndeep belief networks. In Proceedings IEEE of Signal Processing to Audio\\nand Acoustics . 2011.\\n[320] H. Schwenk. Continuous space translation models for phrase-based sta-\\ntistical machine translation. In Proceedings of Computional Linguistics .\\n2012.\\n[321] H. Schwenk, A. Rousseau, and A. Mohammed. Large, pruned or contin-\\nuous space language models on a gpu for statistical machine translation.\\nInProceedings of the Joint Human Language Technology Conference\\nand the North American Chapter of the Association of ComputationalLinguistics (HLT-NAACL) 2012 Workshop on the future of language\\nmodeling for Human Language Technology (HLT) , pages 11–19.\\n[322] F. Seide, H. Fu, J. Droppo, G. Li, and D. Yu. On parallelizability of\\nstochastic gradient descent for speech DNNs. In Proceedings of Interna-\\ntional Conference on Acoustics Speech and Signal Processing (ICASSP) .\\n2014.\\n[323] F. Seide, G. Li, X. Chen, and D. Yu. Feature engineering in context-\\ndependent deep neural networks for conversational speech transcription.InProceedings of the Automatic Speech Recognition and Understanding\\nWorkshop (ASRU) , pages 24–29. 2011.\\n[324] F. Seide, G. Li, and D. Yu. Conversational speech transcription using\\ncontext-dependent deep neural networks. In Proceedings of Interspeech ,\\npages 437–440. 2011.\\n[325] M. Seltzer, D. Yu, and E. Wang. An investigation of deep neural net-\\nworks for noise robust speech recognition. In Proceedings of Interna-\\ntional Conference on Acoustics Speech and Signal Processing (ICASSP) .\\n2013.\\n[326] M. Shannon, H. Zen, and W. Byrne. Autoregressive models for statisti-\\ncal parametric speech synthesis. IEEE Transactions on Audio, Speech,\\nLanguage Processing , 21(3):587–597, 2013.\\nFull text available at: http://dx.doi.org/10.1561/2000000039 182 References\\n[327] H. Sheikhzadeh and L. Deng. Waveform-based speech recognition using\\nhidden ﬁlter models: Parameter selection and sensitivity to power nor-\\nmalization. IEEE Transactions on on Speech and Audio Processing\\n(ICASSP) , 2:80–91, 1994.\\n[328] Y. Shen, X. He, J. Gao, L. Deng, and G. Mesnil. Learning semantic\\nrepresentations using convolutiona l neural networks for web search. In\\nProceedings World Wide Web . 2014.\\n[329] K. Simonyan, A. Vedaldi, and A. Zisserman. Deep ﬁsher networks for\\nlarge-scale image classiﬁcation. In Proceedings of Neural Information\\nProcessing Systems (NIPS) . 2013.\\n[330] M. Siniscalchi, J. Li, and C. Lee. Hermitian polynomial for speaker\\nadaptation of connectionist speech recognition systems. IEEE Trans-\\nactions on Audio, Speech, and Language Processing , 21(10):2152–2161,\\n2013a.\\n[331] M. Siniscalchi, T. Svendsen, and C.-H. Lee. A bottom-up modular\\nsearch approach to large vocabulary continuous speech recognition.\\nIEEE Transactions on Audio, Speech, Language Processing , 21, 2013.\\n[332] M. Siniscalchi, D. Yu, L. Deng, and C.-H. Lee. Exploiting deep neu-\\nral networks for detection-based speech recognition. Neurocomputing ,\\n106:148–157, 2013.\\n[333] M. Siniscalchi, D. Yu, L. Deng, and C.-H. Lee. Speech recognition using\\nlong-span temporal patterns in a deep network model. IEEE Signal\\nProcessing Letters , 20(3):201–204, March 2013.\\n[334] G. Sivaram and H. Hermansky. Sparse multilayer perceptrons for\\nphoneme recognition. IEEE Transactions on Audio, Speech, & Lan-\\nguage Processing , 20(1), January 2012.\\n[335] P. Smolensky. Tensor product variable binding and the representation\\nof symbolic structures in connectionist systems. Artiﬁcial Intelligence ,\\n46:159–216, 1990.\\n[336] P. Smolensky and G. Legendre. T h eH a r m o n i cM i n d—F r o mN e u -\\nral Computation to Optimality-Theoretic Grammar.T h e M I T P r e s s ,Cambridge, MA, 2006.\\n[337] J. Snoek, H. Larochelle, and R. Adams. Practical bayesian optimization\\nof machine learning algorithms. In Proceedings of Neural Information\\nProcessing Systems (NIPS) . 2012.\\n[338] R. Socher. New directions in deep learning: Structured models, tasks,\\nand datasets. Neural Information Processing Systems (NIPS) Workshop\\non Deep Learning and Unsupervised Feature Learning , 2012.\\nFull text available at: http://dx.doi.org/10.1561/2000000039 References 183\\n[339] R. Socher, Y. Bengio, and C. Manning. Deep learning for NLP.\\nTutorial at Association of Computational Logistics (ACL), 2012, and\\nNorth American Chapter of the Association of Computational Linguis-\\ntics (NAACL) , 2013. http://www.socher.o rg/index.php/DeepLearning\\nTutorial.\\n[340] R. Socher, D. Chen, C. Manning, and A. Ng. Reasoning with neural\\ntensor networks for knowledge base completion. In Proceedings of Neural\\nInformation Processing Systems (NIPS) . 2013.\\n[341] R. Socher and L. Fei-Fei. Connecting modalities: Semi-supervised\\nsegmentation and annotation of images using unaligned text corpora.InProceedings of Computer Vision and Pattern Recognition (CVPR) .\\n2010.\\n[342] R. Socher, M. Ganjoo, H. Sridhar, O. Bastani, C. Manning, and A. Ng.\\nZero-shot learning through cross-modal transfer. In Proceedings of Neu-\\nral Information Processing Systems (NIPS) . 2013b.\\n[343] R. Socher, Q. Le, C. Manning, and A. Ng. Grounded compositional\\nsemantics for ﬁnding and describing images with sentences. Neu-\\nral Information Processing Systems (NIPS) Deep Learning Workshop ,\\n2013c.\\n[344] R. Socher, C. Lin, A. Ng, and C. Manning. Parsing natural scenes\\nand natural language with recursive neural networks. In Proceedings of\\nInternational Conference on Machine Learning (ICML) . 2011.\\n[345] R. Socher, J. Pennington, E. Huang, A. Ng, and C. Manning. Dynamic\\npooling and unfolding recursive autoencoders for paraphrase detection.InProceedings of Neural Information Processing Systems (NIPS) . 2011.\\n[346] R. Socher, J. Pennington, E. Huang, A. Ng, and C. Manning. Semi-\\nsupervised recursive autoencoders f or predicting sentiment distribu-\\ntions. In Proceedings of Empirical Methods in Natural Language Pro-\\ncessing (EMNLP) . 2011.\\n[347] R. Socher, A. Perelygin, J. Wu, J. Chuang, C. Manning, A. Ng, and\\nC. Potts. Recursive deep models for semantic compositionality over asentiment treebank. In Proceedings of Empirical Methods in Natural\\nLanguage Processing (EMNLP) . 2013.\\n[348] N. Srivastava and R. Salakhutdinov. Multimodal learning with deep\\nboltzmann machines. In Proceedings of Neural Information Processing\\nSystems (NIPS) . 2012.\\nFull text available at: http://dx.doi.org/10.1561/2000000039 184 References\\n[349] N. Srivastava and R. Salakhutdinov. Discriminative transfer learning\\nwith tree-based priors. In Proceedings of Neural Information Processing\\nSystems (NIPS) . 2013.\\n[350] R. Srivastava, J. Masci, S. Kazerounian, F. Gomez, and J. Schmidhuber.\\nCompete to compute. In Proceedings of Neural Information Processing\\nSystems (NIPS) . 2013.\\n[351] T. Stafylakis, P. Kenny, M. Senoussaoui, and P. Dumouchel. Prelimi-\\nnary investigation of boltzmann machine classiﬁers for speaker recogni-\\ntion. In Proceedings of Odyssey , pages 109–116. 2012.\\n[352] V. Stoyanov, A. Ropson, and J. Eisner. Empirical risk minimization of\\ngraphical model parameters given approximate inference, decoding, andmodel structure. In Proceedings of Artiﬁcial Intelligence and Statistics\\n(AISTATS) . 2011.\\n[353] H. Su, G. Li, D. Yu, and F. Seide. Error back propagation for sequence\\ntraining of context-dependent deep networks for conversational speech\\ntranscription. In Proceedings of International Conference on Acoustics\\nSpeech and Signal Processing (ICASSP) . 2013.\\n[354] A. Subramanya, L. Deng, Z. Liu, an d Z. Zhang. Multi-sensory speech\\nprocessing: Incorporating automatically extracted hidden dynamicinformation. In Proceedings of IEEE International Conference on Mul-\\ntimedia & Expo (ICME) . Amsterdam, July 2005.\\n[355] J. Sun and L. Deng. An overlapping-feature based phonological model\\nincorporating linguistic constraints: Applications to speech recognition.\\nJournal on Acoustical Society of America , 111(2):1086–1101, 2002.\\n[356] I. Sutskever. Training recurrent neural networks. Ph.D. Thesis, Univer-\\nsity of Toronto, 2013.\\n[357] I. Sutskever, J. Martens, and G. Hinton. Generating text with recurrent\\nneural networks. In Proceedings of International Conference on Machine\\nLearning (ICML) . 2011.\\n[358] Y. Tang and C. Eliasmith. Deep networks for robust visual recogni-\\ntion. In Proceedings of International Conference on Machine Learning\\n(ICML). 2010.\\n[359] Y. Tang and R. Salakhutdinov. Learning Stochastic Feedforward Neural\\nNetworks . NIPS, 2013.\\n[360] A. Tarralba, R. Fergus, and Y. Weiss. Small codes and large image\\ndatabases for recognition. In Proceedings of Computer Vision and Pat-\\ntern Recognition (CVPR) . 2008.\\nFull text available at: http://dx.doi.org/10.1561/2000000039 References 185\\n[361] G. Taylor, G. E. Hinton, and S. Roweis. Modeling human motion using\\nbinary latent variables. In Proceedings of Neural Information Processing\\nSystems (NIPS) . 2007.\\n[362] S. Thomas, M. Seltzer, K. Church, and H. Hermansky. Deep neural\\nnetwork features and semi-supervised training for low resource speech\\nrecognition. In Proceedings of Interspeech . 2013.\\n[363] T. Tieleman. Training restricted boltzmann machines using approx-\\nimations to the likelihood gradient. In Proceedings of International\\nConference on Machine Learning (ICML) . 2008.\\n[364] K. Tokuda, Y. Nankaku, T. Toda, H. Zen, H. Yamagishi, and K. Oura.\\nSpeech synthesis based on hidden markov models. Proceedings of the\\nIEEE , 101(5):1234–1252, 2013.\\n[365] F. Triefenbach, A. Jalalvand, K. Demuynck, and J.-P. Martens. Acoustic\\nmodeling with hierarchical reservoirs. IEEE Transactions on Audio,\\nSpeech, and Language Processing , 21(11):2439–2450, November 2013.\\n[366] G. Tur, L. Deng, D. Hakkani-Tür, and X. He. Towards deep under-\\nstanding: Deep convex networks for semantic utterance classiﬁcation. InProceedings of International Conference on Acoustics Speech and Signal\\nProcessing (ICASSP) . 2012.\\n[367] J. Turian, L. Ratinov, and Y. Bengio. Word representations: A simple\\nand general method for semi-supervised learning. In Proceedings of\\nAssociation for Computational Linguistics (ACL) . 2010.\\n[368] Z. Tüske, M. Sundermeyer, R. Schlüter, and H. Ney. Context-dependent\\nMLPs for LVCSR: TANDEM, hybrid or both? In Proceedings of Inter-\\nspeech . 2012.\\n[369] B. Uria, S. Renals, and K. Richmond. A deep neural network for\\nacoustic-articulatory speech inversion. Neural Information Processing\\nSystems (NIPS) Workshop on Deep Learning and Unsupervised FeatureLearning , 2011.\\n[370] R. van Dalen and M. Gales. Extended VTS for noise-robust speech\\nrecognition. IEEE Transactions on Audio, Speech, and Language Pro-\\ncessing , 19(4):733–743, 2011.\\n[371] A. van den Oord, S. Dieleman, and B. Schrauwen. Deep content-based\\nmusic recommendation. In Proceedings of Neural Information Process-\\ning Systems (NIPS) . 2013.\\n[372] V. Vasilakakis, S. Cumani, and P. Laface. Speaker recognition by means\\nof deep belief networks. In Proceedings of Biometric Technologies in\\nForensic Science . 2013.\\nFull text available at: http://dx.doi.org/10.1561/2000000039 186 References\\n[373] K. Vesely, A. Ghoshal, L. Burget, and D. Povey. Sequence-discriminative\\ntraining of deep neural networks. In Proceedings of Interspeech . 2013.\\n[374] K. Vesely, M. Hannemann, and L. Burget. Semi-supervised training of\\ndeep neural networks. In Proceedings of the Automatic Speech Recogni-\\ntion and Understanding Workshop (ASRU) . 2013.\\n[375] P. Vincent. A connection between score matching and denoising autoen-\\ncoder. Neural Computation, 23(7):1661–1674, 2011.\\n[376] P. Vincent, H. Larochelle, I. Lajoie, Y. Bengio, and P. Manzagol.\\nStacked denoising autoencoders: Lea rning useful representations in a\\ndeep network with a loca l denoising criterion. Journal of Machine\\nLearning Research , 11:3371–3408, 2010.\\n[377] O. Vinyals, Y. Jia, L. Deng, and T. Darrell. Learning with recursive\\nperceptual representations. In Proceedings of Neural Information Pro-\\ncessing Systems (NIPS) . 2012.\\n[378] O. Vinyals and D. Povey. Krylov subspace descent for deep learning. In\\nProceedings of Artiﬁcial Intelligence and Statistics (AISTATS) . 2012.\\n[379] O. Vinyals and S. Ravuri. Comparing multilayer perceptron to deep\\nbelief network tandem features for robust ASR. In Proceedings of\\nInternational Conference on Acoustics Speech and Signal Processing\\n(ICASSP) . 2011.\\n[380] O. Vinyals, S. Ravuri, and D. Povey. Revisiting recurrent neural net-\\nworks for robust ASR. In Proceedings of International Conference on\\nAcoustics Speech and Signal Processing (ICASSP) . 2012.\\n[381] S. Wager, S. Wang, and P. Liang. Dropout training as adaptive reg-\\nularization. In Proceedings of Neural Information Processing Systems\\n(NIPS) . 2013.\\n[382] A. Waibel, T. Hanazawa, G. Hinton, K. Shikano, and K. Lang. Phoneme\\nrecognition using time-delay neural networks. IEEE Transactions on\\nAcoustical Speech, and Signal Processing , 37:328–339, 1989.\\n[383] G. Wang and K. Sim. Context-dependent modelling of deep neural\\nnetwork using logistic regression. In Proceedings of the Automatic Speech\\nRecognition and Understanding Workshop (ASRU) . 2013.\\n[384] G. Wang and K. Sim. Regression-based context-dependent modeling\\nof deep neural networks for speech recognition. IEEE/Association for\\nComputing Machinery (ACM) Transactions on Audio, Speech, and Lan-\\nguage Processing , 2014.\\nFull text available at: http://dx.doi.org/10.1561/2000000039 References 187\\n[385] D. Warde-Farley, I. Goodfellow, A. Courville, and Y. Bengi. An empir-\\nical analysis of dropout in piecewise linear networks. In Proceedings of\\nInternational Conference on Learning Representations (ICLR) . 2014.\\n[386] M. Welling, M. Rosen-Zvi, and G. Hinton. Exponential family harmo-\\nniums with an application to information retrieval. In Proceedings of\\nNeural Information Processing Systems (NIPS) . 2005.\\n[387] C. Weng, D. Yu, M. Seltzer, and J. Droppo. Single-channel mixed speech\\nrecognition using deep neural networks. In Proceedings of International\\nConference on Acoustics Speech and Signal Processing (ICASSP) . 2014.\\n[388] J. Weston, S. Bengio, and N. Usunier. Large scale image annotation:\\nLearning to rank with joint word-image embeddings. Machine Learning ,\\n81(1):21–35, 2010.\\n[389] J. Weston, S. Bengio, and N. Usunier. Wsabie: Scaling up to large\\nvocabulary image annotation. In Proceedings of International Joint\\nConference on Artiﬁcial Intelligence (IJCAI) . 2011.\\n[390] S. Wiesler, J. Li, and J. Xue. Investigations on hessian-free optimization\\nfor cross-entropy training of deep neural networks. In Proceedings of\\nInterspeech . 2013.\\n[391] M. Wohlmayr, M. Stark, and F. Pernkopf. A probabilistic interac-\\ntion model for multi-pitch tracking with factorial hidden markov model.\\nIEEE Transactions on Audio, Speech, and Language Processing , 19(4),\\nMay 2011.\\n[392] D. Wolpert. Stacked generalization. Neural Networks , 5(2):241–259,\\n1992.\\n[393] S. J. Wright, D. Kanevsky, L. Deng, X. He, G. Heigold, and H. Li.\\nOptimization algorithms and applications for speech and language pro-cessing. IEEE Transactions on Audio, Speech, and Language Processing ,\\n21(11):2231–2243, November 2013.\\n[394] L. Xiao and L. Deng. A geometric perspective of large-margin training\\nof gaussian models. IEEE Signal Processing Magazine , 27(6):118–123,\\nNovember 2010.\\n[395] X. Xie and S. Seung. Equivalence of backpropagation and contrastive\\nhebbian learning in a layered network. Neural computation, 15:441–454,\\n2003.\\n[396] Y. Xu, J. Du, L. Dai, and C. Lee. An experimental study on speech\\nenhancement based on deep neural networks. IEEE Signal Processing\\nLetters , 21(1):65–68, 2014.\\nFull text available at: http://dx.doi.org/10.1561/2000000039 188 References\\n[397] J. Xue, J. Li, and Y. Gong. Restructuring of deep neural network\\nacoustic models with singular value decomposition. In Proceedings of\\nInterspeech . 2013.\\n[398] S. Yamin, L. Deng, Y. Wang, and A. Acero. An integrative and discrimi-\\nnative technique for spoken utterance classiﬁcation. IEEE Transactions\\non Audio, Speech, and Language Processing , 16:1207–1214, 2008.\\n[399] Z. Yan, Q. Huo, and J. Xu. A scalable approach to using DNN-derived\\nfeatures in GMM-HMM based acoustic modeling for LVCSR. In Pro-\\nceedings of Interspeech . 2013.\\n[400] D. Yang and S. Furui. Combining a two-step CRF model and a joint\\nsource-channel model for machine transliteration. In Proceedings of\\nAssociation for Computational Linguistics (ACL) , pages 275–280. 2010.\\n[401] K. Yao, D. Yu, L. Deng, and Y. Gong. A fast maximum likelihood non-\\nlinear feature transformation method for GMM-HMM speaker adapta-\\ntion. Neurocomputing , 2013a.\\n[402] K. Yao, D. Yu, F. Seide, H. Su, L. Deng, and Y. Gong. Adaptation of\\ncontext-dependent deep neural networks for automatic speech recogni-tion. In Proceedings of International Conference on Acoustics Speech\\nand Signal Processing (ICASSP) . 2012.\\n[403] K. Yao, G. Zweig, M. Hwang, Y. Shi, and D. Yu. Recurrent neural\\nnetworks for language understanding. In Proceedings of Interspeech .\\n2013.\\n[404] T. Yoshioka and T. Nakatani. Noise model transfer: Novel approach to\\nrobustness against nonstationary noise. IEEE Transactions on Audio,\\nSpeech, and Language Processing , 21(10):2182–2192, 2013.\\n[405] T. Yoshioka, A. Ragni, and M. Gales. Investigation of unsupervised\\nadaptation of DNN acoustic models with ﬁlter bank input. In Pro-\\nceedings of International Conference on Acoustics Speech and Signal\\nProcessing (ICASSP) . 2013.\\n[406] L. Younes. On the convergence of markovian stochastic algorithms with\\nrapidly decreasing ergodicity rates. Stochastics and Stochastic Reports ,\\n65(3):177–228, 1999.\\n[407] D. Yu, X. Chen, and L. Deng. Factorized deep neural networks for adap-\\ntive speech recognition. International Workshop on Statistical Machine\\nLearning for Speech Processing , March 2012b.\\n[408] D. Yu, D. Deng, and S. Wang. Learning in the deep-structured con-\\nditional random ﬁelds. Neural Information Processing Systems (NIPS)\\n2009 Workshop on Deep Learning for Speech Recognition and Related\\nApplications , 2009.\\nFull text available at: http://dx.doi.org/10.1561/2000000039 References 189\\n[409] D. Yu and L. Deng. Solving nonlinear estimation problems using splines.\\nIEEE Signal Processing Magazine , 26(4):86–90, July 2009.\\n[410] D. Yu and L. Deng. Deep-structured hidden conditional random ﬁelds\\nfor phonetic recognition. In Proceedings of Interspeech . September 2010.\\n[411] D. Yu and L. Deng. Accelerated parallelizable neural networks learning\\nalgorithms for speech recognition. In Proceedings of Interspeech . 2011.\\n[412] D. Yu and L. Deng. Deep learning and its applications to signal and\\ninformation processing. IEEE Signal Processing Magazine , pages 145–\\n154, January 2011.\\n[413] D. Yu and L. Deng. Eﬃcient and eﬀective algorithms for training single-\\nhidden-layer neural networks. Pattern Recognition Letters , 33:554–558,\\n2012.\\n[414] D. Yu, L. Deng, and G. E. Dahl. Roles of pre-training and ﬁne-tuning in\\ncontext-dependent DBN-HMMs for r eal-world speech recognition. Neu-\\nral Information Processing Systems (NIPS) 2010 Workshop on Deep\\nLearning and Unsupervised Feature Learning , December 2010.\\n[415] D. Yu, L. Deng, J. Droppo, J. Wu, Y. Gong, and A. Acero. Robust\\nspeech recognition using cepstral m inimum-mean-square-error noise\\nsuppressor. IEEE Transactions on Audio, Speech, and Language Pro-\\ncessing , 16(5), July 2008.\\n[416] D. Yu, L. Deng, Y. Gong, and A. Acero. A novel framework and training\\nalgorithm for variable-parameter hidden markov models. IEEE Trans-\\nactions on Audio, Speech and Language Processing , 17(7):1348–1360,\\n2009.\\n[417] D. Yu, L. Deng, X. He, and A. Acero. Large-margin minimum clas-\\nsiﬁcation error training: A theoretical risk minimization perspective.\\nComputer Speech and Language , 22(4):415–429, October 2008.\\n[418] D. Yu, L. Deng, X. He, and X. Acero. Large-margin minimum classi-\\nﬁcation error training for large-scale speech recognition tasks. In Pro-\\nceedings of International Conference on Acoustics Speech and Signal\\nProcessing (ICASSP) . 2007.\\n[419] D. Yu, L. Deng, G. Li, and F. Seide. Discriminative pretraining of deep\\nneural networks. U.S. Patent Filing , November 2011.\\n[420] D. Yu, L. Deng, P. Liu, J. Wu, Y. Gong, and A. Acero. Cross-lingual\\nspeech recognition under runtime resource constraints. In Proceedings\\nof International Conference on Acoustics Speech and Signal Processing(ICASSP) . 2009b.\\nFull text available at: http://dx.doi.org/10.1561/2000000039 190 References\\n[421] D. Yu, L. Deng, and F. Seide. Large vocabulary speech recognition using\\ndeep tensor neural networks. In Proceedings of Interspeech . 2012c.\\n[422] D. Yu, L. Deng, and F. Seide. The deep tensor neural network with\\napplications to large vocabulary speech recognition. IEEE Transactions\\non Audio, Speech, and Language Processing , 21(2):388–396, 2013.\\n[423] D. Yu, J.-Y. Li, and L. Deng. Calibration of conﬁdence measures in\\nspeech recognition. IEEE Transactions on Audio, Speech and Language ,\\n19:2461–2473, 2010.\\n[424] D. Yu, F. Seide, G. Li, and L. Deng. Exploiting sparseness in deep\\nneural networks for large vocabulary speech recognition. In Proceedings\\nof International Conference on Acoustics Speech and Signal Processing\\n(ICASSP) . 2012.\\n[425] D. Yu and M. Seltzer. Improved bottleneck features using pre-trained\\ndeep neural networks. In Proceedings of Interspeech . 2011.\\n[426] D. Yu, M. Seltzer, J. Li, J.-T. Huang, and F. Seide. Feature learning in\\ndeep neural networks — studies on speech recognition. In Proceedings\\nof International Conference on Learning Representations (ICLR) . 2013.\\n[427] D. Yu, S. Siniscalchi, L. Deng, and C. Lee. Boosting attribute and\\nphone estimation accura cies with deep neural networks for detection-\\nbased speech recognition. In Proceedings of International Conference\\non Acoustics Speech and Signal Processing (ICASSP) . 2012.\\n[428] D. Yu, S. Wang, and L. Deng. Sequential labeling using deep-structured\\nconditional random ﬁelds. Journal of Selected Topics in Signal Process-\\ning, 4:965–973, 2010.\\n[429] D. Yu, S. Wang, Z. Karam, and L. Deng. Language recognition using\\ndeep-structured conditional random ﬁelds. In Proceedings of Interna-\\ntional Conference on Acoustics Speech and Signal Processing (ICASSP) ,\\npages 5030–5033. 2010.\\n[430] D. Yu, K. Yao, H. Su, G. Li, and F. Seide. KL-divergence regularized\\ndeep neural network adaptation for improved large vocabulary speech\\nrecognition. In Proceedings of International Conference on Acoustics\\nSpeech and Signal Processing (ICASSP) . 2013.\\n[431] K. Yu, M. Gales, and P. Woodland. Unsupervised adaptation with dis-\\ncriminative mapping transforms. IEEE Transactions on Audio, Speech,\\nand Language Processing , 17(4):714–723, 2009.\\n[432] K. Yu, Y. Lin, and H. Laﬀerty. Learning image representations from\\nthe pixel level via hierarchical sparse coding. In Proceedings Computer\\nVision and Pattern Recognition (CVPR) . 2011.\\nFull text available at: http://dx.doi.org/10.1561/2000000039 References 191\\n[433] F. Zamora-Martínez, M. Castro-Bleda, and S. España-Boquera. Fast\\nevaluation of connectionist language models. International Conference\\no nA r t i ﬁ c i a lN e u r a lN e t w o r k s , pages 144–151, 2009.\\n[434] M. Zeiler. Hierarchical convolutional deep learning in computer vision.\\nPh.D. Thesis, New York University, January 2014.\\n[435] M. Zeiler and R. Fergus. Stochastic pooling for regularization of deep\\nconvolutional neural networks. In Proceedings of International Confer-\\nence on Learning Representations (ICLR) . 2013.\\n[436] M. Zeiler and R. Fergus. Visualiz ing and understanding convolutional\\nnetworks. arXiv:1311.2901, pages 1–11, 2013.\\n[437] M. Zeiler, G. Taylor, and R. Fergus. Adaptive deconvolutional networks\\nfor mid and high level feature learning. In Proceedings of International\\nConference on Computer vision (ICCV) . 2011.\\n[438] H. Zen, M. Gales, J. F. Nankaku, and Y. K. Tokuda. Product of\\nexperts for statistical par ametric speech synthesis. IEEE Transactions\\non Audio, Speech, and Language Processing , 20(3):794–805, March 2012.\\n[439] H. Zen, Y. Nankaku, and K. Tokuda. Continuous stochastic feature\\nmapping based on trajectory HMMs. IEEE Transactions on Audio,\\nSpeech, and Language Processings , 19(2):417–430, February 2011.\\n[440] H. Zen, A. Senior, and M. Schuster. Statistical parametric speech syn-\\nthesis using deep neural networks. In Proceedings of International Con-\\nference on Acoustics Speech and Signal Processing (ICASSP) , pages\\n7962–7966. 2013.\\n[441] X. Zhang, J. Trmal, D. Povey, and S. Khudanpur. Improving deep\\nneural network acoustic models using generalized maxout networks. In\\nProceedings of International Conference on Acoustics Speech and Signal\\nProcessing (ICASSP) . 2014.\\n[442] X. Zhang and J. Wu. Deep belief networks based voice activity detec-\\ntion. IEEE Transactions on Audio, Speech, and Language Processing ,\\n21(4):697–710, 2013.\\n[443] Z. Zhang, Z. Liu, M. Sinclair, A. Acero, L. Deng, J. Droppo, X. Huang,\\nand Y. Zheng. Multi-sensory microphones for robust speech detection,enhancement and recognition. In Proceedings of International Confer-\\nence on Acoustics Speech and Signal Processing (ICASSP) . 2004.\\n[444] Y. Zhao and B. Juang. Nonlinear compensation using the gauss-newton\\nmethod for noise-robust speech recognition. IEEE Transactions on\\nAudio, Speech, and Language Processing , 20(8):2191–2206, 2012.\\nFull text available at: http://dx.doi.org/10.1561/2000000039 192 References\\n[445] W. Zou, R. Socher, D. Cer, and C. Manning. Bilingual word embed-\\ndings for phrase-based machine translation. In Proceedings of Empirical\\nMethods in Natural Language Processing (EMNLP) . 2013.\\n[446] G. Zweig and P. Nguyen. A segmental CRF approach to large vocab-\\nulary continuous speech recognition. In Proceedings of the Automatic\\nSpeech Recognition and Understanding Workshop (ASRU) . 2009.\\nFull text available at: http://dx.doi.org/10.1561/2000000039',\n",
       "  '48    IEEE COMPUTATIONAL INTELLIGENCE MAGAZINE | MAY 2014 1556-603X/14/$31.00©2014IEEENatural language processing (NLP) is a theory-motivated range of computational tech-niques for the automatic analysis and representation of human language. NLP research has evolved from the era of punch cards and batch processing (in which the analysis of a sentence could take up to 7 minutes) to the era of Google and the likes of it (in which millions of webpages can be processed in less than a second). This review paper draws on recent developments in NLP research to look at the past, pres-ent, and future of NLP technology in a new light. Borrowing the paradigm of ‘jumping curves’ from the field of  business management and marketing prediction, this survey article reinter-prets the evolution of NLP research as the intersection of three overlapping curves-namely Syntactics, Semantics, and Pragmatics Curves- which will eventually lead NLP research to evolve into natural language understanding.I. IntroductionBetween the birth of the Internet and2003, year of birth of social networkssuch as MySpace, Delicious, LinkedIn, and Facebook, there were just a fewdozen exabytes of information on theWeb. Today, that same amount of infor-mation is created weekly. The advent ofthe Social Web has provided peoplewith new content-sharing services thatallow them to create and share theirown contents, ideas, and opinions, in a time- and cost-efficient way, with virtu-ally millions of other people connected to the World Wide Web. This huge amount of information, however, is mainly unstructured (because it is spe-cifically produced for human consump-tion) and hence not directly machine-processable. The automatic analysis of text involves a deep understanding of natural language by machines, a reality from which we are still very far off.Hitherto, online information retrieval, aggregation, and processing have mainly been based on algorithms relying on the textual representation of web pages. Such algorithms are very good at retrieving texts, splitting them into parts, checking the spelling and counting the number of words. When it comes to interpreting sentences and extracting meaningful information,  however, their capabilities are known to be very limited. Natural language pro-cessing (NLP), in fact, requires high-level symbolic capabilities (Dyer, 1994), including:/uni274Fcreation and propagation of dynamicbindings;/uni274Fmanipulation of recursive, constitu-ent structures;/uni274Facquisition and access of lexical,semantic, and episodic memories;/uni274Fcontrol of multiple learning/process-ing modules and routing of informa-tion among such modules;/uni274Fgrounding of basic-level languageconstructs (e.g., objects and actions)in perceptual/motor experiences;/uni274Frepresentation of abstract concepts.All such capabilities are required toshift from mere NLP to what is usually referred to as natural language under-standing (Allen, 1987). T oday, most of the existing approaches are still based on the syntactic representation of text, a method that relies mainly on word co-occurrence frequencies. Such algorithms are limited by the fact that they can pro-cess only the information that they can ‘see’. As human text processors, we do not have such limitations as every word we see activates a cascade of semantically related concepts, relevant episodes, and sensory experiences, all of which enable the completion of complex NLP tasks—such as word-sense disam-biguation, textual entailment, and semantic role labeling—in a quick and effortless way.Computational models attempt to bridge such a cognitive gap by emulat-ing the way the human brain processes natural language, e.g., by leveraging on semantic features that are not explicitly expressed in text. Computational mod-els are useful both for scientific pur-poses (such as exploring the nature of linguistic communication), as well as for Jumping NLP Curves: A Review of Natural Language Processing Research\\nDigital Object Identifier 10.1109/MCI.2014.2307227Date of publication:11 April 2014Erik Cambria School of Computer Engineering, Nanyang Technological UniversityBebo White SLAC National Accelerator Laboratory, Stanford University\\n© BRAND X PICTURES    ArticleReview MAY 2014 | IEEE COMPUTATIONAL INTELLIGENCE MAGAZINE    49practical purposes (such as enabling effective human-machine communica-tion). Traditional research disciplines do not have the tools to completely address the problem of how language compre-hension and production work. Even if you combine all the approaches, a com-prehensive theory would be too com-plex to be studied using traditional methods. However, we may be able to realize such complex theories as com-puter programs and then test them by observing how well they perform. By seeing where they fail, we can incre-mentally improve them. Computational models may provide very specific pre-dictions about human behaviors that can then be explored by the psycholin-guist. By continuing this process, we may eventually acquire a deeper under-standing of how human language pro-cessing occurs. To realize such a dream will take the combined efforts of for-ward-thinking psycholinguists, neuro-scientists, anthropologists, philosophers, and computer scientists.Unlike previous surveys focusing on specific aspects or applications of NLP research (e.g., evaluation criteria (Jones & Galliers, 1995), knowledge-based sys-tems (Mahesh, Nirenburg, & Tucker, 1997), text retrieval (Jackson & Moulin-ier, 1997), and connectionist models (Christiansen & Chater, 1999)), this review paper focuses on the evolution of NLP research according to three differ-ent paradigms, namely: bag-of-words, word embeddings, and narrative understanding. Borrowing the concept of ‘jumping curves’ from the field of business management, this survey article explains how and why NLP research has been gradually shifting from lexical semantics to compositional semantics and offers insights on next-generation narrative-based NLP technology.The rest of the paper is organized as follows: Section 2 presents the historical background and the different schools of thought of NLP research; Section 3 discusses past, present,  and future evolution of NLP technologies; Section 4 describes traditional syntax-centered NLP methodologies; Section 5  illustrates emerging semantics-basedNLP approaches; Section 6 introduces pio-neering works on narrative understand-ing; Section 7 proposes further insights on the evolution of current NLP tech-nologies and suggests near future research directions; finally, Section 8 concludes the paper and outlines future areas of NLP research.2. BackgroundSince its inception in 1950s, NLPresearch has been focusing on tasks suchas machine translation, informationretrieval, text summarization, questionanswering, information extraction, topicmodeling, and more recently, opinionmining. Most NLP research carried outin the early days focused on syntax, partly because syntactic processing wasmanifestly necessary, and partly throughimplicit or explicit endorsement of theidea of syntax-driven processing.Although the semantic problems and needs of NLP were clear from the very beginning, the strategy adopted by the research community was to tackle syntax first, for the more direct applicability of machine learning techniques. However, there were some researchers who con-centrated on semantics because they saw it as the really challenging problem or assumed that semantically-driven pro-cessing be a better approach. Thus, Mas-terman’s and Ceccato’s groups, for exam-ple, exploited semantic pattern matching using semantic categories and semantic case frames, and in Ceccato’s work (Cec-cato, 1967) particularly, world knowledge was used to extend linguistic semantics, along with semantic networks as a device for knowledge representation. Later works recognized the need for external knowledge in interpreting and responding to language input (Minsky, 1968) and explicitly emphasized seman-tics in the form of general-purpose semantics with case structures for repre-sentation and semantically-driven pro-cessing (Schank, 1975).One of the most popular representa-tion strategies since then has been first order logic (FOL), a deductive system that consists of axioms and rules of infer-ences and can be used to formalize rela-tionally-rich predicates and quantifica-tion (Barwise, 1977). FOL supports syntactic, semantic and, to a certain degree, pragmatic expressions. Syntax specifies the way groups of symbols are to be arranged, so that the group of sym-bols is considered properly formed. Semantics specifies what well-formed expressions are supposed to mean. Prag-matics specifies how contextual informa-tion can be leveraged to provide better correlations between different semantics, which is essential for tasks such as word sense disambiguation. Logic, however, is known to have the problem of monoto-nicity. The set of entailed sentences will only increase as information is added to the knowledge base, but this runs the risk of violating a common property of human reasoning—the freedom and flexibility to change one’s mind. Solu-tions such as default and linear logic serve to address parts of these issues. Default logic is proposed by Raymond Reiter to formalize default assumptions, e.g., “all birds fly” (Reiter, 1980). How-ever, issues arise when default logic for-malizes facts that are true in the majority of cases but are false with regards to exceptions to these ‘general rules’, e.g., “penguins do not fly”.Another popular model for the description of natural language is pro-duction rule (Chomsky, 1956). A pro-duction rule system keeps a working memory of on-going memory assertions. This working memory is volatile and in turn keeps a set of production rules. A production rule comprises of an ante-cedent set of conditions and a conse-quent set of actions (i.e., IF <condi-tions> THEN <actions>). The basic operation for a production rule system involves a cycle of three steps (‘recog-nize’, ‘resolve conflict’, and ‘act’) that repeats until no more rules are applicable to the working memory. The step ‘recog-nize’ identifies the rules whose anteced-ent conditions are satisfied by the current working memory. The set of rules identi-fied is also called the conflict set. The step ‘resolve conflict’ looks into the con-flict set and selects a set of suitable rules to execute. The step ‘act’ simply executes the actions and updates the working memory. Production rules are modular.  50    IEEE COMPUTATIONAL INTELLIGENCE MAGAZINE | MAY 2014Each rule is independent from the oth-ers, allowing rules to be added and deleted easily. Production rule systems have a simple control structure and the rules are easily understood by humans. This is because rules are usually derived from the observation of expert behavior or expert knowledge, thus the terminol-ogy used in encoding the rules tends to resonate with human understanding. However, there are issues with scalability when production rule systems become larger; a significant amount of mainte-nance is required to maintain a system with thousands of rules.Another instance of a prominent NLP model is the ontology Web lan-guage (OWL) (McGuinness & Van Harmelen, 2004), an XML-based vocab-ulary that extends the resource descrip-tion framework (RDF) to provide a more comprehensive set for ontology representation, such as the definition of classes, relationships between classes, properties of classes, and constraints on relationships between classes and their properties. RDF supports the subject-predicate-object model that makes assertions about a resource. RDF-based reasoning engines have been developed to check for semantic consistency which then helps to improve ontology classifi-cation. In general, OWL requires the strict definition of static structures, and therefore is not suitable for representing knowledge that contains subjective degrees of confidence. Instead, it is more suited for representing declarative knowledge. Furthermore, yet another problem of OWL is that it does not allow for an easy representation of tem-poral-dependent knowledge.Networks are yet another well-known way to do NLP . For example, Bayesian networks (Pearl, 1985) (also known as belief networks) provide a means of expressing joint probability distributions over many interrelated hypotheses. All variables are represented using directed acyclic graph (DAG). Arcs are causal connections between two variables where the truth of the former directly affects the truth of the latter. A Bayesian network is able to represent subjective degrees of confidence. The representation explicitly explores the role of prior knowledge and combines pieces of evidence of the likelihood of events. In order to compute the joint distribution of the belief network, there is a need to know Pr(P|parents(P)) for each variable P. It is difficult to deter-mine the probability of each variable P in the belief network. Hence, it is also difficult to enhance and maintain the statistical table for large-scale informa-tion processing problems. Bayesian net-works also have limited expressiveness, which is only equivalent to the expres-siveness of proposition logic. For this reason, semantic networks are more often used in NLP research.A semantic network (Sowa, 1987) is a graphical notation for representing knowledge in patterns of interconnected nodes and arcs. Definitional networks focus on IsA relationships between a concept and a newly defined sub-type. The result of such a structure is called a generalization, which in turn supports the rule of inheritance for copying properties defined for a super-type to all of its sub-types. The information in defi-nitional networks is often assumed to be true. Y et another kind of semantic net-works is the assertional network, which is meant to assert propositions and the information it contains is assumed to be contingently true. Contingent truth is not reached with the application of default logic; instead, it is based more on Man’s application of common-sense. The proposition also has sufficient rea-son in which the reason entails the proposition, e.g., “the stone is warm” with the sufficient reasons being “the sun is shining on the stone” and “what-ever the sun shines on is warm”.The idea of semantic networks arose in the early 1960s from Simmons (Sim-mons, 1963) and Quillian (Quillian, 1963) and was further developed in the late 1980s by Marvin Minsky within his Society of Mind theory (Minsky, 1986), according to which the magic of human intelligence stems from our vast diversity—and not from any single, per-fect principle. Minsky theorized that the mind is made of many little parts that he termed ‘agents’, each mindless by itself but able to lead to true intelligence when working together. These groups of agents, or ‘agencies’, are responsible for performing some type of function, such as remembering, comparing, gen-eralizing, exemplifying, analogizing, sim-plifying, predicting, etc. Minsky’s theory of human cognition, in particular, was welcomed with great enthusiasm by the artificial intelligence (AI) community and gave birth to many attempts to build common-sense knowledge bases for NLP tasks. The most representative projects are: (a) Cyc (Lenat & Guha, 1989), Doug Lenat’s logic-based reposi-tory of common-sense knowledge; (b) WordNet (Fellbaum, 1998), Christiane Fellbaum’s universal database of word senses; (c) Thought-Treasure (Mueller, 1998), Erik Mueller’s story understand-ing system; and (d) the Open Mind Common Sense project (Singh, 2002), a second-generation common-sense data-base. The last project stands out because knowledge is represented in natural  TABLE 1 Most popular schools of thought in knowledge representation and NLP research.APPROACHCHARACTERISTIC FEATURESREFERENCEPRODUCTION RULE CYCLES OF `RECOGNIZE’, `RESOLVE CONFLICT’, `ACT’ STEPS(CHOMSKY, 1956)SEMANTIC PATTERN MATCHINGSEMANTIC CATEGORIES AND SEMANTIC CASE FRAMES(CECCATO, 1967)FIRST ORDER LOGIC (FOL)AXIOMS AND RULES OF INFERENCES(BARWISE, 1977)BAYESIAN NETWORKS VARIABLES REPRESENTED BY A PROBABILIS-TIC DIRECTED ACYCLIC GRAPH(PEARL, 1985)SEMANTIC NETWORKSPATTERNS OF INTERCONNECTED NODES AND ARCS(SOWA, 1987)ONTOLOGY WEB LANGUAGE (OWL)HIERARCHICAL CLASSES AND RELATION-SHIPS BETWEEN THEM(MCGUINNESS & VAN HARMELEN, 2004) MAY 2014 | IEEE COMPUTAT IONAL INTELLIGENCE MAGAZ INE    51language (rather than being based upon \\na formal logical structure), and informa-tion is not hand-crafted by expert engi-neers but spontaneously inserted by online volunteers. T oday, the common-sense knowledge collected by the Open Mind Common Sense project is being exploited for many different NLP tasks such as textual affect sensing (H. Liu, Lieberman, & Selker, 2003), casual con-versation understanding (Eagle, Singh, & Pentland, 2003), opinion mining (Cam -\\nbria & Hussain, 2012), story telling (Hayden et al., 2013), and more.\\n3. Overlapping NLP Curves\\nWith the dawn of the Internet Age, civilization has undergone profound, rapid-fire changes that we are experi-encing more than ever today. Eventechnologies that are adapting, growing, and innovating have the gnawing sensethat obsolescence is right around thecorner. NLP research, in particular, hasnot evolved at the same pace as othertechnologies in the past 15 years.\\nWhile NLP research has made great \\nstrides in producing artificially intelli -\\ngent behaviors, e.g., Google, IBM’s Wat-son, and Apple’s Siri, none of such NLP frameworks actually understand what they are doing—making them no differ-ent from a parrot that learns to repeat words without any clear understanding of what it is saying. T oday, even the most popular NLP technologies view text analysis as a word or pattern matching task. Trying to ascertain the meaning of a piece of text by processing it at word-level, however, is no different from attempting to understand a picture by analyzing it at pixel-level.\\nIn a Web where user-generated con-\\ntent (UGC) is drowning in its own out-put, NLP researchers are faced with the same challenge: the need to jump the curve (Imparato & Harari, 1996) to make significant, discontinuous leaps in their thinking, whether it is about information retrieval, aggregation, or processing. Relying on arbitrary key-words, punctuation, and word co-occurrence frequencies has worked fairly well so far, but the explosion of UGCs and the outbreak of deceptive phenomena such as web-trolling and opinion spam, are causing standard NLP algorithms to be increasing less efficient. In order to properly extract and manip-ulate text meanings, a NLP system must have access to a significant amount of knowledge about the world and the domain of discourse.\\nTo this end, NLP systems will \\ngradually stop relying too much on word-based techniques while starting to exploit semantics more consistently and, hence, make a leap from the  Syntactics Curve to the Semantics Curve (Figure /uni00A01). NLP research has \\nbeen interspersed with word-level approaches because, at first glance, the most basic unit of linguistic structure appears to be the word. Single-word expressions, however, are just a subset of concepts, multi-word expressions that carry specific semantics and sentics  \\n(Cambria & Hussain, 2012), that is, the denotative and connotative informa-tion commonly associated with real-world objects, actions, events, and people. Sentics, in particular, specifies the affective information associated with such real-world entities, which is key for common-sense reasoning and decision-making.\\nSemantics and sentics include com-\\nmon-sense knowledge (which humans normally acquire during the formative years of their lives) and common knowl -edge (which people continue to accrue in their everyday life) in a re-usable knowledge base for machines. Common knowledge includes general knowledge about the world, e.g., a chair is a type of \\nfurniture, while common-sense knowl -\\nedge comprises obvious or widely accepted things that people normally know about the world but which are usually left unstated in discourse, e.g., that things fall downwards (and not upwards) a n d  people smile when they are happy. The difference between common and common-sense knowledge can be expressed as the difference between knowing the name of an object and understanding the same object’s purpose. For example, you can know the name of all the different kinds or brands of ‘pipe’, but not its purpose nor the method of usage. In other words, a ‘pipe’ is not a pipe unless it can be used (Magritte, 1929) (Figure 2 ).\\nIt is through the combined use of \\ncommon and common-sense knowl -\\nedge that we can have a grip on both high- and low-level concepts as well as nuances in natural language understand -\\ning and therefore effectively communi-cate with other people without having to continuously ask for definitions and explanations. Common-sense, in partic-ular, is key in properly deconstructing natural language text into sentiments according to different contexts—for \\nFIGURE 1 Envisioned evolution of NL P research through three different eras or curves.\\nNLP System PerformanceBest Path\\n1930                      1970 2010 2050Syntactics Curve\\n(Bag-of-Words Model)Semantics Curve\\n(Word Embeddings)Pragmatics Curve\\n(Narrative Understanding)\\n Time 52    IEEE COMPUTATIONAL INTELLIGENCE MAGAZINE | MAY 2014example, in appraising the concept ‘small room’ as negative for a hotel review and ‘small queue’ as positive for a post office, or the concept ‘go read the book’ as positive for a book review but negative for a movie review.Semantics, however, is just one layer up in the scale that separates NLP from natural language understanding. In order to achieve the ability to accu-rately and sensibly process information, computational models will also need to be able to project semantics and sentics in time, compare them in a parallel and dynamic way, according to different contexts and with respect to different actors and their intentions (Howard & Cambria, 2013). This will mean jump-ing from the Semantics Curve to the Pragmatics Curve, which will enable NLP to be more adaptive and, hence, open-domain, context-aware, and intent-driven. Intent, in particular, will be key for tasks such as sentiment anal-ysis—a concept that generally has a negative connotation, e.g., small seat, might turn out to be positive, e.g., if the intent is for an infant to be safely seated in it.While the paradigm of the Syntac-tics Curve is the bag-of-words model (Zellig, 1954) and the Semantics Curve is characterized by a concept-level model (Cambria & Hussain, 2012), the paradigm of the Pragmatics Curve will be the narrative understanding model. In this last model, each piece of text will be represented by mini-stories or interconnected episodes, leading to a more detailed level of text comprehension and sensible computa-tion. While the concept-level model helps to overcome problems such as word-sense disambiguation and semantic role labeling, the narrativeunderstanding model will enable tackling NLP issues such as co-reference resolution and textual entailment.4.Poising on the Syntactics CurveToday, syntax-centered NLP is still themost popular way to manage tasks suchas information retrieval and extraction,auto-categorization, topic modeling,etc. Despite semantics enthusiasts hav-ing argued the importance and inevita-bility of a shift away from syntax for years, the vast majority of NLP researchers nowadays are still trying to keep their balance on the Syntactics Curve. Syntax-centered NLP can be broadly grouped into three main cate-gories: keyword spotting, lexical affinity, and statistical methods.4.1. Keyword SpottingKeyword Spotting is the most naïve approach and probably also the most popular because of its accessibility and economy. T ext is classified into catego-ries based on the presence of fairly unambiguous words. Popular projects include: (a) Ortony’s Affective Lexicon (Ortony, Clore, & Collins, 1988), which groups words into affective categories; (b) Penn Treebank (Marcus, Santorini, &Marcinkiewicz, 1994), a corpus consist-ing of over 4.5 million words of Ameri-can English annotated for part-of-speech (POS) information; (c)PageRank (Page, Brin, Motwani, &Winograd, 1999), the famous rankingalgorithm of Google; (d) LexRank(G/Udieresis.scnes & Radev, 2004), a stochasticgraph-based method for computing rel-ative importance of textual units forNLP; finally, (e) T extRank (Mihalcea &Tarau, 2004), a g raph-based rankingmodel for text processing, based on twounsupervised methods for keyword andsentence extraction. The major weaknessof keyword spotting lies in its relianceupon the presence of obvious wordswhich are only surface features of theprose. A text document about dogswhere the word ‘dog’ is never men-tioned, e.g., because dogs are addressedaccording to the specific breeds theybelong to, might never be retrieved by a keyword-based search engine.4.2. Lexical AffinityLexical Affinity is slightly more sophisti-cated than keyword spotting as, rather than simply detecting obvious words, it assigns to arbitrary words a probabilistic ‘affinity’ for a particular category (Bush, 1999; Bybee & Scheibman, 1999; Krug, 1998; Church & Hanks, 1989; Jurafsky et al., 2000). For example, ‘accident’ might be assigned a 75% probability of indicating a negative event, as in ‘car accident’ or ‘hurt in an accident’. These probabilities are usually gleaned from linguistic corpora (Kucera & Francis, 1969; Godfrey, Holliman, & McDaniel, 1992; Stevenson, Mikels, & James, 2007). Although this approach often outper-forms pure keyword spotting, there are two main problems with it. First, lexical affinity operating solely on the word-level can easily be tricked by sentences such as “I avoided an accident” (nega-tion) and “I met my girlfriend by acci-dent” (connotation of unplanned but lovely surprise). Second, lexical affinity probabilities are often biased toward text of a particular genre, dictated by the source of the linguistic corpora. This makes it difficult to develop a re-usable, domain-independent model.4.3. Statistical NLPStatistical NLP has been the mainstream NLP research direction since late 1990s. It relies on language models (Manning & Sch/Udieresis.sctze, 1999; Hofmann, 1999;  Nigam, McCallum, Thrun, & Mitchell, 2000) based on popular machine-learn-ing algorithms such as maximum-likeli-hood (Berger, Della Pietra, & Della Pietra, 1996), expectation maximization (Nigam et al., 2000), conditional ran-dom fields (Lafferty, McCallum, & Pereira, 2001), and support vector machines (Joachims, 2002). By feeding a large training corpus of annotated texts to a machine-learning algorithm, it is possible for the system to not only learn the valence of keywords (as in the key-word spotting approach), but also to take into account the valence of other arbi-trary keywords (like lexical affinity), FIGURE 2 A ‘pipe’ is not a pipe, unless we know how to use it.\\n MAY 2014 | IEEE COMPUTATIONAL INTELLIGENCE MAGAZINE    53punctuation, and word co-occurrence frequencies. However, statistical methods are generally semantically weak, mean-ing that, with the exception of obvious keywords, other lexical or co-occur-rence elements in a statistical model have little predictive value individually. As a result, statistical text classifiers only work with acceptable accuracy when given a sufficiently large text input. So, while these methods may be able to classify text on the page- or paragraph-level, they do not work well on smaller text units such as sentences or clauses.5. Surfing the Semantics CurveSemantics-based NLP focuses on theintrinsic meaning associated with natu-ral language text. Rather than simplyprocessing documents at syntax-level, semantics-based approaches rely onimplicit denotative features associatedwith natural language text, hence step-ping away from the blind usage of key-words and word co-occurrence count. Unlike purely syntactical techniques, concept-based approaches are also ableto detect semantics that are expressedin a subtle manner, e.g., through theanalysis of concepts that do not explic-itly convey relevant information, butwhich are implicitly linked to otherconcepts that do so. Semantics-basedNLP approaches can be broadlygrouped into two main categories:techniques that leverage on externalknowledge, e.g., ontologies (taxonomicNLP) or semantic knowledge bases(noetic NLP), and methods that exploitonly intrinsic semantics of documents(endogenous NLP).5.1. Endogenous NLPEndogenous NLP involves the use of machine-learning techniques to per-form semantic analysis of a corpus by building structures that approximate concepts from a large set of documents. It does not involve prior semantic understanding of documents; instead, it relies only on the endogenous knowl-edge of these (rather than on external knowledge bases). The advantages of this approach over the knowledge engineer-ing approach are effectiveness, consider-able savings in terms of expert man-power, and straightforward portability to different domains (Sebastiani, 2002).Endogenous NLP includes methods based either on lexical semantics, which focuses on the meanings of individual words, or compositional semantics, which looks at the meanings of sen-tences and longer utterances. The vast major ity of endogenous NLP approaches is based on lexical semantics and includes well-known machine-learning techniques. Some examples of this are: (a) latent semantic analysis (Hofmann, 2001), where documents are represented as vectors in a term space; (b) latent Dirichlet allocation (Porteouset al., 2008), which involves attributingdocument terms to topics; (c) MapRe-duce (C. Liu, Qi, Wang, & Y u, 2012), aframework that has proved to be veryefficient for data-intensive tasks, e.g., large scale RDFS/OWL reasoning and(d) genetic algorithms (D. Goldberg, 1989), probabilistic search proceduresdesigned to work on large spacesinvolving states that can be representedby strings.Works leveraging on compositional semantics, instead, mainly include approaches based on Hidden Markov Models (Denoyer, Zaragoza, & Gallinari, 2001; Frasconi, Soda, & Vullo, 2001), association rule learning (Cohen, 1995; Cohen & Singer, 1999), feature ensem-bles (Xia, Zong, Hu, & Cambria, 2013; Poria, Gelbukh, Hussain, Das, & Ban-dyopadhyay, 2013) and probabilistic gen-erative models (Lau, Xia, & Y e, 2014).5.2. Taxonomic NLPTaxonomic NLP includes initiatives that aim to build universal taxonomies or Web ontologies for grasping the sub-sumptive or hierarchical semantics asso-ciated with natural language expres-sions. Such taxonomies usually consist of concepts (e.g., painter), instances (e.g., “Leonardo da Vinci”), attributes and values (e.g., “Leonardo’s birthday is April 15, 1452”), and relationships (e.g., “Mona Lisa is painted by Leonardo”). In particular, subsumptive knowledge representations build upon IsA r e l a-tionships, which are usually extracted through syntactic patterns for auto-matic hypernym discovery (Hearst,  1992) able to infer triples such as <Pablo Picasso-IsA-artist> from stretches of text like “...artists such as Pablo Picasso...” or “...Pablo Picasso and other artists...”.In general, attempts to build taxo-nomic resources are countless and include both resources crafted by human experts or community efforts, such as WordNet and Freebase (Bol-lacker, Evans, Paritosh, Sturge, & Taylor, 2008), and automatically built knowl-edge bases. Examples of such knowl-edge bases include: (a) WikiTaxonomy (Ponzetto & Strube, 2007), a taxonomy extracted from Wikipedia’s category links; (b) YAGO (Suchanek, Kasneci, & Weikum, 2007), a semantic knowledge base derived from WordNet, Wikipedia, and GeoNames; (c) NELL (Carlson et al., 2010) (Never-Ending Language Learning), a semantic machine-learning system that is acquiring knowledge from the Web every day; finally, (d) Pro-base (Wu, Li, Wang, & Zhu, 2012), a research prototype that aims to build a unified taxonomy of worldly facts from 1.68 billion webpages in Bing repository.Other popular Semantic Web proj-ects include: (a) SHOE (Heflin & Hen-dler, 1999) (Simple HTML Ontology Extensions), a knowledge representa-tion language that allows webpages to be annotated with semantics; (b) Annotea (Kahan, 2002), an open RDF infrastructure for shared Web annota-tions; (c) SIOC (Breslin, Harth, Bojars, & Decker, 2005) (Semantically Inter-linked Online Communities), an ontol-ogy combining terms from vocabular-ies that already exist with new terms needed to describe the relationships between concepts in the realm of online community sites; (d) SKOS (Miles & Bechhofer, 2009) (Simple Knowledge Organization System), an area of work developing specifications and standards to support the use of knowledge organization systems such as thesauri, classification schemes, sub-ject heading lists and taxonomies; (e) FOAF (Brickley & Miller, 2010) (Friend Of A Friend), a project devoted  54    IEEE COMPUTATIONAL INTELLIGENCE MAGAZINE | MAY 2014to linking people and information using the Web; (f  ) ISOS (Ding, Jin, Ren, & Hao, 2013) (Intelligent Self-Organizing Scheme), a scheme for the Internet of Things inspired by the endocrine regulating mechanism;  finally, (g) FRED (Gangemi, Presutti, & Reforgiato, 2014), a tool that produces an event-based RDF/OWL representa-tion of natural language text. The main weakness of taxonomic NLP is in the typicality of their knowledge bases. The way knowledge is represented in tax-onomies and Web ontologies is usually strictly defined and does not allow for the combined handling of differing nuanced concepts, as the inference of semantic features associated with con-cepts is bound by the fixed, flat repre-sentation. The concept of ‘book’, for example, is typically associated to con-cepts such as ‘newspaper’ or ‘magazine’, as it contains knowledge, has pages, etc. In a different context, however, a book could be used as paperweight, doorstop, or even as a weapon. Another key weakness of Semantic Web projects is that they are not easily scalable and, hence, not widely adopted (Gueret, Schlobach, Dentler, Schut, & Eiben, 2012). This increases the amount of time that has to pass before the initial customer feedback is even possible, and also slows down feedback loop itera-tions, ultimately putting Semantic Web applications at a user-experience and agility disadvantage as compared to their Web 2.0 counterparts, because their usability inadvertently takes a back seat to the number of other com-plex problems that have to be solved before clients even see the application.5.3. Noetic NLPNoetic NLP embraces all the mind-inspired approaches to NLP that attempt to compensate for the lack of domain adaptivity and implicit seman-tic feature inference of traditional algo-rithms, e.g., first principles modeling or explicit statistical modeling. Noetic NLP differs from taxonomic NLP in which it does not focus on encoding subsumption knowledge, but rather attempts to collect idiosyncratic knowl-edge about objects, actions, events, and people. Noetic NLP , moreover, per-forms reasoning in an adaptive and dynamic way, e.g., by generating con-text-dependent results or by discover-ing new semantic patterns that are not explicitly encoded in the knowledge base. Examples of noetic NLP include paradigms such as connectionist NLP (Christiansen & Chater, 1999), which models mental phenomena as emergent processes of interconnected networks of simple units, e.g., neural networks (Collobert et al., 2011); deep learning (Martinez, Bengio, & Yannakakis, 2013); sentic computing (Cambria & Hussain, 2012), an approach to concept-level sentiment analysis based on an ensem-ble of graph-mining and dimensional-ity-reduction techniques; and energy-based knowledge representation (Olsher, 2013), a novel framework for nuanced common-sense reasoning.Besides knowledge representation and reasoning, a key aspect of noetic NLP is also semantic parsing. Most cur-rent NLP technologies rely on part-of-speech (POS) tagging, but that is unlike the way the human mind extracts meaning from text. Instead, just as the human mind does, a construction-based semantic parser (CBSP) (Cambria, Raja-gopal, Olsher, & Das, 2013) quickly identifies meaningful stretches of text without requiring time-consuming phrase structure analysis. The use of con-structions, defined as “stored pairings of form and function” (A. Goldberg, 2003) makes it possible to link distributed lin-guistic components to one another, eas-ing extraction of semantics from linguis-tic structures. Constructions are composed of fixed lexical items and cat-egory-based slots, or ‘spaces’ that are filled in by lexical items during text pro-cessing. An interesting example from the relevant literature would be the con-struction [<ACTION> <OBJECT> <DIRECTION> <OBJECT>].  Instances of this include the phrases ‘sneeze the napkin across the table’ or ‘hit the ball over the fence’. Construc-tions not only help understand how var-ious lexical items work together to cre-ate the whole meaning, but also give the parser a sense of what categories of words are used together and thus where to expect different words.CBSP uses this knowledge to deter-mine constructions, their matching lexi-cal terms, and how good each match is. Each of CBSP’s constructions contrib-utes its own unique semantics and car-ries a unique name. In order to choose the best possible construction for each span of text, CBSP uses knowledge about the lexical items found in text. This knowledge is obtained from look-ing individual lexical terms up in the knowledge bases so as to obtain infor-mation about the basic category mem-bership of that word.It then efficiently compares these potential memberships with the catego-ries specified for each construction in the corpus, finding the best matches so that CBSP can extract a concept from a sentence. An example would be the extraction of the concept ‘buy christmas present’ from the sentence “today I bought a lot of very nice Christmas gifts”. Constructions are typically nested within one another: CBSP is capable of finding only those construction overlaps that are semantically sensible, based on the overall semantics of constructions and construction slot categories, thus greatly reducing the time taken to pro-cess large numbers of texts. In the big data environment, a key benefit of con-struction-based parsing is that only small sections of text are required in order to extract meaning; word category infor-mation and the generally small size of constructions mean that the parser can still make use of error-filled or conven-tionally unparseable text.6. Foreseeing the Pragmatics CurveNarrative understanding and generationare central for reasoning, decision-mak-ing, and ‘sensemaking’. Besides being akey part of human-to-human commu-nication, narratives are the means bywhich reality is constructed and plan-ning is conducted. Decoding how nar-ratives are generated and processed bythe human brain might eventually leadus to truly understand and explainhuman intelligence and consciousness. MAY 2014 | IEEE COMPUTATIONAL INTELLIGENCE MAGAZINE    55Computational modeling is a pow-erful and effective way to investigate narrative understanding. A lot of the cognitive processes that lead humans to understand or generate narratives have traditionally been of interest to AI researchers under the umbrella of knowledge representation, common-sense reasoning, social cognition, learn-ing, and NLP . Once NLP research can grasp semantics at a level comparable to human text processing, the jump to the Pragmatics Curve will be necessary, in the same way as semantic machine learning is now gradually evolving from lexical to compositional semantics.  There are already a few pioneering works that attempt to understand narra-tives by leveraging on discourse struc-ture (Asher & Lascarides, 2003), argu-ment-support hierarchies (Bex,  Prakken, & Verheij, 2007), plan graphs (Y oung, 2007), and common-sense rea-soning (Mueller, 2007). One of the most representative initiatives in this context is Patrick Winston’s work on computational models of narrative (Winston, 2011; Richards, Finlayson, & Winston, 2009), which is based on five key hypotheses:/uni274FThe inner language hypothesis: wehave an inner symbolic language thatenables event description./uni274FThe strong story hypothesis: we canassemble event descriptions into stories./uni274FThe directed perception hypothesis: we can direct the resources of our per-ceptual faculties to answer questionsusing real and imagined situations./uni274FThe social animal hypothesis: wehave a powerful reason to express thethought in our inner language in anexternal communication language./uni274FThe exotic engineering hypothesis: our brains are unlike standard left-to-right engineered systems.Essentially, Patrick Winston believesthat human intelligence stems from our unique abilities for storytelling and understanding (Finlayson & Winston, 2011). Accordingly, his recent work has focused on developing a computational system that is able to analyze narrative texts to infer non-obvious answers to questions about these texts. This has resulted in the Genesis System. Work-ing with short story summaries pro-vided in English, together with low-level common-sense rules and higher-level reflection patterns that are also expressed in English, Genesis has been successful in demonstrating sev-eral story understanding capabilities. One instance of this is its ability to determine that both Macbeth and the 2007 Russia-Estonia Cyberwar involve revenge, even though neither the word ‘revenge’ nor any of its synonyms are mentioned in accounts describing those texts.7. DiscussionWord- and concept-level approaches toNLP are just a first step towards naturallanguage understanding. The future ofNLP lies in biologically and linguistical-ly motivated computational paradigmsthat enable narrative understanding and, hence, ‘sensemaking’. Computational in-telligence potentially has a large futurepossibility to play an important role inNLP research. Fuzzy logic, for example, has a direct relation to NLP (Carvalho, Batista, & Coheur, 2012) for tasks suchas sentiment analysis (Subasic &Huettner, 2001), linguistic summariza-tion (Kacprzyk & Zadrozny, 2010),knowledge representation (Lai, Wu, Lin, & Huang, 2011), and word meaning in-ference (Kazemzadeh, Lee, & Narayanan, 2013). Artificial neural networks can aidthe completion of NLP tasks such asambiguity resolution (Chan & Franklin, 1998; Costa, Frasconi, Lombardo, &Soda, 2005), grammatical inference(Lawrence, Giles, & Fong, 2000), wordrepresentation (Luong, Socher, & Man-ning, 2013), and emotion recognition(Cambria, Gastaldo, Bisio, & Zunino, 2014). Evolutionary computation can beexploited for tasks such as grammaticalevolution (O’Neill & Ryan, 2001), knowledge discovery (Atkinson-Abutridy, Mellish, & Aitken, 2003), textcategorization (Araujo, 2004), and rulelearning (Ghandar, Michalewicz,Schmidt, T o, & Zurbruegg, 2009).Despite its potential, however, the use of computational intelligence tech-niques till date has not been so active in the field of NLP . The first reason is that NLP is a huge field currently tack-ling dozens of different problems for which specific evaluation metrics exist, and it is not possible to reduce the whole field into a specific problem, as it was done in early works (Novak, 1992). The second reason may be that power-ful techniques such as support vector machines (Drucker, Wu, & Vapnik,  1999), kernel principal component analysis (Schölkopf et al., 1999), and la-tent Dirichlet allocation (Mukherjee & Blei, 2009) have achieved remarkable results on widely used NLP datasets, which are not yet met by computation-al intelligence techniques. All such word-based algorithms, however, are limited by the fact that they can process only the information that they can ‘see’ and, hence, will sooner or later reach saturation. Computational intelligence techniques, instead, can go beyond the syntactic representation of documents by emulating the way the human brain processes natural language (e.g., by le-veraging on semantic features that are not explicitly expressed in text) and, hence, have higher potential to tackle complementary NLP tasks. An ensem-ble of computational intelligence tech-niques, for example, could be exploited within the same NLP model for on-line learning of natural language con-cepts (through neural networks),  concept classification and semantic fea-ture generalization (through fuzzy sets), and concept meaning evolution and continuous system optimization (through evolutionary computation).8. ConclusionIn a Web where user-generated contenthas already hit critical mass, the need forsensible computation and informationaggregation is increasing exponentially, as demonstrated by the ‘mad rush’ in theindustry for ‘big data experts’ and thegrowth of a new ‘Data Science’ disci-pline. The democratization of onlinecontent creation has led to the increaseof  W e b  d e b r i s ,  w h i c h  i s  i n e v i t a b l y  a n dnegatively affecting information retrievaland extraction. T o analyze this negativetrend and propose possible solutions, this review paper focused on the evolution of NLP research according to three dif-ferent paradigms, namely: bag-of-words, word embeddings, and narrative understanding. Borrowingthe concept of ‘jumping curves’ from the field of business management, this survey article explained how and why NLP research is gradually shifting from lexical semantics to compositional semantics and offered insights on next-generation narrative-based NLP technology. Jumping the curve, however, is not an easy task: the origins of human lan-guage has sometimes been called the hardest problem of science (Christiansen & Kirby, 2003). NLP technologies evolved from the era of punch cards and batch processing (in which the analysis of a natural language sentence could take up to 7 minutes (Plath, 1967)) to the era of Google and the likes of it (in which millions of webpages can be pro-cessed in less than a second). Even the most efficient word-based algorithms, however, perform very poorly, if not properly trained or when contexts and domains change. Such algorithms are limited by the fact that they can process only information that they can ‘see’. Language, however, is a system where all terms are interdependent and where the value of one is the result of the simulta-neous presence of the others (De Sau-ssure, 1916). As human text processors, we ‘see more than what we see’ (David-son, 1997) in which every word acti-vates a cascade of semantically-related concepts that enable the completion of complex NLP tasks, such as word-sense disambiguation, textual entailment, and semantic role labeling, in a quick and effortless way.Concepts are the glue that holds our mental world together (Murphy, 2004). Without concepts, there would be no mental world in the first place (Bloom, 2003). Needless to say, the ability to organize knowledge into concepts is one of the defining characteristics of the human mind. A truly intelligent system needs physical, social  and sensory knowledge56    IEEE COMPUTATIONAL INTELLIGENCE MAGA ZINE | MAY 2014 about the way people think. Having a database of millions of common-sense facts, however, is not enough for   computational natural language understanding: we will need to teach NLP systems how to handle this knowledge (IQ), but also interpret emotions (EQ) and cultural nuances (CQ).References[1] J. Allen. Natural Language Understanding. Redwood City, CA: Benjamin/Cummings, 1987.[2] L. Araujo, “Symbiosis of evolutionary techniques and statistical natural language processing,” IEEE Trans. Evol. Comput., vol. 8, no. 1, pp. 14–27, 2004.[3]N. Asher and A. Lascarides, Logics of Conversation. Cambridge, U.K.: Cambridge Univ. Press, 2003.[4] J. Atkinson-Abutridy, C. Mellish, and S. Aitken, “A semantically guided and domain independent evolution-ary model for knowledge discovery from texts,” IEEE Trans. Evol. Comput., vol. 7, no. 6, pp. 546–560, 2003.[5] J. Barwise, “An introduction to first-order logic,” in Handbook of Mathematical Logic. (Studies in Logic and the Foundations of Mathematics). Amsterdam, The Nether-lands: North-Holland, 1977.[6] A. Berger, V. D. Pietra, and S. D. Pietra, “A maximum entropy approach to natural language processing,” Com-put. Linguistics, vol. 22, no. 1, pp. 39–71, 1996.[7] F. Bex, H. Prakken, and B. Verheij, “Formalizing argumentative story-based analysis of evidence,” in Proc. Int. Conf. Artificial Intelligence Law, 2007, pp. 1-10.[8] P. Bloom, “Glue for the mental world,” Nature, vol. 421, pp. 212–213, Jan. 2003.[9] K. Bollacker, C. Evans, P. Paritosh, T. Sturge, and J. Taylor, “Freebase: A collaboratively created graph database for structuring human knowledge,” in Proc. ACM SIG-MOD Int. Conf. Management Data, 2008, pp. 1247–1250.[10] J. Breslin, A. Harth, U. Bojars, and S. Decker, “To-wards semantically-interlinked online communities,” in The Semantic Web: Research and Applications. Berlin Hei-delberg: Springer-Verlag, 2005, pp. 500–514.[11] D. Brickley and L. Miller. (2010). FOAF vocabu-lary specification 0.98. Namespace Document [Online]. Available: http://xmlns.com/foaf/spec/[12] N. Bush, “The predictive value of transitional prob-ability for word-boundary palatalization in English,” Unpublished M.S .thesis, Univ. New Mexico, Albuquer-que, NM, 1999.[13]J. Bybee and J. Scheibman, “The effect of usage on degrees of constituency: The reduction of don’t in Eng-lish,” Linguistics, vol. 37, no. 4, pp. 575–596, 1999.[14]E. Cambria, P. Gastaldo, F. Bisio, and R. Zunino, “An ELM-based model for affective analogical reason-ing,” Neurocomputing, Special Issue on Extreme Learning Machines, 2014.[15] E. Cambria and A. Hussain, Sentic Computing: Tech-niques, Tools, and Applications. Dordrecht, The Nether-lands: Springer-Verlag, 2012.[16] E. Cambria, D. Rajagopal, D. Olsher, and D. Das, “Big social data analysis,” in Big Data Computing, R. Akerkar, Ed. London: Chapman and Hall, 2013, pp. 401–414.[17]A. Carlson, J. Betteridge, B. Kisiel, B. Settles, E. Hruschka, and T. Mitchell, “Toward an architecture for never-ending language learning,” in Proc. Conf. Artificial Intelligence AAAI, Atlanta, GA, 2010, pp. 1306–1313.[18]J. Carvalho, F. Batista, and L. Coheur, “A critical survey on the use of fuzzy sets in speech and natural lan-guage processing,” in Proc. IEEE Int. Conf. Fuzzy Systems, 2012, pp. 270–277.[19]S. Ceccato, “Correlational analysis and mechani-cal translation,” in Machine Translation, A. D. Booth, Ed. Amsterdam, The Netherlands: North Holland, 1967, pp. 77–135.[20]S. Chan and J. Franklin, “Symbolic connectionism in natural language disambiguation,” IEEE Trans. Neural Netw., vol. 9, no. 5, pp. 739–755, 1998.[21]N. Chomsky, “Three models for the description of language,” IRE Trans. Inform. Theory, vol. 2, no. 3, pp. 113–124, 1956.[22]M. Christiansen and N. Chater, “Connectionist natural language processing: The state of the art,” Cogn. Sci., vol. 23, no. 4, pp. 417–437, 1999.[23] M. Christiansen and S. Kirby, “Language evolution: The hardest problem in science?” in Language Evolution, M. Christiansen and S. Kirby, Eds. Oxford, U.K.: Oxford Univ. Press, 2003. pp. 1–15.[24] K. Church an d  P. Hanks, “Word association norms, mutual information, and lexicography,” in Proc. 27th Annu. Meeting Association Computational Linguistics, 1989, pp. 76–83.[25] W. Cohen, “Learning to classify English text with ILP methods,” in Advances in Inductive Logic Programming, L. De Raedt, Ed. Amsterdam, The Netherlands: IOS Press, 1995, pp. 124–143.[26]W. Cohen and Y. Singer, “Context-sensitive learn-ing methods for text categorization,” ACM Trans. Inform. Syst., vol. 17, no. 2, pp. 141–173, 1999.[27]R. Collobert, J. Weston, L. Bottou, M. Karlen, K. Kavukcuoglu, and P. Kuksa, “Natural language process-ing (almost) from scratch,” J. Mach. Learn. Res., vol. 12, pp. 2493–2537, 2011.[28] F. Costa, P. Frasconi, V. Lombardo, P. Sturt, and G. Soda, “Ambiguity resolution analysis in incremental pars-ing of natural language,” IEEE Trans. Neural Netw., vol. 16, no. 4, pp. 959–971, 2005.[29] D. Davidson, “Seeing through language,” in Royal Institute of Philosophy, Supplement. Cambridge, U.K.: Cambridge Univ. Press, 1997, vol. 42 , pp. 15–28.[30] L. Denoyer, H. Zaragoza, and P. Gallinari, “HMM-based passage models for document classification and ranking,” in Proc. 23rd European Colloq. Information Re-trieval Research, Darmstadt, Germany, 2001.[31] F. de Saussure, Cours de Linguistique Générale. Paris: Payot, 1916.[32]Y. Ding, Y. Jin, L. Ren, and K. Hao, “An intelli-gent self-organization scheme for the Internet of things,” IEEE Comput. Intell. Mag., vol. 8, no. 3, pp. 41–53, 2013.[33] H. Drucker, D. Wu, and V. Vapnik, “Support vector machines for spam categorization,” IEEE Trans. Neural Netw., vol. 10, no. 5, pp. 1048–1054, 1999.[34] M. Dyer, “Connectionist natural language pro-cessing: A status report,” in Computational Architectures Integrating Neural and Symbolic Processes, R. Sun and L. Bookman, Eds. Dordrecht, The Netherlands: Kluwer Academic, 1995, vol. 292, pp. 389–429.[35] N. Eagle, P. Singh, and A. Pentland, “Common sense conversations: Understanding casual conversation using a common sense database,” in Proc. Int. Joint Conf. Artificial Intelligence, 2003.[36]C. Fellbaum, WordNet: An Electronic Lexical Database(language, speech, and communication). Cambridge, MA: The MIT Press, 1998.[37] M. Finlayson and P. Winston, “Narrative is a key cognitive competency,” in Proc. 2nd Annu. Meeting Bio-logically Inspired Cognitive Architectures, 2011, p. 110.[38]P. Frasconi, G. Soda, and A. Vullo, “Text categori-zation for multi-page documents: A hybrid naive Bayes HMM approach,” J. Intell. Inform. Syst., vol. 18, nos. 2–3, pp. 195–217, 2001.[39] A. Gangemi, V. Presutti, D. Reforgiato, “Frame-based detection of opinion holders and topics: A model and a tool,” IEEE Comput. Intell. Mag., vol. 9, no. 1, pp. 20–30, 2014.[40] A. Ghandar, Z. Michalewicz, M. Schmidt, T. To, and R. Zurbruegg, “Computational intelligence for evolving trading rules,” IEEE Trans. Evol. Comput., vol. 13, no. 1, pp. 71–86, 2009.[41] J. Godfrey, E. Holliman, and J. McDaniel, “Switch-board: Telephone speech corpus for research and develop-ment,” in Proc. IEEE Int. Conf. Acoustics, Speech, Signal Processing, 1992, pp. 517–520. MAY 2014 | IEEE COMPUTATIONAL INTELLIGENCE MAGAZINE    57[42] A. Goldberg, “Constructions: A new theoretical ap-proach to language,” Trends Cogn. Sci., vol. 7, no. 5, pp. 219–224, 2003.[43] D. Goldberg, Genetic Algorithms in Search, Optimization, and Machine Learning. Reading, MA: Addison-Wesley, 1989.[44] C. Gueret, S. Schlobach, K. Dentler, M. Schut, and G.Eiben, “Evolutionary and swarm computing for the semantic Web,” IEEE Comput. Intell. Mag., vol. 7, no. 2, pp. 16–31, 2012.[45] E. Günes and D. Radev, “LexRank: Graph-based lexical centrality as salience in text summarization,” J. Artif. Intell. Res., vol. 22, no. 1, pp. 457–479, 2004.[46] K. Hayden, D. Novy, C. Havasi, M. Bove, S. Alfaro, and R. Speer, “Narratarium: An immersive storytelling environment,” in Proc. Human-Computer Interaction, 2013, vol. 374, pp. 536–540.[47] M. Hearst, “Automatic acquisition of hyponyms from large text corpora,” in Proc. 14th Conf. Computational Linguistics, 1992, pp. 539–545.[48]J. Heflin and J. Hendler, “Shoe: A knowledge rep-resentation language for internet applications,” Univ. Maryland, College Park, Maryland, Tech. Rep., 1999.[49] T. Hofmann, “Probabilistic latent semantic index-ing,” in Proc. 22nd Annu. Int. ACM SIGIR Conf. Research Development Information Retrieval, 1999, p. 50–57.[50] T. Hofmann, “Unsupervised learning by probabilis-tic latent semantic analysis,” Machine Learn., vol. 42, nos. 1–2, pp. 177–196, 2001.[51] N. Howard a n d  E. Cambria, “Intention awareness: Improving upon situation awareness in human-centric en-vironments,” Human-Centric Computing Information Sciences. vol. 3, Cambridge, MA: Springer-Verlag, 2013. no. 9. [52] N. Imparato and O. Harari, Jumping the Curve: In-novation and Strategic Choice in An Age of Transition. San Francisco, CA: Jossey-Bass, 1996.[53] P. Jackson and I. Moulinier, Natural Language Pro-cessing for Online Applications: Text Retrieval, Extraction and Categorization. Philadelphia, PA: John Benjamins. 1997.[54]T. Joachims, Learning To Classify Text Using Support Vector Machines: Methods, Theory and Algorithms. Norwell, MA: Kluwer Academic, 2002.[55] K. Jones and J. Galliers, “Evaluating natural language processing systems: An analysis and review,” Comput. Lin-guistics, vol. 24, no. 2, 1995.[56]D. Jurafsky, A. Bell, M. Gregory, W. Raymond, J. Bybee, and P. Hopper, Probabilistic Relations Between Words: Evidence From Reduction In Lexical Production. Am-sterdam, The Netherlands: John Benjamins, 2000.[57] J. Kacprzyk and S. Zadrozny, “Computing with words is an implementable paradigm: Fuzzy queries, linguistic data summaries, and natural-language gen-eration,” IEEE Trans. Fuzzy Syst., vol. 18, no. 3, pp. 461–472. 2010.[58] J. Kahan, “Annotea: An open RDF infrastructure for shared web annotations,” Comput. Netw., vol. 39, no.5, pp. 589–608, 2002.[59] A. Kazemzadeh, S. Lee, and S. Narayanan, “Fuzzy logic models for the meaning of emotion words,” IEEE Comput. Intell. Mag., vol. 8, no. 2, pp. 34–49, 2013.[60] M. Krug, “String frequency: A cognitive motivating factor in coalescence, language processing, and linguistic change,” J. Eng. Linguistics, vol. 26, no. 4, pp. 286–320, 1998.[61] H. Kucera and N. Francis, “Computational analysis of present-day American English,” Int. J. Amer. Linguis-tics, vol. 35, no. 1, pp. 71–75, 1969.[62] J. Lafferty, A. McCallum, and F. Pereira, “Condi-tional random fields: Probabilistic models for segment-ing and labeling sequence data,” in Proc. 18th Int. Conf. Machine Learning, 2001, pp. 282–289.[63] L. Lai, C. Wu, P. Lin, and L. Huang, “Developing a fuzzy search engine based on fuzzy ontology and seman-tic search,” in Proc. IEEE Int. Conf. Fuzzy Systems, Taipei, Taiwan, 2011, pp. 2684–2689. [64] R. Lau, Y. Xia, and Y. Ye, “A probabilistic generative model for mining cybercriminal networks from online social media,” IEEE Comput. Intell. Mag., vol. 9, no. 1, pp. 31–43, 2014.[65] S. Lawrence, C. Giles, and S. Fong, “Natural lan-guage grammatical inference with recurrent neural net-works,” IEEE Trans. Knowledge. Data Eng., vol. 12, no. 1, pp. 126–140, 2000.[66] D. Lenat and R. Guha, Building Large Knowledge-Based Systems: Representation and Inference in the Cyc Project. Boston, MA: Addison-Wesley, 1989.[67] C. Liu, G. Qi, H. Wang, and Y. Yu, “Reasoning with large scale ontologies in fuzzy pD* using mapreduce,” IEEE Comput. Intell. Mag., vol. 7, no. 27, pp. 54–66, 2012.[68] H. Liu, H. Lieberman, and T. Selker, “A model of textual affect sensing using real-world knowledge,” in Proc. 8th Int. Conf. Intelligent User Interfaces, 2003, pp. 125–132.[69] M. Luong, R. Socher, and C. Manning, “Better word representations with recursive neural networks for mor-phology,” in Proc. Conf. Natural Language Learning, 2013.[70] R. Magritte, “Les mots et les images,” La Révolution surréaliste, no. 12, 1929.[71] K. Mahesh, S. Nirenburg, and A. Tucker, Knowledge-Based Systems for Natural Language Processing. Boca Raton, FL: CRC Press, 1997.[72] C. Manning, and H. Schütze, Foundations of Statistical Natural Language Processing. Cambridge, MA: MIT press, 1999.[73] M. Marcus, B. Santorini, and M. Marcinkiewicz, “Building a large annotated corpus of english: The penn treebank,” Comput. Linguistics, vol. 19, no. 2, pp. 313–330, 1994.[74] H. Martinez, Y. Bengio, and G. Yannakakis, “Learn-ing deep physiological models of affect,” IEEE Comput. Intell. Mag., vol. 8, no. 2, pp. 20–33, 2013.[75] D. McGuinness and F. Van Harmelen, OWL web ontology language overview, W3C recommendation, 2004.[76] R. Mihalcea and P. Tarau, “TextRank: Bringing or-der into texts,” in Proc. Conf. Empirical Methods Natural Language Processing, Barcelona, 2004.[77]A. Miles and S. Bechhofer, “SKOS simple knowl-edge organization system reference,” W3C Recommenda-tion, Tech. Rep. 2009.[78]M. Minsky, Semantic Information Processing. Cam-bridge, MA: MIT Press, 1968.[79] M. Minsky, The Society of Mind. New York: Simon and Schuster, 1986.[80] E. Mueller, Natural Language Processing with Thought-Treasure. New York: Signifonn, 1998.[81] E. Mueller, “Modeling space and time in narratives about restaurants,” Literary Linguistic Comput., vol. 22, no. 1, pp. 67–84, 2007.[82]I. Mukherjee, and D. Blei, “Relative performance guarantees for approximate inference in latent dirichlet allocation,” in Proc. Neural Information Processing Systems,Vancouver, BC, 2009, pp. 1129–1136.[83]G. Murphy, The Big Book of Concepts. Cambridge, MA: MIT Press, 2004.[84] K. Nigam, A. McCallum, S. Thrun, and T. Mitchell, “Text classification from labeled and unlabeled docu-ments using EM,” Machine Learn., vol. 39, nos. 2–3, pp. 103–134, 2000.[85] V. Novak, “Fuzzy sets in natural language process-ing,” in An Introduction to Fuzzy Logic Applications in Intelli-gent Systems, Yager Ed. Norwell, MA: Kluwer Academic, 1992, pp. 185–200.[86]D. Olsher, “COGVIEW & INTELNET: Nuanced energy-based knowledge representation and integrated cognitive-conceptual framework for realistic culture, values, and concept-affected systems simulation,” in Proc. 2013 IEEE Symp. Computational Intelligence Human-Like Intelligence, Singapore, 2013, pp. 82–91.[87] M. O’Neill an d  C. Ryan, “Grammatical evolution,” IEEE Trans. Evol. Comput., vol. 5, no. 4, pp. 349–358, 2001.[88] A. Ortony, G. Clore, and A. Collins, “The cognitive structure of emotions,” Cambridge, U.K.: Cambridge Univ. Press, 1988.[89] L. Page, S. Brin, R. Motwani, and T. Winograd, “The pagerank citation ranking: bringing order to the web,” Stanford Univ., Stanford, CA, Tech. Rep., 1999.[90]J. Pearl, “Bayesian networks: A model of self-acti-vated memory for evidential reasoning,” UCLA comput. Sci., Irvine, CA: Tech. Rep. CSD-850017, 1985.[91]W. Plath, “Multiple path analysis and automatic translation,” in Machine Translation, A. D. Booth, Ed. Amsterdam, The Netherlands: North-Holland, 1967, pp. 267–315.[92]S. Ponzetto and M. Strube, “Deriving a large-scale taxonomy from Wikipedia,” in Proc. AAAI’07 22nd Nat. Conf. Artificial Intelligence, Vancouver, BC, 2007, pp. 1440–1445.[93]S. Poria, A. Gelbukh, A. Hussain, D. Das, and S. Bandyopadhyay, “Enhanced SenticNet with affective labels for concept-based opinion mining,” IEEE Intell. Syst., vol. 28, no. 2, pp. 31–38, 2013.[94] I. Porteous, I. Newman, A. Ihler, A. Asuncion, P.Smyth, and M. Welling, “Fast collapsed Gibbs sampling for latent dirichlet allocation,” in Proc. 14th ACM SIG-KDD Int. Conf. Knowledge Discovery Data Mining, 2008, pp. 569–577.[95] R. Quillian, “A notation for representing conceptual information: An application to semantics and mechanical english paraphrasing,” System Development Corp., Santa Monica, California, Tech. Rep. SP-1395, 1963.[96] R. Reiter, “A logic for default reasoning,” Artificial Intell., vol. 13, pp. 81–132, 1980.[97]W. Richards, M. Finlayson, and P. Winston, “Ad-vancing computational models of narrative,” MIT Com-puter Science and Artificial Intelligence Laboratory, Cambridge, MA, Tech. Rep. 2009-063, 2009.[98] R. Schank, Conceptual Information Processing. Amster-dam, The Netherlands: Elsevier Science Inc., 1975.[99] B. Schölkopf, S. Mika, C. Burges, P. Knirsch, K.-R.Müller, G. Rätsch, and A. Smola, “Input space versus fea-ture space in kernel-based methods,” IEEE Trans. Neural Netw., vol. 10, no. 5, pp. 1000–1017, 1999.[100] F. Sebastiani, “Machine learning in automated text categorization,” ACM Comput. Surv., vol. 34, no. 1, pp. 1–47, 2002.[101]R. Simmons, “Synthetic language behavior,” Data Processing Manage., vol. 5, no. 12, pp. 11–18, 1963.[102]P. Singh. (2002). The open mind common sense project. [Online]. Available: http://www.kurzweilai.net/[103] J. Sowa, “Semantic networks,” in Encyclopedia of Ar-tificial Intelligence, S. Shapiro, Ed. New York: Wiley, 1987.[104] R. Stevenson, J. Mikels, and T. James, “Character-ization of the affective norms for english words by dis-crete emotional categories,” Behav. Res. Methods, vol. 39, no. 4, pp. 1020–1024, 2007.[105] P. Subasic and A. Huettner, “Affect analysis of text using fuzzy semantic typing,” IEEE Trans. Fuzzy Syst., vol. 9, no. 4, pp. 483–496, 2001.[106]F. Suchanek, G. Kasneci, and G. Weikum, “Yago: A core of semantic knowledge,” in Proc. 16th Int. World Wide Web Conf., 2007. pp. 697–706.[107]P. Winston, “The strong story hypothesis and the directed perception hypothesis,” in Proc. AAAi Fall Symp.: Advances Cognitive Systems, 2011.[108] W. Wu, H. Li, H. Wang, and K. Zhu, “Probase: A probabilistic taxonomy for text understanding,” in Proc. ACM SIGMOD Int. Conf. Management Data, Scottsdale, AZ, 2012, pp. 481–492.[109]R. Xia, C. Zong, X. Hu, and E. Cambria, “Fea-ture ensemble plus sample selection: A comprehensive approach to domain adaptation for sentiment classifica-tion,” IEEE Intell. Syst., vol. 28, no. 3, pp. 10–18, 2013.[110] R. Young, “Story and discourse: A bipartite model of narrative generation in virtual worlds,” Interaction Stud-ies, vol. 8, pp. 177–208, 2007.[111] H. Zellig, “Distributional structure,” Word, vol. 10, pp. 146–162, 1954.'],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': [{'title': '딥러닝'}, {'title': '자연어처리'}],\n",
       " 'included': [<IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['2']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['48    IEEE COMPUTATIONAL INTELLIGENCE MAGAZINE | MAY 2014 1556-603X/14/$31.00©2014IEEENatural language processing (NLP) is a theory-motivated range of computational tech-niques for the automatic analysis and representation of human language. NLP research has evolved from the era of punch cards and batch processing (in which the analysis of a sentence could take up to 7 minutes) to the era of Google and the likes of it (in which millions of webpages can be processed in less than a second). This review paper draws on recent developments in NLP research to look at the past, pres-ent, and future of NLP technology in a new light. Borrowing the paradigm of ‘jumping curves’ from the field of  business management and marketing prediction, this survey article reinter-prets the evolution of NLP research as the intersection of three overlapping curves-namely Syntactics, Semantics, and Pragmatics Curves- which will eventually lead NLP research to evolve into natural language understanding.I. IntroductionBetween the birth of the Internet and2003, year of birth of social networkssuch as MySpace, Delicious, LinkedIn, and Facebook, there were just a fewdozen exabytes of information on theWeb. Today, that same amount of infor-mation is created weekly. The advent ofthe Social Web has provided peoplewith new content-sharing services thatallow them to create and share theirown contents, ideas, and opinions, in a time- and cost-efficient way, with virtu-ally millions of other people connected to the World Wide Web. This huge amount of information, however, is mainly unstructured (because it is spe-cifically produced for human consump-tion) and hence not directly machine-processable. The automatic analysis of text involves a deep understanding of natural language by machines, a reality from which we are still very far off.Hitherto, online information retrieval, aggregation, and processing have mainly been based on algorithms relying on the textual representation of web pages. Such algorithms are very good at retrieving texts, splitting them into parts, checking the spelling and counting the number of words. When it comes to interpreting sentences and extracting meaningful information,  however, their capabilities are known to be very limited. Natural language pro-cessing (NLP), in fact, requires high-level symbolic capabilities (Dyer, 1994), including:/uni274Fcreation and propagation of dynamicbindings;/uni274Fmanipulation of recursive, constitu-ent structures;/uni274Facquisition and access of lexical,semantic, and episodic memories;/uni274Fcontrol of multiple learning/process-ing modules and routing of informa-tion among such modules;/uni274Fgrounding of basic-level languageconstructs (e.g., objects and actions)in perceptual/motor experiences;/uni274Frepresentation of abstract concepts.All such capabilities are required toshift from mere NLP to what is usually referred to as natural language under-standing (Allen, 1987). T oday, most of the existing approaches are still based on the syntactic representation of text, a method that relies mainly on word co-occurrence frequencies. Such algorithms are limited by the fact that they can pro-cess only the information that they can ‘see’. As human text processors, we do not have such limitations as every word we see activates a cascade of semantically related concepts, relevant episodes, and sensory experiences, all of which enable the completion of complex NLP tasks—such as word-sense disam-biguation, textual entailment, and semantic role labeling—in a quick and effortless way.Computational models attempt to bridge such a cognitive gap by emulat-ing the way the human brain processes natural language, e.g., by leveraging on semantic features that are not explicitly expressed in text. Computational mod-els are useful both for scientific pur-poses (such as exploring the nature of linguistic communication), as well as for Jumping NLP Curves: A Review of Natural Language Processing Research\\nDigital Object Identifier 10.1109/MCI.2014.2307227Date of publication:11 April 2014Erik Cambria School of Computer Engineering, Nanyang Technological UniversityBebo White SLAC National Accelerator Laboratory, Stanford University\\n© BRAND X PICTURES    ArticleReview MAY 2014 | IEEE COMPUTATIONAL INTELLIGENCE MAGAZINE    49practical purposes (such as enabling effective human-machine communica-tion). Traditional research disciplines do not have the tools to completely address the problem of how language compre-hension and production work. Even if you combine all the approaches, a com-prehensive theory would be too com-plex to be studied using traditional methods. However, we may be able to realize such complex theories as com-puter programs and then test them by observing how well they perform. By seeing where they fail, we can incre-mentally improve them. Computational models may provide very specific pre-dictions about human behaviors that can then be explored by the psycholin-guist. By continuing this process, we may eventually acquire a deeper under-standing of how human language pro-cessing occurs. To realize such a dream will take the combined efforts of for-ward-thinking psycholinguists, neuro-scientists, anthropologists, philosophers, and computer scientists.Unlike previous surveys focusing on specific aspects or applications of NLP research (e.g., evaluation criteria (Jones & Galliers, 1995), knowledge-based sys-tems (Mahesh, Nirenburg, & Tucker, 1997), text retrieval (Jackson & Moulin-ier, 1997), and connectionist models (Christiansen & Chater, 1999)), this review paper focuses on the evolution of NLP research according to three differ-ent paradigms, namely: bag-of-words, word embeddings, and narrative understanding. Borrowing the concept of ‘jumping curves’ from the field of business management, this survey article explains how and why NLP research has been gradually shifting from lexical semantics to compositional semantics and offers insights on next-generation narrative-based NLP technology.The rest of the paper is organized as follows: Section 2 presents the historical background and the different schools of thought of NLP research; Section 3 discusses past, present,  and future evolution of NLP technologies; Section 4 describes traditional syntax-centered NLP methodologies; Section 5  illustrates emerging semantics-basedNLP approaches; Section 6 introduces pio-neering works on narrative understand-ing; Section 7 proposes further insights on the evolution of current NLP tech-nologies and suggests near future research directions; finally, Section 8 concludes the paper and outlines future areas of NLP research.2. BackgroundSince its inception in 1950s, NLPresearch has been focusing on tasks suchas machine translation, informationretrieval, text summarization, questionanswering, information extraction, topicmodeling, and more recently, opinionmining. Most NLP research carried outin the early days focused on syntax, partly because syntactic processing wasmanifestly necessary, and partly throughimplicit or explicit endorsement of theidea of syntax-driven processing.Although the semantic problems and needs of NLP were clear from the very beginning, the strategy adopted by the research community was to tackle syntax first, for the more direct applicability of machine learning techniques. However, there were some researchers who con-centrated on semantics because they saw it as the really challenging problem or assumed that semantically-driven pro-cessing be a better approach. Thus, Mas-terman’s and Ceccato’s groups, for exam-ple, exploited semantic pattern matching using semantic categories and semantic case frames, and in Ceccato’s work (Cec-cato, 1967) particularly, world knowledge was used to extend linguistic semantics, along with semantic networks as a device for knowledge representation. Later works recognized the need for external knowledge in interpreting and responding to language input (Minsky, 1968) and explicitly emphasized seman-tics in the form of general-purpose semantics with case structures for repre-sentation and semantically-driven pro-cessing (Schank, 1975).One of the most popular representa-tion strategies since then has been first order logic (FOL), a deductive system that consists of axioms and rules of infer-ences and can be used to formalize rela-tionally-rich predicates and quantifica-tion (Barwise, 1977). FOL supports syntactic, semantic and, to a certain degree, pragmatic expressions. Syntax specifies the way groups of symbols are to be arranged, so that the group of sym-bols is considered properly formed. Semantics specifies what well-formed expressions are supposed to mean. Prag-matics specifies how contextual informa-tion can be leveraged to provide better correlations between different semantics, which is essential for tasks such as word sense disambiguation. Logic, however, is known to have the problem of monoto-nicity. The set of entailed sentences will only increase as information is added to the knowledge base, but this runs the risk of violating a common property of human reasoning—the freedom and flexibility to change one’s mind. Solu-tions such as default and linear logic serve to address parts of these issues. Default logic is proposed by Raymond Reiter to formalize default assumptions, e.g., “all birds fly” (Reiter, 1980). How-ever, issues arise when default logic for-malizes facts that are true in the majority of cases but are false with regards to exceptions to these ‘general rules’, e.g., “penguins do not fly”.Another popular model for the description of natural language is pro-duction rule (Chomsky, 1956). A pro-duction rule system keeps a working memory of on-going memory assertions. This working memory is volatile and in turn keeps a set of production rules. A production rule comprises of an ante-cedent set of conditions and a conse-quent set of actions (i.e., IF <condi-tions> THEN <actions>). The basic operation for a production rule system involves a cycle of three steps (‘recog-nize’, ‘resolve conflict’, and ‘act’) that repeats until no more rules are applicable to the working memory. The step ‘recog-nize’ identifies the rules whose anteced-ent conditions are satisfied by the current working memory. The set of rules identi-fied is also called the conflict set. The step ‘resolve conflict’ looks into the con-flict set and selects a set of suitable rules to execute. The step ‘act’ simply executes the actions and updates the working memory. Production rules are modular.  50    IEEE COMPUTATIONAL INTELLIGENCE MAGAZINE | MAY 2014Each rule is independent from the oth-ers, allowing rules to be added and deleted easily. Production rule systems have a simple control structure and the rules are easily understood by humans. This is because rules are usually derived from the observation of expert behavior or expert knowledge, thus the terminol-ogy used in encoding the rules tends to resonate with human understanding. However, there are issues with scalability when production rule systems become larger; a significant amount of mainte-nance is required to maintain a system with thousands of rules.Another instance of a prominent NLP model is the ontology Web lan-guage (OWL) (McGuinness & Van Harmelen, 2004), an XML-based vocab-ulary that extends the resource descrip-tion framework (RDF) to provide a more comprehensive set for ontology representation, such as the definition of classes, relationships between classes, properties of classes, and constraints on relationships between classes and their properties. RDF supports the subject-predicate-object model that makes assertions about a resource. RDF-based reasoning engines have been developed to check for semantic consistency which then helps to improve ontology classifi-cation. In general, OWL requires the strict definition of static structures, and therefore is not suitable for representing knowledge that contains subjective degrees of confidence. Instead, it is more suited for representing declarative knowledge. Furthermore, yet another problem of OWL is that it does not allow for an easy representation of tem-poral-dependent knowledge.Networks are yet another well-known way to do NLP . For example, Bayesian networks (Pearl, 1985) (also known as belief networks) provide a means of expressing joint probability distributions over many interrelated hypotheses. All variables are represented using directed acyclic graph (DAG). Arcs are causal connections between two variables where the truth of the former directly affects the truth of the latter. A Bayesian network is able to represent subjective degrees of confidence. The representation explicitly explores the role of prior knowledge and combines pieces of evidence of the likelihood of events. In order to compute the joint distribution of the belief network, there is a need to know Pr(P|parents(P)) for each variable P. It is difficult to deter-mine the probability of each variable P in the belief network. Hence, it is also difficult to enhance and maintain the statistical table for large-scale informa-tion processing problems. Bayesian net-works also have limited expressiveness, which is only equivalent to the expres-siveness of proposition logic. For this reason, semantic networks are more often used in NLP research.A semantic network (Sowa, 1987) is a graphical notation for representing knowledge in patterns of interconnected nodes and arcs. Definitional networks focus on IsA relationships between a concept and a newly defined sub-type. The result of such a structure is called a generalization, which in turn supports the rule of inheritance for copying properties defined for a super-type to all of its sub-types. The information in defi-nitional networks is often assumed to be true. Y et another kind of semantic net-works is the assertional network, which is meant to assert propositions and the information it contains is assumed to be contingently true. Contingent truth is not reached with the application of default logic; instead, it is based more on Man’s application of common-sense. The proposition also has sufficient rea-son in which the reason entails the proposition, e.g., “the stone is warm” with the sufficient reasons being “the sun is shining on the stone” and “what-ever the sun shines on is warm”.The idea of semantic networks arose in the early 1960s from Simmons (Sim-mons, 1963) and Quillian (Quillian, 1963) and was further developed in the late 1980s by Marvin Minsky within his Society of Mind theory (Minsky, 1986), according to which the magic of human intelligence stems from our vast diversity—and not from any single, per-fect principle. Minsky theorized that the mind is made of many little parts that he termed ‘agents’, each mindless by itself but able to lead to true intelligence when working together. These groups of agents, or ‘agencies’, are responsible for performing some type of function, such as remembering, comparing, gen-eralizing, exemplifying, analogizing, sim-plifying, predicting, etc. Minsky’s theory of human cognition, in particular, was welcomed with great enthusiasm by the artificial intelligence (AI) community and gave birth to many attempts to build common-sense knowledge bases for NLP tasks. The most representative projects are: (a) Cyc (Lenat & Guha, 1989), Doug Lenat’s logic-based reposi-tory of common-sense knowledge; (b) WordNet (Fellbaum, 1998), Christiane Fellbaum’s universal database of word senses; (c) Thought-Treasure (Mueller, 1998), Erik Mueller’s story understand-ing system; and (d) the Open Mind Common Sense project (Singh, 2002), a second-generation common-sense data-base. The last project stands out because knowledge is represented in natural  TABLE 1 Most popular schools of thought in knowledge representation and NLP research.APPROACHCHARACTERISTIC FEATURESREFERENCEPRODUCTION RULE CYCLES OF `RECOGNIZE’, `RESOLVE CONFLICT’, `ACT’ STEPS(CHOMSKY, 1956)SEMANTIC PATTERN MATCHINGSEMANTIC CATEGORIES AND SEMANTIC CASE FRAMES(CECCATO, 1967)FIRST ORDER LOGIC (FOL)AXIOMS AND RULES OF INFERENCES(BARWISE, 1977)BAYESIAN NETWORKS VARIABLES REPRESENTED BY A PROBABILIS-TIC DIRECTED ACYCLIC GRAPH(PEARL, 1985)SEMANTIC NETWORKSPATTERNS OF INTERCONNECTED NODES AND ARCS(SOWA, 1987)ONTOLOGY WEB LANGUAGE (OWL)HIERARCHICAL CLASSES AND RELATION-SHIPS BETWEEN THEM(MCGUINNESS & VAN HARMELEN, 2004) MAY 2014 | IEEE COMPUTAT IONAL INTELLIGENCE MAGAZ INE    51language (rather than being based upon \\na formal logical structure), and informa-tion is not hand-crafted by expert engi-neers but spontaneously inserted by online volunteers. T oday, the common-sense knowledge collected by the Open Mind Common Sense project is being exploited for many different NLP tasks such as textual affect sensing (H. Liu, Lieberman, & Selker, 2003), casual con-versation understanding (Eagle, Singh, & Pentland, 2003), opinion mining (Cam -\\nbria & Hussain, 2012), story telling (Hayden et al., 2013), and more.\\n3. Overlapping NLP Curves\\nWith the dawn of the Internet Age, civilization has undergone profound, rapid-fire changes that we are experi-encing more than ever today. Eventechnologies that are adapting, growing, and innovating have the gnawing sensethat obsolescence is right around thecorner. NLP research, in particular, hasnot evolved at the same pace as othertechnologies in the past 15 years.\\nWhile NLP research has made great \\nstrides in producing artificially intelli -\\ngent behaviors, e.g., Google, IBM’s Wat-son, and Apple’s Siri, none of such NLP frameworks actually understand what they are doing—making them no differ-ent from a parrot that learns to repeat words without any clear understanding of what it is saying. T oday, even the most popular NLP technologies view text analysis as a word or pattern matching task. Trying to ascertain the meaning of a piece of text by processing it at word-level, however, is no different from attempting to understand a picture by analyzing it at pixel-level.\\nIn a Web where user-generated con-\\ntent (UGC) is drowning in its own out-put, NLP researchers are faced with the same challenge: the need to jump the curve (Imparato & Harari, 1996) to make significant, discontinuous leaps in their thinking, whether it is about information retrieval, aggregation, or processing. Relying on arbitrary key-words, punctuation, and word co-occurrence frequencies has worked fairly well so far, but the explosion of UGCs and the outbreak of deceptive phenomena such as web-trolling and opinion spam, are causing standard NLP algorithms to be increasing less efficient. In order to properly extract and manip-ulate text meanings, a NLP system must have access to a significant amount of knowledge about the world and the domain of discourse.\\nTo this end, NLP systems will \\ngradually stop relying too much on word-based techniques while starting to exploit semantics more consistently and, hence, make a leap from the  Syntactics Curve to the Semantics Curve (Figure /uni00A01). NLP research has \\nbeen interspersed with word-level approaches because, at first glance, the most basic unit of linguistic structure appears to be the word. Single-word expressions, however, are just a subset of concepts, multi-word expressions that carry specific semantics and sentics  \\n(Cambria & Hussain, 2012), that is, the denotative and connotative informa-tion commonly associated with real-world objects, actions, events, and people. Sentics, in particular, specifies the affective information associated with such real-world entities, which is key for common-sense reasoning and decision-making.\\nSemantics and sentics include com-\\nmon-sense knowledge (which humans normally acquire during the formative years of their lives) and common knowl -edge (which people continue to accrue in their everyday life) in a re-usable knowledge base for machines. Common knowledge includes general knowledge about the world, e.g., a chair is a type of \\nfurniture, while common-sense knowl -\\nedge comprises obvious or widely accepted things that people normally know about the world but which are usually left unstated in discourse, e.g., that things fall downwards (and not upwards) a n d  people smile when they are happy. The difference between common and common-sense knowledge can be expressed as the difference between knowing the name of an object and understanding the same object’s purpose. For example, you can know the name of all the different kinds or brands of ‘pipe’, but not its purpose nor the method of usage. In other words, a ‘pipe’ is not a pipe unless it can be used (Magritte, 1929) (Figure 2 ).\\nIt is through the combined use of \\ncommon and common-sense knowl -\\nedge that we can have a grip on both high- and low-level concepts as well as nuances in natural language understand -\\ning and therefore effectively communi-cate with other people without having to continuously ask for definitions and explanations. Common-sense, in partic-ular, is key in properly deconstructing natural language text into sentiments according to different contexts—for \\nFIGURE 1 Envisioned evolution of NL P research through three different eras or curves.\\nNLP System PerformanceBest Path\\n1930                      1970 2010 2050Syntactics Curve\\n(Bag-of-Words Model)Semantics Curve\\n(Word Embeddings)Pragmatics Curve\\n(Narrative Understanding)\\n Time 52    IEEE COMPUTATIONAL INTELLIGENCE MAGAZINE | MAY 2014example, in appraising the concept ‘small room’ as negative for a hotel review and ‘small queue’ as positive for a post office, or the concept ‘go read the book’ as positive for a book review but negative for a movie review.Semantics, however, is just one layer up in the scale that separates NLP from natural language understanding. In order to achieve the ability to accu-rately and sensibly process information, computational models will also need to be able to project semantics and sentics in time, compare them in a parallel and dynamic way, according to different contexts and with respect to different actors and their intentions (Howard & Cambria, 2013). This will mean jump-ing from the Semantics Curve to the Pragmatics Curve, which will enable NLP to be more adaptive and, hence, open-domain, context-aware, and intent-driven. Intent, in particular, will be key for tasks such as sentiment anal-ysis—a concept that generally has a negative connotation, e.g., small seat, might turn out to be positive, e.g., if the intent is for an infant to be safely seated in it.While the paradigm of the Syntac-tics Curve is the bag-of-words model (Zellig, 1954) and the Semantics Curve is characterized by a concept-level model (Cambria & Hussain, 2012), the paradigm of the Pragmatics Curve will be the narrative understanding model. In this last model, each piece of text will be represented by mini-stories or interconnected episodes, leading to a more detailed level of text comprehension and sensible computa-tion. While the concept-level model helps to overcome problems such as word-sense disambiguation and semantic role labeling, the narrativeunderstanding model will enable tackling NLP issues such as co-reference resolution and textual entailment.4.Poising on the Syntactics CurveToday, syntax-centered NLP is still themost popular way to manage tasks suchas information retrieval and extraction,auto-categorization, topic modeling,etc. Despite semantics enthusiasts hav-ing argued the importance and inevita-bility of a shift away from syntax for years, the vast majority of NLP researchers nowadays are still trying to keep their balance on the Syntactics Curve. Syntax-centered NLP can be broadly grouped into three main cate-gories: keyword spotting, lexical affinity, and statistical methods.4.1. Keyword SpottingKeyword Spotting is the most naïve approach and probably also the most popular because of its accessibility and economy. T ext is classified into catego-ries based on the presence of fairly unambiguous words. Popular projects include: (a) Ortony’s Affective Lexicon (Ortony, Clore, & Collins, 1988), which groups words into affective categories; (b) Penn Treebank (Marcus, Santorini, &Marcinkiewicz, 1994), a corpus consist-ing of over 4.5 million words of Ameri-can English annotated for part-of-speech (POS) information; (c)PageRank (Page, Brin, Motwani, &Winograd, 1999), the famous rankingalgorithm of Google; (d) LexRank(G/Udieresis.scnes & Radev, 2004), a stochasticgraph-based method for computing rel-ative importance of textual units forNLP; finally, (e) T extRank (Mihalcea &Tarau, 2004), a g raph-based rankingmodel for text processing, based on twounsupervised methods for keyword andsentence extraction. The major weaknessof keyword spotting lies in its relianceupon the presence of obvious wordswhich are only surface features of theprose. A text document about dogswhere the word ‘dog’ is never men-tioned, e.g., because dogs are addressedaccording to the specific breeds theybelong to, might never be retrieved by a keyword-based search engine.4.2. Lexical AffinityLexical Affinity is slightly more sophisti-cated than keyword spotting as, rather than simply detecting obvious words, it assigns to arbitrary words a probabilistic ‘affinity’ for a particular category (Bush, 1999; Bybee & Scheibman, 1999; Krug, 1998; Church & Hanks, 1989; Jurafsky et al., 2000). For example, ‘accident’ might be assigned a 75% probability of indicating a negative event, as in ‘car accident’ or ‘hurt in an accident’. These probabilities are usually gleaned from linguistic corpora (Kucera & Francis, 1969; Godfrey, Holliman, & McDaniel, 1992; Stevenson, Mikels, & James, 2007). Although this approach often outper-forms pure keyword spotting, there are two main problems with it. First, lexical affinity operating solely on the word-level can easily be tricked by sentences such as “I avoided an accident” (nega-tion) and “I met my girlfriend by acci-dent” (connotation of unplanned but lovely surprise). Second, lexical affinity probabilities are often biased toward text of a particular genre, dictated by the source of the linguistic corpora. This makes it difficult to develop a re-usable, domain-independent model.4.3. Statistical NLPStatistical NLP has been the mainstream NLP research direction since late 1990s. It relies on language models (Manning & Sch/Udieresis.sctze, 1999; Hofmann, 1999;  Nigam, McCallum, Thrun, & Mitchell, 2000) based on popular machine-learn-ing algorithms such as maximum-likeli-hood (Berger, Della Pietra, & Della Pietra, 1996), expectation maximization (Nigam et al., 2000), conditional ran-dom fields (Lafferty, McCallum, & Pereira, 2001), and support vector machines (Joachims, 2002). By feeding a large training corpus of annotated texts to a machine-learning algorithm, it is possible for the system to not only learn the valence of keywords (as in the key-word spotting approach), but also to take into account the valence of other arbi-trary keywords (like lexical affinity), FIGURE 2 A ‘pipe’ is not a pipe, unless we know how to use it.\\n MAY 2014 | IEEE COMPUTATIONAL INTELLIGENCE MAGAZINE    53punctuation, and word co-occurrence frequencies. However, statistical methods are generally semantically weak, mean-ing that, with the exception of obvious keywords, other lexical or co-occur-rence elements in a statistical model have little predictive value individually. As a result, statistical text classifiers only work with acceptable accuracy when given a sufficiently large text input. So, while these methods may be able to classify text on the page- or paragraph-level, they do not work well on smaller text units such as sentences or clauses.5. Surfing the Semantics CurveSemantics-based NLP focuses on theintrinsic meaning associated with natu-ral language text. Rather than simplyprocessing documents at syntax-level, semantics-based approaches rely onimplicit denotative features associatedwith natural language text, hence step-ping away from the blind usage of key-words and word co-occurrence count. Unlike purely syntactical techniques, concept-based approaches are also ableto detect semantics that are expressedin a subtle manner, e.g., through theanalysis of concepts that do not explic-itly convey relevant information, butwhich are implicitly linked to otherconcepts that do so. Semantics-basedNLP approaches can be broadlygrouped into two main categories:techniques that leverage on externalknowledge, e.g., ontologies (taxonomicNLP) or semantic knowledge bases(noetic NLP), and methods that exploitonly intrinsic semantics of documents(endogenous NLP).5.1. Endogenous NLPEndogenous NLP involves the use of machine-learning techniques to per-form semantic analysis of a corpus by building structures that approximate concepts from a large set of documents. It does not involve prior semantic understanding of documents; instead, it relies only on the endogenous knowl-edge of these (rather than on external knowledge bases). The advantages of this approach over the knowledge engineer-ing approach are effectiveness, consider-able savings in terms of expert man-power, and straightforward portability to different domains (Sebastiani, 2002).Endogenous NLP includes methods based either on lexical semantics, which focuses on the meanings of individual words, or compositional semantics, which looks at the meanings of sen-tences and longer utterances. The vast major ity of endogenous NLP approaches is based on lexical semantics and includes well-known machine-learning techniques. Some examples of this are: (a) latent semantic analysis (Hofmann, 2001), where documents are represented as vectors in a term space; (b) latent Dirichlet allocation (Porteouset al., 2008), which involves attributingdocument terms to topics; (c) MapRe-duce (C. Liu, Qi, Wang, & Y u, 2012), aframework that has proved to be veryefficient for data-intensive tasks, e.g., large scale RDFS/OWL reasoning and(d) genetic algorithms (D. Goldberg, 1989), probabilistic search proceduresdesigned to work on large spacesinvolving states that can be representedby strings.Works leveraging on compositional semantics, instead, mainly include approaches based on Hidden Markov Models (Denoyer, Zaragoza, & Gallinari, 2001; Frasconi, Soda, & Vullo, 2001), association rule learning (Cohen, 1995; Cohen & Singer, 1999), feature ensem-bles (Xia, Zong, Hu, & Cambria, 2013; Poria, Gelbukh, Hussain, Das, & Ban-dyopadhyay, 2013) and probabilistic gen-erative models (Lau, Xia, & Y e, 2014).5.2. Taxonomic NLPTaxonomic NLP includes initiatives that aim to build universal taxonomies or Web ontologies for grasping the sub-sumptive or hierarchical semantics asso-ciated with natural language expres-sions. Such taxonomies usually consist of concepts (e.g., painter), instances (e.g., “Leonardo da Vinci”), attributes and values (e.g., “Leonardo’s birthday is April 15, 1452”), and relationships (e.g., “Mona Lisa is painted by Leonardo”). In particular, subsumptive knowledge representations build upon IsA r e l a-tionships, which are usually extracted through syntactic patterns for auto-matic hypernym discovery (Hearst,  1992) able to infer triples such as <Pablo Picasso-IsA-artist> from stretches of text like “...artists such as Pablo Picasso...” or “...Pablo Picasso and other artists...”.In general, attempts to build taxo-nomic resources are countless and include both resources crafted by human experts or community efforts, such as WordNet and Freebase (Bol-lacker, Evans, Paritosh, Sturge, & Taylor, 2008), and automatically built knowl-edge bases. Examples of such knowl-edge bases include: (a) WikiTaxonomy (Ponzetto & Strube, 2007), a taxonomy extracted from Wikipedia’s category links; (b) YAGO (Suchanek, Kasneci, & Weikum, 2007), a semantic knowledge base derived from WordNet, Wikipedia, and GeoNames; (c) NELL (Carlson et al., 2010) (Never-Ending Language Learning), a semantic machine-learning system that is acquiring knowledge from the Web every day; finally, (d) Pro-base (Wu, Li, Wang, & Zhu, 2012), a research prototype that aims to build a unified taxonomy of worldly facts from 1.68 billion webpages in Bing repository.Other popular Semantic Web proj-ects include: (a) SHOE (Heflin & Hen-dler, 1999) (Simple HTML Ontology Extensions), a knowledge representa-tion language that allows webpages to be annotated with semantics; (b) Annotea (Kahan, 2002), an open RDF infrastructure for shared Web annota-tions; (c) SIOC (Breslin, Harth, Bojars, & Decker, 2005) (Semantically Inter-linked Online Communities), an ontol-ogy combining terms from vocabular-ies that already exist with new terms needed to describe the relationships between concepts in the realm of online community sites; (d) SKOS (Miles & Bechhofer, 2009) (Simple Knowledge Organization System), an area of work developing specifications and standards to support the use of knowledge organization systems such as thesauri, classification schemes, sub-ject heading lists and taxonomies; (e) FOAF (Brickley & Miller, 2010) (Friend Of A Friend), a project devoted  54    IEEE COMPUTATIONAL INTELLIGENCE MAGAZINE | MAY 2014to linking people and information using the Web; (f  ) ISOS (Ding, Jin, Ren, & Hao, 2013) (Intelligent Self-Organizing Scheme), a scheme for the Internet of Things inspired by the endocrine regulating mechanism;  finally, (g) FRED (Gangemi, Presutti, & Reforgiato, 2014), a tool that produces an event-based RDF/OWL representa-tion of natural language text. The main weakness of taxonomic NLP is in the typicality of their knowledge bases. The way knowledge is represented in tax-onomies and Web ontologies is usually strictly defined and does not allow for the combined handling of differing nuanced concepts, as the inference of semantic features associated with con-cepts is bound by the fixed, flat repre-sentation. The concept of ‘book’, for example, is typically associated to con-cepts such as ‘newspaper’ or ‘magazine’, as it contains knowledge, has pages, etc. In a different context, however, a book could be used as paperweight, doorstop, or even as a weapon. Another key weakness of Semantic Web projects is that they are not easily scalable and, hence, not widely adopted (Gueret, Schlobach, Dentler, Schut, & Eiben, 2012). This increases the amount of time that has to pass before the initial customer feedback is even possible, and also slows down feedback loop itera-tions, ultimately putting Semantic Web applications at a user-experience and agility disadvantage as compared to their Web 2.0 counterparts, because their usability inadvertently takes a back seat to the number of other com-plex problems that have to be solved before clients even see the application.5.3. Noetic NLPNoetic NLP embraces all the mind-inspired approaches to NLP that attempt to compensate for the lack of domain adaptivity and implicit seman-tic feature inference of traditional algo-rithms, e.g., first principles modeling or explicit statistical modeling. Noetic NLP differs from taxonomic NLP in which it does not focus on encoding subsumption knowledge, but rather attempts to collect idiosyncratic knowl-edge about objects, actions, events, and people. Noetic NLP , moreover, per-forms reasoning in an adaptive and dynamic way, e.g., by generating con-text-dependent results or by discover-ing new semantic patterns that are not explicitly encoded in the knowledge base. Examples of noetic NLP include paradigms such as connectionist NLP (Christiansen & Chater, 1999), which models mental phenomena as emergent processes of interconnected networks of simple units, e.g., neural networks (Collobert et al., 2011); deep learning (Martinez, Bengio, & Yannakakis, 2013); sentic computing (Cambria & Hussain, 2012), an approach to concept-level sentiment analysis based on an ensem-ble of graph-mining and dimensional-ity-reduction techniques; and energy-based knowledge representation (Olsher, 2013), a novel framework for nuanced common-sense reasoning.Besides knowledge representation and reasoning, a key aspect of noetic NLP is also semantic parsing. Most cur-rent NLP technologies rely on part-of-speech (POS) tagging, but that is unlike the way the human mind extracts meaning from text. Instead, just as the human mind does, a construction-based semantic parser (CBSP) (Cambria, Raja-gopal, Olsher, & Das, 2013) quickly identifies meaningful stretches of text without requiring time-consuming phrase structure analysis. The use of con-structions, defined as “stored pairings of form and function” (A. Goldberg, 2003) makes it possible to link distributed lin-guistic components to one another, eas-ing extraction of semantics from linguis-tic structures. Constructions are composed of fixed lexical items and cat-egory-based slots, or ‘spaces’ that are filled in by lexical items during text pro-cessing. An interesting example from the relevant literature would be the con-struction [<ACTION> <OBJECT> <DIRECTION> <OBJECT>].  Instances of this include the phrases ‘sneeze the napkin across the table’ or ‘hit the ball over the fence’. Construc-tions not only help understand how var-ious lexical items work together to cre-ate the whole meaning, but also give the parser a sense of what categories of words are used together and thus where to expect different words.CBSP uses this knowledge to deter-mine constructions, their matching lexi-cal terms, and how good each match is. Each of CBSP’s constructions contrib-utes its own unique semantics and car-ries a unique name. In order to choose the best possible construction for each span of text, CBSP uses knowledge about the lexical items found in text. This knowledge is obtained from look-ing individual lexical terms up in the knowledge bases so as to obtain infor-mation about the basic category mem-bership of that word.It then efficiently compares these potential memberships with the catego-ries specified for each construction in the corpus, finding the best matches so that CBSP can extract a concept from a sentence. An example would be the extraction of the concept ‘buy christmas present’ from the sentence “today I bought a lot of very nice Christmas gifts”. Constructions are typically nested within one another: CBSP is capable of finding only those construction overlaps that are semantically sensible, based on the overall semantics of constructions and construction slot categories, thus greatly reducing the time taken to pro-cess large numbers of texts. In the big data environment, a key benefit of con-struction-based parsing is that only small sections of text are required in order to extract meaning; word category infor-mation and the generally small size of constructions mean that the parser can still make use of error-filled or conven-tionally unparseable text.6. Foreseeing the Pragmatics CurveNarrative understanding and generationare central for reasoning, decision-mak-ing, and ‘sensemaking’. Besides being akey part of human-to-human commu-nication, narratives are the means bywhich reality is constructed and plan-ning is conducted. Decoding how nar-ratives are generated and processed bythe human brain might eventually leadus to truly understand and explainhuman intelligence and consciousness. MAY 2014 | IEEE COMPUTATIONAL INTELLIGENCE MAGAZINE    55Computational modeling is a pow-erful and effective way to investigate narrative understanding. A lot of the cognitive processes that lead humans to understand or generate narratives have traditionally been of interest to AI researchers under the umbrella of knowledge representation, common-sense reasoning, social cognition, learn-ing, and NLP . Once NLP research can grasp semantics at a level comparable to human text processing, the jump to the Pragmatics Curve will be necessary, in the same way as semantic machine learning is now gradually evolving from lexical to compositional semantics.  There are already a few pioneering works that attempt to understand narra-tives by leveraging on discourse struc-ture (Asher & Lascarides, 2003), argu-ment-support hierarchies (Bex,  Prakken, & Verheij, 2007), plan graphs (Y oung, 2007), and common-sense rea-soning (Mueller, 2007). One of the most representative initiatives in this context is Patrick Winston’s work on computational models of narrative (Winston, 2011; Richards, Finlayson, & Winston, 2009), which is based on five key hypotheses:/uni274FThe inner language hypothesis: wehave an inner symbolic language thatenables event description./uni274FThe strong story hypothesis: we canassemble event descriptions into stories./uni274FThe directed perception hypothesis: we can direct the resources of our per-ceptual faculties to answer questionsusing real and imagined situations./uni274FThe social animal hypothesis: wehave a powerful reason to express thethought in our inner language in anexternal communication language./uni274FThe exotic engineering hypothesis: our brains are unlike standard left-to-right engineered systems.Essentially, Patrick Winston believesthat human intelligence stems from our unique abilities for storytelling and understanding (Finlayson & Winston, 2011). Accordingly, his recent work has focused on developing a computational system that is able to analyze narrative texts to infer non-obvious answers to questions about these texts. This has resulted in the Genesis System. Work-ing with short story summaries pro-vided in English, together with low-level common-sense rules and higher-level reflection patterns that are also expressed in English, Genesis has been successful in demonstrating sev-eral story understanding capabilities. One instance of this is its ability to determine that both Macbeth and the 2007 Russia-Estonia Cyberwar involve revenge, even though neither the word ‘revenge’ nor any of its synonyms are mentioned in accounts describing those texts.7. DiscussionWord- and concept-level approaches toNLP are just a first step towards naturallanguage understanding. The future ofNLP lies in biologically and linguistical-ly motivated computational paradigmsthat enable narrative understanding and, hence, ‘sensemaking’. Computational in-telligence potentially has a large futurepossibility to play an important role inNLP research. Fuzzy logic, for example, has a direct relation to NLP (Carvalho, Batista, & Coheur, 2012) for tasks suchas sentiment analysis (Subasic &Huettner, 2001), linguistic summariza-tion (Kacprzyk & Zadrozny, 2010),knowledge representation (Lai, Wu, Lin, & Huang, 2011), and word meaning in-ference (Kazemzadeh, Lee, & Narayanan, 2013). Artificial neural networks can aidthe completion of NLP tasks such asambiguity resolution (Chan & Franklin, 1998; Costa, Frasconi, Lombardo, &Soda, 2005), grammatical inference(Lawrence, Giles, & Fong, 2000), wordrepresentation (Luong, Socher, & Man-ning, 2013), and emotion recognition(Cambria, Gastaldo, Bisio, & Zunino, 2014). Evolutionary computation can beexploited for tasks such as grammaticalevolution (O’Neill & Ryan, 2001), knowledge discovery (Atkinson-Abutridy, Mellish, & Aitken, 2003), textcategorization (Araujo, 2004), and rulelearning (Ghandar, Michalewicz,Schmidt, T o, & Zurbruegg, 2009).Despite its potential, however, the use of computational intelligence tech-niques till date has not been so active in the field of NLP . The first reason is that NLP is a huge field currently tack-ling dozens of different problems for which specific evaluation metrics exist, and it is not possible to reduce the whole field into a specific problem, as it was done in early works (Novak, 1992). The second reason may be that power-ful techniques such as support vector machines (Drucker, Wu, & Vapnik,  1999), kernel principal component analysis (Schölkopf et al., 1999), and la-tent Dirichlet allocation (Mukherjee & Blei, 2009) have achieved remarkable results on widely used NLP datasets, which are not yet met by computation-al intelligence techniques. All such word-based algorithms, however, are limited by the fact that they can process only the information that they can ‘see’ and, hence, will sooner or later reach saturation. Computational intelligence techniques, instead, can go beyond the syntactic representation of documents by emulating the way the human brain processes natural language (e.g., by le-veraging on semantic features that are not explicitly expressed in text) and, hence, have higher potential to tackle complementary NLP tasks. An ensem-ble of computational intelligence tech-niques, for example, could be exploited within the same NLP model for on-line learning of natural language con-cepts (through neural networks),  concept classification and semantic fea-ture generalization (through fuzzy sets), and concept meaning evolution and continuous system optimization (through evolutionary computation).8. ConclusionIn a Web where user-generated contenthas already hit critical mass, the need forsensible computation and informationaggregation is increasing exponentially, as demonstrated by the ‘mad rush’ in theindustry for ‘big data experts’ and thegrowth of a new ‘Data Science’ disci-pline. The democratization of onlinecontent creation has led to the increaseof  W e b  d e b r i s ,  w h i c h  i s  i n e v i t a b l y  a n dnegatively affecting information retrievaland extraction. T o analyze this negativetrend and propose possible solutions, this review paper focused on the evolution of NLP research according to three dif-ferent paradigms, namely: bag-of-words, word embeddings, and narrative understanding. Borrowingthe concept of ‘jumping curves’ from the field of business management, this survey article explained how and why NLP research is gradually shifting from lexical semantics to compositional semantics and offered insights on next-generation narrative-based NLP technology. Jumping the curve, however, is not an easy task: the origins of human lan-guage has sometimes been called the hardest problem of science (Christiansen & Kirby, 2003). NLP technologies evolved from the era of punch cards and batch processing (in which the analysis of a natural language sentence could take up to 7 minutes (Plath, 1967)) to the era of Google and the likes of it (in which millions of webpages can be pro-cessed in less than a second). Even the most efficient word-based algorithms, however, perform very poorly, if not properly trained or when contexts and domains change. Such algorithms are limited by the fact that they can process only information that they can ‘see’. Language, however, is a system where all terms are interdependent and where the value of one is the result of the simulta-neous presence of the others (De Sau-ssure, 1916). As human text processors, we ‘see more than what we see’ (David-son, 1997) in which every word acti-vates a cascade of semantically-related concepts that enable the completion of complex NLP tasks, such as word-sense disambiguation, textual entailment, and semantic role labeling, in a quick and effortless way.Concepts are the glue that holds our mental world together (Murphy, 2004). Without concepts, there would be no mental world in the first place (Bloom, 2003). Needless to say, the ability to organize knowledge into concepts is one of the defining characteristics of the human mind. A truly intelligent system needs physical, social  and sensory knowledge56    IEEE COMPUTATIONAL INTELLIGENCE MAGA ZINE | MAY 2014 about the way people think. Having a database of millions of common-sense facts, however, is not enough for   computational natural language understanding: we will need to teach NLP systems how to handle this knowledge (IQ), but also interpret emotions (EQ) and cultural nuances (CQ).References[1] J. Allen. Natural Language Understanding. Redwood City, CA: Benjamin/Cummings, 1987.[2] L. Araujo, “Symbiosis of evolutionary techniques and statistical natural language processing,” IEEE Trans. Evol. Comput., vol. 8, no. 1, pp. 14–27, 2004.[3]N. Asher and A. Lascarides, Logics of Conversation. Cambridge, U.K.: Cambridge Univ. Press, 2003.[4] J. Atkinson-Abutridy, C. Mellish, and S. Aitken, “A semantically guided and domain independent evolution-ary model for knowledge discovery from texts,” IEEE Trans. Evol. Comput., vol. 7, no. 6, pp. 546–560, 2003.[5] J. Barwise, “An introduction to first-order logic,” in Handbook of Mathematical Logic. (Studies in Logic and the Foundations of Mathematics). Amsterdam, The Nether-lands: North-Holland, 1977.[6] A. Berger, V. D. Pietra, and S. D. Pietra, “A maximum entropy approach to natural language processing,” Com-put. Linguistics, vol. 22, no. 1, pp. 39–71, 1996.[7] F. Bex, H. Prakken, and B. Verheij, “Formalizing argumentative story-based analysis of evidence,” in Proc. Int. Conf. Artificial Intelligence Law, 2007, pp. 1-10.[8] P. Bloom, “Glue for the mental world,” Nature, vol. 421, pp. 212–213, Jan. 2003.[9] K. Bollacker, C. Evans, P. Paritosh, T. Sturge, and J. Taylor, “Freebase: A collaboratively created graph database for structuring human knowledge,” in Proc. ACM SIG-MOD Int. Conf. Management Data, 2008, pp. 1247–1250.[10] J. Breslin, A. Harth, U. Bojars, and S. Decker, “To-wards semantically-interlinked online communities,” in The Semantic Web: Research and Applications. Berlin Hei-delberg: Springer-Verlag, 2005, pp. 500–514.[11] D. Brickley and L. Miller. (2010). FOAF vocabu-lary specification 0.98. Namespace Document [Online]. Available: http://xmlns.com/foaf/spec/[12] N. Bush, “The predictive value of transitional prob-ability for word-boundary palatalization in English,” Unpublished M.S .thesis, Univ. New Mexico, Albuquer-que, NM, 1999.[13]J. Bybee and J. Scheibman, “The effect of usage on degrees of constituency: The reduction of don’t in Eng-lish,” Linguistics, vol. 37, no. 4, pp. 575–596, 1999.[14]E. Cambria, P. Gastaldo, F. Bisio, and R. Zunino, “An ELM-based model for affective analogical reason-ing,” Neurocomputing, Special Issue on Extreme Learning Machines, 2014.[15] E. Cambria and A. Hussain, Sentic Computing: Tech-niques, Tools, and Applications. Dordrecht, The Nether-lands: Springer-Verlag, 2012.[16] E. Cambria, D. Rajagopal, D. Olsher, and D. Das, “Big social data analysis,” in Big Data Computing, R. Akerkar, Ed. London: Chapman and Hall, 2013, pp. 401–414.[17]A. Carlson, J. Betteridge, B. Kisiel, B. Settles, E. Hruschka, and T. Mitchell, “Toward an architecture for never-ending language learning,” in Proc. Conf. Artificial Intelligence AAAI, Atlanta, GA, 2010, pp. 1306–1313.[18]J. Carvalho, F. Batista, and L. Coheur, “A critical survey on the use of fuzzy sets in speech and natural lan-guage processing,” in Proc. IEEE Int. Conf. Fuzzy Systems, 2012, pp. 270–277.[19]S. Ceccato, “Correlational analysis and mechani-cal translation,” in Machine Translation, A. D. Booth, Ed. Amsterdam, The Netherlands: North Holland, 1967, pp. 77–135.[20]S. Chan and J. Franklin, “Symbolic connectionism in natural language disambiguation,” IEEE Trans. Neural Netw., vol. 9, no. 5, pp. 739–755, 1998.[21]N. Chomsky, “Three models for the description of language,” IRE Trans. Inform. Theory, vol. 2, no. 3, pp. 113–124, 1956.[22]M. Christiansen and N. Chater, “Connectionist natural language processing: The state of the art,” Cogn. Sci., vol. 23, no. 4, pp. 417–437, 1999.[23] M. Christiansen and S. Kirby, “Language evolution: The hardest problem in science?” in Language Evolution, M. Christiansen and S. Kirby, Eds. Oxford, U.K.: Oxford Univ. Press, 2003. pp. 1–15.[24] K. Church an d  P. Hanks, “Word association norms, mutual information, and lexicography,” in Proc. 27th Annu. Meeting Association Computational Linguistics, 1989, pp. 76–83.[25] W. Cohen, “Learning to classify English text with ILP methods,” in Advances in Inductive Logic Programming, L. De Raedt, Ed. Amsterdam, The Netherlands: IOS Press, 1995, pp. 124–143.[26]W. Cohen and Y. Singer, “Context-sensitive learn-ing methods for text categorization,” ACM Trans. Inform. Syst., vol. 17, no. 2, pp. 141–173, 1999.[27]R. Collobert, J. Weston, L. Bottou, M. Karlen, K. Kavukcuoglu, and P. Kuksa, “Natural language process-ing (almost) from scratch,” J. Mach. Learn. Res., vol. 12, pp. 2493–2537, 2011.[28] F. Costa, P. Frasconi, V. Lombardo, P. Sturt, and G. Soda, “Ambiguity resolution analysis in incremental pars-ing of natural language,” IEEE Trans. Neural Netw., vol. 16, no. 4, pp. 959–971, 2005.[29] D. Davidson, “Seeing through language,” in Royal Institute of Philosophy, Supplement. Cambridge, U.K.: Cambridge Univ. Press, 1997, vol. 42 , pp. 15–28.[30] L. Denoyer, H. Zaragoza, and P. Gallinari, “HMM-based passage models for document classification and ranking,” in Proc. 23rd European Colloq. Information Re-trieval Research, Darmstadt, Germany, 2001.[31] F. de Saussure, Cours de Linguistique Générale. Paris: Payot, 1916.[32]Y. Ding, Y. Jin, L. Ren, and K. Hao, “An intelli-gent self-organization scheme for the Internet of things,” IEEE Comput. Intell. Mag., vol. 8, no. 3, pp. 41–53, 2013.[33] H. Drucker, D. Wu, and V. Vapnik, “Support vector machines for spam categorization,” IEEE Trans. Neural Netw., vol. 10, no. 5, pp. 1048–1054, 1999.[34] M. Dyer, “Connectionist natural language pro-cessing: A status report,” in Computational Architectures Integrating Neural and Symbolic Processes, R. Sun and L. Bookman, Eds. Dordrecht, The Netherlands: Kluwer Academic, 1995, vol. 292, pp. 389–429.[35] N. Eagle, P. Singh, and A. Pentland, “Common sense conversations: Understanding casual conversation using a common sense database,” in Proc. Int. Joint Conf. Artificial Intelligence, 2003.[36]C. Fellbaum, WordNet: An Electronic Lexical Database(language, speech, and communication). Cambridge, MA: The MIT Press, 1998.[37] M. Finlayson and P. Winston, “Narrative is a key cognitive competency,” in Proc. 2nd Annu. Meeting Bio-logically Inspired Cognitive Architectures, 2011, p. 110.[38]P. Frasconi, G. Soda, and A. Vullo, “Text categori-zation for multi-page documents: A hybrid naive Bayes HMM approach,” J. Intell. Inform. Syst., vol. 18, nos. 2–3, pp. 195–217, 2001.[39] A. Gangemi, V. Presutti, D. Reforgiato, “Frame-based detection of opinion holders and topics: A model and a tool,” IEEE Comput. Intell. Mag., vol. 9, no. 1, pp. 20–30, 2014.[40] A. Ghandar, Z. Michalewicz, M. Schmidt, T. To, and R. Zurbruegg, “Computational intelligence for evolving trading rules,” IEEE Trans. Evol. Comput., vol. 13, no. 1, pp. 71–86, 2009.[41] J. Godfrey, E. Holliman, and J. McDaniel, “Switch-board: Telephone speech corpus for research and develop-ment,” in Proc. IEEE Int. Conf. Acoustics, Speech, Signal Processing, 1992, pp. 517–520. MAY 2014 | IEEE COMPUTATIONAL INTELLIGENCE MAGAZINE    57[42] A. Goldberg, “Constructions: A new theoretical ap-proach to language,” Trends Cogn. Sci., vol. 7, no. 5, pp. 219–224, 2003.[43] D. Goldberg, Genetic Algorithms in Search, Optimization, and Machine Learning. Reading, MA: Addison-Wesley, 1989.[44] C. Gueret, S. Schlobach, K. Dentler, M. Schut, and G.Eiben, “Evolutionary and swarm computing for the semantic Web,” IEEE Comput. Intell. Mag., vol. 7, no. 2, pp. 16–31, 2012.[45] E. Günes and D. Radev, “LexRank: Graph-based lexical centrality as salience in text summarization,” J. Artif. Intell. Res., vol. 22, no. 1, pp. 457–479, 2004.[46] K. Hayden, D. Novy, C. Havasi, M. Bove, S. Alfaro, and R. Speer, “Narratarium: An immersive storytelling environment,” in Proc. Human-Computer Interaction, 2013, vol. 374, pp. 536–540.[47] M. Hearst, “Automatic acquisition of hyponyms from large text corpora,” in Proc. 14th Conf. Computational Linguistics, 1992, pp. 539–545.[48]J. Heflin and J. Hendler, “Shoe: A knowledge rep-resentation language for internet applications,” Univ. Maryland, College Park, Maryland, Tech. Rep., 1999.[49] T. Hofmann, “Probabilistic latent semantic index-ing,” in Proc. 22nd Annu. Int. ACM SIGIR Conf. Research Development Information Retrieval, 1999, p. 50–57.[50] T. Hofmann, “Unsupervised learning by probabilis-tic latent semantic analysis,” Machine Learn., vol. 42, nos. 1–2, pp. 177–196, 2001.[51] N. Howard a n d  E. Cambria, “Intention awareness: Improving upon situation awareness in human-centric en-vironments,” Human-Centric Computing Information Sciences. vol. 3, Cambridge, MA: Springer-Verlag, 2013. no. 9. [52] N. Imparato and O. Harari, Jumping the Curve: In-novation and Strategic Choice in An Age of Transition. San Francisco, CA: Jossey-Bass, 1996.[53] P. Jackson and I. Moulinier, Natural Language Pro-cessing for Online Applications: Text Retrieval, Extraction and Categorization. Philadelphia, PA: John Benjamins. 1997.[54]T. Joachims, Learning To Classify Text Using Support Vector Machines: Methods, Theory and Algorithms. Norwell, MA: Kluwer Academic, 2002.[55] K. Jones and J. Galliers, “Evaluating natural language processing systems: An analysis and review,” Comput. Lin-guistics, vol. 24, no. 2, 1995.[56]D. Jurafsky, A. Bell, M. Gregory, W. Raymond, J. Bybee, and P. Hopper, Probabilistic Relations Between Words: Evidence From Reduction In Lexical Production. Am-sterdam, The Netherlands: John Benjamins, 2000.[57] J. Kacprzyk and S. Zadrozny, “Computing with words is an implementable paradigm: Fuzzy queries, linguistic data summaries, and natural-language gen-eration,” IEEE Trans. Fuzzy Syst., vol. 18, no. 3, pp. 461–472. 2010.[58] J. Kahan, “Annotea: An open RDF infrastructure for shared web annotations,” Comput. Netw., vol. 39, no.5, pp. 589–608, 2002.[59] A. Kazemzadeh, S. Lee, and S. Narayanan, “Fuzzy logic models for the meaning of emotion words,” IEEE Comput. Intell. Mag., vol. 8, no. 2, pp. 34–49, 2013.[60] M. Krug, “String frequency: A cognitive motivating factor in coalescence, language processing, and linguistic change,” J. Eng. Linguistics, vol. 26, no. 4, pp. 286–320, 1998.[61] H. Kucera and N. Francis, “Computational analysis of present-day American English,” Int. J. Amer. Linguis-tics, vol. 35, no. 1, pp. 71–75, 1969.[62] J. Lafferty, A. McCallum, and F. Pereira, “Condi-tional random fields: Probabilistic models for segment-ing and labeling sequence data,” in Proc. 18th Int. Conf. Machine Learning, 2001, pp. 282–289.[63] L. Lai, C. Wu, P. Lin, and L. Huang, “Developing a fuzzy search engine based on fuzzy ontology and seman-tic search,” in Proc. IEEE Int. Conf. Fuzzy Systems, Taipei, Taiwan, 2011, pp. 2684–2689. [64] R. Lau, Y. Xia, and Y. Ye, “A probabilistic generative model for mining cybercriminal networks from online social media,” IEEE Comput. Intell. Mag., vol. 9, no. 1, pp. 31–43, 2014.[65] S. Lawrence, C. Giles, and S. Fong, “Natural lan-guage grammatical inference with recurrent neural net-works,” IEEE Trans. Knowledge. Data Eng., vol. 12, no. 1, pp. 126–140, 2000.[66] D. Lenat and R. Guha, Building Large Knowledge-Based Systems: Representation and Inference in the Cyc Project. Boston, MA: Addison-Wesley, 1989.[67] C. Liu, G. Qi, H. Wang, and Y. Yu, “Reasoning with large scale ontologies in fuzzy pD* using mapreduce,” IEEE Comput. Intell. Mag., vol. 7, no. 27, pp. 54–66, 2012.[68] H. Liu, H. Lieberman, and T. Selker, “A model of textual affect sensing using real-world knowledge,” in Proc. 8th Int. Conf. Intelligent User Interfaces, 2003, pp. 125–132.[69] M. Luong, R. Socher, and C. Manning, “Better word representations with recursive neural networks for mor-phology,” in Proc. Conf. Natural Language Learning, 2013.[70] R. Magritte, “Les mots et les images,” La Révolution surréaliste, no. 12, 1929.[71] K. Mahesh, S. Nirenburg, and A. Tucker, Knowledge-Based Systems for Natural Language Processing. Boca Raton, FL: CRC Press, 1997.[72] C. Manning, and H. Schütze, Foundations of Statistical Natural Language Processing. Cambridge, MA: MIT press, 1999.[73] M. Marcus, B. Santorini, and M. Marcinkiewicz, “Building a large annotated corpus of english: The penn treebank,” Comput. Linguistics, vol. 19, no. 2, pp. 313–330, 1994.[74] H. Martinez, Y. Bengio, and G. Yannakakis, “Learn-ing deep physiological models of affect,” IEEE Comput. Intell. Mag., vol. 8, no. 2, pp. 20–33, 2013.[75] D. McGuinness and F. Van Harmelen, OWL web ontology language overview, W3C recommendation, 2004.[76] R. Mihalcea and P. Tarau, “TextRank: Bringing or-der into texts,” in Proc. Conf. Empirical Methods Natural Language Processing, Barcelona, 2004.[77]A. Miles and S. Bechhofer, “SKOS simple knowl-edge organization system reference,” W3C Recommenda-tion, Tech. Rep. 2009.[78]M. Minsky, Semantic Information Processing. Cam-bridge, MA: MIT Press, 1968.[79] M. Minsky, The Society of Mind. New York: Simon and Schuster, 1986.[80] E. Mueller, Natural Language Processing with Thought-Treasure. New York: Signifonn, 1998.[81] E. Mueller, “Modeling space and time in narratives about restaurants,” Literary Linguistic Comput., vol. 22, no. 1, pp. 67–84, 2007.[82]I. Mukherjee, and D. Blei, “Relative performance guarantees for approximate inference in latent dirichlet allocation,” in Proc. Neural Information Processing Systems,Vancouver, BC, 2009, pp. 1129–1136.[83]G. Murphy, The Big Book of Concepts. Cambridge, MA: MIT Press, 2004.[84] K. Nigam, A. McCallum, S. Thrun, and T. Mitchell, “Text classification from labeled and unlabeled docu-ments using EM,” Machine Learn., vol. 39, nos. 2–3, pp. 103–134, 2000.[85] V. Novak, “Fuzzy sets in natural language process-ing,” in An Introduction to Fuzzy Logic Applications in Intelli-gent Systems, Yager Ed. Norwell, MA: Kluwer Academic, 1992, pp. 185–200.[86]D. Olsher, “COGVIEW & INTELNET: Nuanced energy-based knowledge representation and integrated cognitive-conceptual framework for realistic culture, values, and concept-affected systems simulation,” in Proc. 2013 IEEE Symp. Computational Intelligence Human-Like Intelligence, Singapore, 2013, pp. 82–91.[87] M. O’Neill an d  C. Ryan, “Grammatical evolution,” IEEE Trans. Evol. Comput., vol. 5, no. 4, pp. 349–358, 2001.[88] A. Ortony, G. Clore, and A. Collins, “The cognitive structure of emotions,” Cambridge, U.K.: Cambridge Univ. Press, 1988.[89] L. Page, S. Brin, R. Motwani, and T. Winograd, “The pagerank citation ranking: bringing order to the web,” Stanford Univ., Stanford, CA, Tech. Rep., 1999.[90]J. Pearl, “Bayesian networks: A model of self-acti-vated memory for evidential reasoning,” UCLA comput. Sci., Irvine, CA: Tech. Rep. CSD-850017, 1985.[91]W. Plath, “Multiple path analysis and automatic translation,” in Machine Translation, A. D. Booth, Ed. Amsterdam, The Netherlands: North-Holland, 1967, pp. 267–315.[92]S. Ponzetto and M. Strube, “Deriving a large-scale taxonomy from Wikipedia,” in Proc. AAAI’07 22nd Nat. Conf. Artificial Intelligence, Vancouver, BC, 2007, pp. 1440–1445.[93]S. Poria, A. Gelbukh, A. Hussain, D. Das, and S. Bandyopadhyay, “Enhanced SenticNet with affective labels for concept-based opinion mining,” IEEE Intell. Syst., vol. 28, no. 2, pp. 31–38, 2013.[94] I. Porteous, I. Newman, A. Ihler, A. Asuncion, P.Smyth, and M. Welling, “Fast collapsed Gibbs sampling for latent dirichlet allocation,” in Proc. 14th ACM SIG-KDD Int. Conf. Knowledge Discovery Data Mining, 2008, pp. 569–577.[95] R. Quillian, “A notation for representing conceptual information: An application to semantics and mechanical english paraphrasing,” System Development Corp., Santa Monica, California, Tech. Rep. SP-1395, 1963.[96] R. Reiter, “A logic for default reasoning,” Artificial Intell., vol. 13, pp. 81–132, 1980.[97]W. Richards, M. Finlayson, and P. Winston, “Ad-vancing computational models of narrative,” MIT Com-puter Science and Artificial Intelligence Laboratory, Cambridge, MA, Tech. Rep. 2009-063, 2009.[98] R. Schank, Conceptual Information Processing. Amster-dam, The Netherlands: Elsevier Science Inc., 1975.[99] B. Schölkopf, S. Mika, C. Burges, P. Knirsch, K.-R.Müller, G. Rätsch, and A. Smola, “Input space versus fea-ture space in kernel-based methods,” IEEE Trans. Neural Netw., vol. 10, no. 5, pp. 1000–1017, 1999.[100] F. Sebastiani, “Machine learning in automated text categorization,” ACM Comput. Surv., vol. 34, no. 1, pp. 1–47, 2002.[101]R. Simmons, “Synthetic language behavior,” Data Processing Manage., vol. 5, no. 12, pp. 11–18, 1963.[102]P. Singh. (2002). The open mind common sense project. [Online]. Available: http://www.kurzweilai.net/[103] J. Sowa, “Semantic networks,” in Encyclopedia of Ar-tificial Intelligence, S. Shapiro, Ed. New York: Wiley, 1987.[104] R. Stevenson, J. Mikels, and T. James, “Character-ization of the affective norms for english words by dis-crete emotional categories,” Behav. Res. Methods, vol. 39, no. 4, pp. 1020–1024, 2007.[105] P. Subasic and A. Huettner, “Affect analysis of text using fuzzy semantic typing,” IEEE Trans. Fuzzy Syst., vol. 9, no. 4, pp. 483–496, 2001.[106]F. Suchanek, G. Kasneci, and G. Weikum, “Yago: A core of semantic knowledge,” in Proc. 16th Int. World Wide Web Conf., 2007. pp. 697–706.[107]P. Winston, “The strong story hypothesis and the directed perception hypothesis,” in Proc. AAAi Fall Symp.: Advances Cognitive Systems, 2011.[108] W. Wu, H. Li, H. Wang, and K. Zhu, “Probase: A probabilistic taxonomy for text understanding,” in Proc. ACM SIGMOD Int. Conf. Management Data, Scottsdale, AZ, 2012, pp. 481–492.[109]R. Xia, C. Zong, X. Hu, and E. Cambria, “Fea-ture ensemble plus sample selection: A comprehensive approach to domain adaptation for sentiment classifica-tion,” IEEE Intell. Syst., vol. 28, no. 3, pp. 10–18, 2013.[110] R. Young, “Story and discourse: A bipartite model of narrative generation in virtual worlds,” Interaction Stud-ies, vol. 8, pp. 177–208, 2007.[111] H. Zellig, “Distributional structure,” Word, vol. 10, pp. 146–162, 1954.']],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': [[{'title': '자연어처리'}]],\n",
       " 'distances': [[1.0148909801179846]],\n",
       " 'included': [<IncludeEnum.distances: 'distances'>,\n",
       "  <IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_text = 'Natural Language'\n",
    "query_embedding = model.encode(query_text).tolist()\n",
    "results = collection.query(query_embeddings=[query_embedding], n_results=1)\n",
    "\n",
    "results['metadatas'][0][0]['title']\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vectordb_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
