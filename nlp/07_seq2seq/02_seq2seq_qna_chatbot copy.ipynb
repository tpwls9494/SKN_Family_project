{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq Q&A Chatbot 구현 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 취득"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>티가 나니까 눈치가 보이는 거죠!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>훔쳐보는 거 티나나봐요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>흑기사 해주는 짝남.</td>\n",
       "      <td>설렜겠어요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>힘든 연애 좋은 연애라는게 무슨 차이일까?</td>\n",
       "      <td>잘 헤어질 수 있는 사이 여부인 거 같아요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11822</th>\n",
       "      <td>힘들어서 결혼할까봐</td>\n",
       "      <td>도피성 결혼은 하지 않길 바라요.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11823 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Q                         A\n",
       "0                       12시 땡!                하루가 또 가네요.\n",
       "1                  1지망 학교 떨어졌어                 위로해 드립니다.\n",
       "2                 3박4일 놀러가고 싶다               여행은 언제나 좋죠.\n",
       "3              3박4일 정도 놀러가고 싶다               여행은 언제나 좋죠.\n",
       "4                      PPL 심하네                눈살이 찌푸려지죠.\n",
       "...                        ...                       ...\n",
       "11818           훔쳐보는 것도 눈치 보임.        티가 나니까 눈치가 보이는 거죠!\n",
       "11819           훔쳐보는 것도 눈치 보임.             훔쳐보는 거 티나나봐요.\n",
       "11820              흑기사 해주는 짝남.                    설렜겠어요.\n",
       "11821  힘든 연애 좋은 연애라는게 무슨 차이일까?  잘 헤어질 수 있는 사이 여부인 거 같아요.\n",
       "11822               힘들어서 결혼할까봐        도피성 결혼은 하지 않길 바라요.\n",
       "\n",
       "[11823 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습용 텍스트 파일 생성 (Q + A)\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/songys/Chatbot_data/refs/heads/master/ChatbotData.csv')\n",
    "df = df[['Q', 'A']]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 답변을 각각 배열로 저장\n",
    "all_texts = []\n",
    "Q_texts = []\n",
    "A_texts = []\n",
    "\n",
    "for Q, A in df.values:\n",
    "    Q_texts.append(Q)\n",
    "    A_texts.append(A)\n",
    "\n",
    "all_texts = Q_texts + A_texts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습용 텍스트 파일 생성 (Q + A)\n",
    "with open('chatbot_qna.txt', 'w', encoding='utf-8') as f:\n",
    "    for text in all_texts:\n",
    "        f.write(text + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 토커나이저 학습 (sentencepiece 활용)\n",
    "- 접두사, 접미사 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(178) LOG(INFO) Running command: --input=chatbot_qna.txt --pad_id=0 --bos_id=1 --eos_id=2 --unk_id=3 --model_prefix=chatbot_qna --vocab_size=5000\n",
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: chatbot_qna.txt\n",
      "  input_format: \n",
      "  model_prefix: chatbot_qna\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 5000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 3\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: 0\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: chatbot_qna.txt\n",
      "trainer_interface.cc(409) LOG(INFO) Loaded all 23646 sentences\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(539) LOG(INFO) all chars count=353449\n",
      "trainer_interface.cc(550) LOG(INFO) Done: 99.9502% characters are covered.\n",
      "trainer_interface.cc(560) LOG(INFO) Alphabet size=1085\n",
      "trainer_interface.cc(561) LOG(INFO) Final character coverage=0.999502\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 23646 sentences.\n",
      "unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=162596\n",
      "unigram_model_trainer.cc(312) LOG(INFO) Initialized 18866 seed sentencepieces\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 23646\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 21781\n",
      "unigram_model_trainer.cc(602) LOG(INFO) Using 21781 sentences for EM training\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=10912 obj=13.23 num_tokens=46285 num_tokens/piece=4.24166\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=9598 obj=12.125 num_tokens=46421 num_tokens/piece=4.83653\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=7198 obj=12.468 num_tokens=49444 num_tokens/piece=6.86913\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=7197 obj=12.4111 num_tokens=49478 num_tokens/piece=6.87481\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=5500 obj=12.8775 num_tokens=53312 num_tokens/piece=9.69309\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=5500 obj=12.8031 num_tokens=53312 num_tokens/piece=9.69309\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: chatbot_qna.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: chatbot_qna.vocab\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "input_text = 'chatbot_qna.txt'\n",
    "pad_id = 0\n",
    "vocab_size = 5000\n",
    "prefix = 'chatbot_qna'\n",
    "bos_id = 1  # <sos>\n",
    "eos_id = 2  # <eos>\n",
    "unk_id = 3  # <oov>\n",
    "\n",
    "cmd = f'--input={input_text} --pad_id={pad_id} --bos_id={bos_id} --eos_id={eos_id} --unk_id={unk_id} --model_prefix={prefix} --vocab_size={vocab_size}'\n",
    "\n",
    "spm.SentencePieceTrainer.Train(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(f'{prefix}.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁오늘', '은', '▁즐거', '운', '▁수', '요', '일']\n",
      "[78, 15, 850, 170, 20, 6, 76]\n",
      "오늘은 즐거운 수요일\n",
      "오늘은 즐거운 수요일\n"
     ]
    }
   ],
   "source": [
    "vocab_size = sp.get_piece_size()\n",
    "# print(vocab_size)\n",
    "tokens = sp.encode_as_pieces('오늘은 즐거운 수요일')\n",
    "print(tokens)\n",
    "seq = sp.encode_as_ids('오늘은 즐거운 수요일')\n",
    "print(seq)\n",
    "text = sp.decode_pieces(tokens)\n",
    "print(text)\n",
    "text = sp.decode_ids(seq)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 학습용 데이터 Q_input, A_input, A_target 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4228, 299, 5, 4826, 72],\n",
       " [291, 14, 933, 674, 1735],\n",
       " [277, 1280, 2810, 76, 2964, 94],\n",
       " [277, 1280, 2810, 76, 667, 2964, 94],\n",
       " [5, 4549, 4549, 3, 1395, 64]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.set_encode_extra_options(':')\n",
    "Q_inputs = [sp.encode_as_ids(q) for q in Q_texts]\n",
    "Q_inputs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 282, 7, 113, 82, 23, 4],\n",
       " [1, 1459, 5, 3717, 4],\n",
       " [1, 293, 15, 385, 39, 207, 4],\n",
       " [1, 293, 15, 385, 39, 207, 4],\n",
       " [1, 208, 970, 10, 2434, 3090, 173, 14, 40, 4]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.set_encode_extra_options('bos:')\n",
    "A_inputs = [sp.encode_as_ids(a) for a in A_texts]\n",
    "A_inputs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[282, 7, 113, 82, 23, 4, 2],\n",
       " [1459, 5, 3717, 4, 2],\n",
       " [293, 15, 385, 39, 207, 4, 2],\n",
       " [293, 15, 385, 39, 207, 4, 2],\n",
       " [208, 970, 10, 2434, 3090, 173, 14, 40, 4, 2]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.set_encode_extra_options(':eos')\n",
    "A_targets = [sp.encode_as_ids(a) for a in A_texts]\n",
    "A_targets[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 최대 길이 확인\n",
    "Q_max_len = max([len(seq) for seq in Q_inputs])\n",
    "A_max_len = max([len(seq) for seq in A_inputs])\n",
    "Q_max_len, A_max_len\n",
    "\n",
    "plt.hist([len(seq) for seq in Q_inputs + A_inputs])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "Q_inputs_padded = pad_sequences(Q_inputs, maxlen=MAX_LEN, padding='pre', truncating='post')\n",
    "A_inputs_padded = pad_sequences(A_inputs, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "A_targets_padded = pad_sequences(A_targets, maxlen=MAX_LEN, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 인코더 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "EMBEDDING_DIM = 100\n",
    "LATENT_DIM = 128\n",
    "\n",
    "encoder_input = layers.Input(shape=(MAX_LEN,))\n",
    "q_embedding = layers.Embedding(vocab_size + 1, EMBEDDING_DIM)\n",
    "x = q_embedding(encoder_input)\n",
    "_, h, c = layers.LSTM(LATENT_DIM, return_state=True)(x)\n",
    "encoder_states = [h, c]\n",
    "\n",
    "encoder_model = models.Model(inputs=encoder_input, outputs=encoder_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 디코더 (teacher-forcing 모델) 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = layers.Input(shape=[MAX_LEN,])\n",
    "a_embedding = layers.Embedding(vocab_size + 1, EMBEDDING_DIM)\n",
    "x = a_embedding(decoder_input)\n",
    "decoder_lstm = layers.LSTM(LATENT_DIM, return_sequences=True, return_state=True)\n",
    "x, _, _ = decoder_lstm(x, initial_state=encoder_states)\n",
    "decoder_dense = layers.Dense(vocab_size + 1, activation='softmax')\n",
    "decoder_output = decoder_dense(x)\n",
    "\n",
    "decoder_teacher_forcing_model = models.Model(inputs=[encoder_input, decoder_input], outputs=decoder_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 322ms/step - accuracy: 0.7655 - loss: 1.5719 - val_accuracy: 0.7618 - val_loss: 1.7010\n",
      "Epoch 2/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 340ms/step - accuracy: 0.8050 - loss: 1.3304 - val_accuracy: 0.7667 - val_loss: 1.6528\n",
      "Epoch 3/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 326ms/step - accuracy: 0.8077 - loss: 1.2806 - val_accuracy: 0.7700 - val_loss: 1.6279\n",
      "Epoch 4/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 328ms/step - accuracy: 0.8122 - loss: 1.2360 - val_accuracy: 0.7732 - val_loss: 1.6091\n",
      "Epoch 5/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 344ms/step - accuracy: 0.8146 - loss: 1.2057 - val_accuracy: 0.7765 - val_loss: 1.5915\n",
      "Epoch 6/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 320ms/step - accuracy: 0.8180 - loss: 1.1718 - val_accuracy: 0.7797 - val_loss: 1.5727\n",
      "Epoch 7/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 293ms/step - accuracy: 0.8215 - loss: 1.1410 - val_accuracy: 0.7824 - val_loss: 1.5540\n",
      "Epoch 8/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 325ms/step - accuracy: 0.8277 - loss: 1.0910 - val_accuracy: 0.7858 - val_loss: 1.5423\n",
      "Epoch 9/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 318ms/step - accuracy: 0.8307 - loss: 1.0644 - val_accuracy: 0.7881 - val_loss: 1.5276\n",
      "Epoch 10/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 314ms/step - accuracy: 0.8338 - loss: 1.0366 - val_accuracy: 0.7894 - val_loss: 1.5176\n",
      "Epoch 11/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 324ms/step - accuracy: 0.8385 - loss: 0.9990 - val_accuracy: 0.7915 - val_loss: 1.5094\n",
      "Epoch 12/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 315ms/step - accuracy: 0.8401 - loss: 0.9729 - val_accuracy: 0.7924 - val_loss: 1.5054\n",
      "Epoch 13/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 314ms/step - accuracy: 0.8435 - loss: 0.9425 - val_accuracy: 0.7926 - val_loss: 1.5052\n",
      "Epoch 14/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 309ms/step - accuracy: 0.8457 - loss: 0.9186 - val_accuracy: 0.7926 - val_loss: 1.5090\n",
      "Epoch 15/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 299ms/step - accuracy: 0.8477 - loss: 0.8972 - val_accuracy: 0.7933 - val_loss: 1.5112\n",
      "Epoch 16/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 322ms/step - accuracy: 0.8517 - loss: 0.8628 - val_accuracy: 0.7933 - val_loss: 1.5142\n",
      "Epoch 17/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 345ms/step - accuracy: 0.8540 - loss: 0.8433 - val_accuracy: 0.7938 - val_loss: 1.5175\n",
      "Epoch 18/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 321ms/step - accuracy: 0.8567 - loss: 0.8212 - val_accuracy: 0.7939 - val_loss: 1.5243\n",
      "Epoch 19/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 324ms/step - accuracy: 0.8598 - loss: 0.7977 - val_accuracy: 0.7936 - val_loss: 1.5275\n",
      "Epoch 20/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 291ms/step - accuracy: 0.8640 - loss: 0.7636 - val_accuracy: 0.7942 - val_loss: 1.5349\n",
      "Epoch 21/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 311ms/step - accuracy: 0.8670 - loss: 0.7413 - val_accuracy: 0.7943 - val_loss: 1.5416\n",
      "Epoch 22/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 316ms/step - accuracy: 0.8696 - loss: 0.7220 - val_accuracy: 0.7940 - val_loss: 1.5502\n",
      "Epoch 23/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 276ms/step - accuracy: 0.8742 - loss: 0.6912 - val_accuracy: 0.7943 - val_loss: 1.5600\n",
      "Epoch 24/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 312ms/step - accuracy: 0.8757 - loss: 0.6773 - val_accuracy: 0.7946 - val_loss: 1.5645\n",
      "Epoch 25/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 308ms/step - accuracy: 0.8786 - loss: 0.6595 - val_accuracy: 0.7946 - val_loss: 1.5791\n",
      "Epoch 26/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 303ms/step - accuracy: 0.8822 - loss: 0.6354 - val_accuracy: 0.7946 - val_loss: 1.5901\n",
      "Epoch 27/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 292ms/step - accuracy: 0.8850 - loss: 0.6210 - val_accuracy: 0.7943 - val_loss: 1.6020\n",
      "Epoch 28/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 291ms/step - accuracy: 0.8877 - loss: 0.6006 - val_accuracy: 0.7944 - val_loss: 1.6129\n",
      "Epoch 29/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 301ms/step - accuracy: 0.8917 - loss: 0.5804 - val_accuracy: 0.7937 - val_loss: 1.6243\n",
      "Epoch 30/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 295ms/step - accuracy: 0.8937 - loss: 0.5668 - val_accuracy: 0.7940 - val_loss: 1.6366\n",
      "Epoch 31/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 306ms/step - accuracy: 0.8975 - loss: 0.5482 - val_accuracy: 0.7938 - val_loss: 1.6509\n",
      "Epoch 32/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 297ms/step - accuracy: 0.9004 - loss: 0.5289 - val_accuracy: 0.7943 - val_loss: 1.6601\n",
      "Epoch 33/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 292ms/step - accuracy: 0.9024 - loss: 0.5173 - val_accuracy: 0.7934 - val_loss: 1.6754\n",
      "Epoch 34/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 328ms/step - accuracy: 0.9065 - loss: 0.4959 - val_accuracy: 0.7933 - val_loss: 1.6902\n",
      "Epoch 35/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 293ms/step - accuracy: 0.9097 - loss: 0.4782 - val_accuracy: 0.7934 - val_loss: 1.6983\n",
      "Epoch 36/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 296ms/step - accuracy: 0.9121 - loss: 0.4665 - val_accuracy: 0.7931 - val_loss: 1.7157\n",
      "Epoch 37/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 339ms/step - accuracy: 0.9150 - loss: 0.4476 - val_accuracy: 0.7936 - val_loss: 1.7303\n",
      "Epoch 38/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 289ms/step - accuracy: 0.9176 - loss: 0.4345 - val_accuracy: 0.7931 - val_loss: 1.7456\n",
      "Epoch 39/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 286ms/step - accuracy: 0.9197 - loss: 0.4236 - val_accuracy: 0.7931 - val_loss: 1.7607\n",
      "Epoch 40/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 283ms/step - accuracy: 0.9222 - loss: 0.4118 - val_accuracy: 0.7927 - val_loss: 1.7741\n",
      "Epoch 41/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 277ms/step - accuracy: 0.9252 - loss: 0.3958 - val_accuracy: 0.7929 - val_loss: 1.7860\n",
      "Epoch 42/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 290ms/step - accuracy: 0.9274 - loss: 0.3829 - val_accuracy: 0.7926 - val_loss: 1.8013\n",
      "Epoch 43/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 295ms/step - accuracy: 0.9290 - loss: 0.3740 - val_accuracy: 0.7929 - val_loss: 1.8176\n",
      "Epoch 44/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 294ms/step - accuracy: 0.9306 - loss: 0.3651 - val_accuracy: 0.7925 - val_loss: 1.8320\n",
      "Epoch 45/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 284ms/step - accuracy: 0.9328 - loss: 0.3527 - val_accuracy: 0.7924 - val_loss: 1.8476\n",
      "Epoch 46/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 282ms/step - accuracy: 0.9353 - loss: 0.3429 - val_accuracy: 0.7921 - val_loss: 1.8622\n",
      "Epoch 47/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 305ms/step - accuracy: 0.9385 - loss: 0.3263 - val_accuracy: 0.7920 - val_loss: 1.8775\n",
      "Epoch 48/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 291ms/step - accuracy: 0.9410 - loss: 0.3162 - val_accuracy: 0.7919 - val_loss: 1.8952\n",
      "Epoch 49/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 289ms/step - accuracy: 0.9428 - loss: 0.3058 - val_accuracy: 0.7918 - val_loss: 1.9105\n",
      "Epoch 50/50\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 323ms/step - accuracy: 0.9449 - loss: 0.2974 - val_accuracy: 0.7920 - val_loss: 1.9249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1475f0f70>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_teacher_forcing_model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "decoder_teacher_forcing_model.fit(\n",
    "    [Q_inputs_padded, A_inputs_padded],\n",
    "    A_targets_padded,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 디코더 (추론 모델) 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_hidden_state = layers.Input(shape=(LATENT_DIM,))\n",
    "decoder_cell_state = layers.Input(shape=(LATENT_DIM,))\n",
    "decoder_state_inputs = [decoder_hidden_state, decoder_cell_state]\n",
    "\n",
    "decoder_single_input = layers.Input(shape=(1,))\n",
    "x = a_embedding(decoder_single_input)\n",
    "\n",
    "x, h, c = decoder_lstm(x, initial_state=decoder_state_inputs)\n",
    "decoder_states = [h, c]\n",
    "\n",
    "output = decoder_dense(x)\n",
    "\n",
    "decoder_inference_model = models.Model(\n",
    "    inputs=[decoder_single_input] + decoder_state_inputs,\n",
    "    outputs=[output] + decoder_states    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추론 함수\n",
    "- 추론 함수 생성 및 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qna_chatbot(input_seq, temperature=1.0):\n",
    "    # 인코더\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # 디코더\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    bos_id = sp.bos_id()\n",
    "    eos_id = sp.eos_id()\n",
    "    target_seq[0, 0] = bos_id\n",
    "\n",
    "    output_ids = []\n",
    "\n",
    "    for _ in range(MAX_LEN):\n",
    "        output, h, c = decoder_inference_model.predict([target_seq] + states_value)\n",
    "\n",
    "        pred_proba = output[0, 0, :]\n",
    "        \n",
    "        pred_proba = np.log(pred_proba + 1e-10) / temperature\n",
    "        pred_proba = np.exp(pred_proba) / np.sum(np.exp(pred_proba))  # 소프트맥스 \n",
    "        pred_id = np.random.choice(len(pred_proba), p=pred_proba)\n",
    "\n",
    "        if pred_id == eos_id:\n",
    "            break\n",
    "\n",
    "        if pred_id > 0:\n",
    "            output_ids.append(int(pred_id))\n",
    "\n",
    "        target_seq[0, 0] = pred_id\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return sp.decode_ids(output_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 간단한 챗봇 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "답변: 후회해도 그래요.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "답변: 지금은 우세요.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "답변: 용기를 팍팍 내요!\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "답변: 똑같이너 후에 다를 해봐요.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    text = input('질문: ')\n",
    "\n",
    "    if text.lower() == 'exit':\n",
    "        break\n",
    "\n",
    "    input_seq = sp.encode_as_ids(text)\n",
    "    input_seq = pad_sequences([input_seq], maxlen=MAX_LEN, padding='pre', truncating='post')\n",
    "    output = qna_chatbot(input_seq)\n",
    "    print('답변:', output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
