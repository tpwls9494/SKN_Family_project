{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (설명 깃 참고)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec\n",
    "- 2013년 구글에서 개발한 Word Embedding 방법\n",
    "- 최초의 neural embedding model\n",
    "- 매우 큰 corpus에서 자동 학습\n",
    "    - 비지도 지도 학습 (자기 지도학습)이라 할 수 있음\n",
    "    - 많은 데이터를 기반으로 label 값 유추하고 이를 지도학습에 사용\n",
    "- ex)\n",
    "    - **이사금**께 충성을 맹세하였다.\n",
    "    - **왕**께 충성을 맹세하였다.\n",
    "\n",
    "**WordVec 훈련 방식에 따른 구분**\n",
    "1. CBOW : 주변 단어로 중심 단어를 예측\n",
    "2. Skip-gram : 중심 단어로 주변 단어를 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CBOW (Continuous Bag of Words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Skip-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 영어 Word Embedding\n",
    "- 데이터 취득 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "\n",
    "# url = 'https://drive.google.com/uc?id=1DCgLPJsfyLGZ99lB-aF8EvpKIWSZYgp4'\n",
    "# output = 'ted_en.xml'\n",
    "\n",
    "# gdown.download(url, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24062319\n"
     ]
    }
   ],
   "source": [
    "# xml 데이터 처리\n",
    "f = open('ted_en.xml', 'r', encoding='utf-8')\n",
    "xml = etree.parse(f)\n",
    "\n",
    "contents = xml.xpath('//content/text()')    # content 태그 하위 텍스트\n",
    "# print(contents[:5])\n",
    "\n",
    "corpus = '\\n'.join(contents)\n",
    "# print(corpus)\n",
    "\n",
    "# 정규식을 이용해 (Laughter), (Applause) 등 키워드 제거\n",
    "corpus = re.sub(r'\\([^)]*\\)', '', corpus)\n",
    "print(len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['two', 'reasons', 'companies', 'fail', 'new'],\n",
       " ['real',\n",
       "  'real',\n",
       "  'solution',\n",
       "  'quality',\n",
       "  'growth',\n",
       "  'figuring',\n",
       "  'balance',\n",
       "  'two',\n",
       "  'activities',\n",
       "  'exploration',\n",
       "  'exploitation'],\n",
       " ['necessary', 'much', 'good', 'thing'],\n",
       " ['consider', 'facit'],\n",
       " ['actually', 'old', 'enough', 'remember']]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = sent_tokenize(corpus)\n",
    "\n",
    "preprocessed_sentences = []\n",
    "en_stopwords = stopwords.words('english')\n",
    "\n",
    "for sentence in sentences:\n",
    "    sentence = sentence.lower() # 소문자 변환\n",
    "    sentence = re.sub(r'[^a-z0-9]', ' ', sentence)  # 들여쓰기를 써서 빈 문자로 치환해 위치를 확인하기 위함\n",
    "    tokens = word_tokenize(sentence)    # 문장 토큰화\n",
    "    tokens = [token for token in tokens if token not in en_stopwords]   # 불용어 제거\n",
    "    preprocessed_sentences.append(tokens)\n",
    "\n",
    "preprocessed_sentences[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Embedding 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21462, 100)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec(\n",
    "    sentences=preprocessed_sentences,   # corpur\n",
    "    vector_size=100,                    # 임베딩 백터 차원\n",
    "    sg=0,                               # 학습 알고리즘 선택 (0=CBOW, 1=Skip-gram)\n",
    "    window=5,                           # 주변 단어 수 (앞뒤로 n개)\n",
    "    min_count=5                         # 최소 빈도 (빈도 n개 미만은 제거)\n",
    ")\n",
    "\n",
    "# wv = wordVectors\n",
    "model.wv.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>0.027698</td>\n",
       "      <td>-0.040998</td>\n",
       "      <td>0.158571</td>\n",
       "      <td>-0.470428</td>\n",
       "      <td>-0.263714</td>\n",
       "      <td>-1.256787</td>\n",
       "      <td>0.121505</td>\n",
       "      <td>0.704592</td>\n",
       "      <td>-2.485870</td>\n",
       "      <td>-0.654399</td>\n",
       "      <td>...</td>\n",
       "      <td>0.872553</td>\n",
       "      <td>-0.092913</td>\n",
       "      <td>-0.329300</td>\n",
       "      <td>0.157683</td>\n",
       "      <td>0.477647</td>\n",
       "      <td>-2.049717</td>\n",
       "      <td>-0.479907</td>\n",
       "      <td>-0.562799</td>\n",
       "      <td>0.759411</td>\n",
       "      <td>1.016732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>people</th>\n",
       "      <td>-1.022522</td>\n",
       "      <td>-0.078259</td>\n",
       "      <td>0.770004</td>\n",
       "      <td>0.171636</td>\n",
       "      <td>-0.395702</td>\n",
       "      <td>-1.017727</td>\n",
       "      <td>-0.611419</td>\n",
       "      <td>0.840051</td>\n",
       "      <td>-1.823142</td>\n",
       "      <td>-1.775905</td>\n",
       "      <td>...</td>\n",
       "      <td>1.883874</td>\n",
       "      <td>0.505658</td>\n",
       "      <td>-1.191180</td>\n",
       "      <td>-0.094750</td>\n",
       "      <td>-0.187881</td>\n",
       "      <td>-0.461384</td>\n",
       "      <td>-0.655260</td>\n",
       "      <td>-0.315043</td>\n",
       "      <td>-2.428902</td>\n",
       "      <td>1.089525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>-0.916031</td>\n",
       "      <td>-0.575384</td>\n",
       "      <td>-1.049485</td>\n",
       "      <td>-2.131569</td>\n",
       "      <td>-0.609538</td>\n",
       "      <td>-0.501790</td>\n",
       "      <td>0.232423</td>\n",
       "      <td>0.568657</td>\n",
       "      <td>-1.754133</td>\n",
       "      <td>1.305051</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.252220</td>\n",
       "      <td>1.026599</td>\n",
       "      <td>0.267711</td>\n",
       "      <td>-0.096123</td>\n",
       "      <td>0.027727</td>\n",
       "      <td>1.151274</td>\n",
       "      <td>0.502011</td>\n",
       "      <td>0.107587</td>\n",
       "      <td>0.972407</td>\n",
       "      <td>-0.480801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>know</th>\n",
       "      <td>-1.230780</td>\n",
       "      <td>-0.982156</td>\n",
       "      <td>-0.222020</td>\n",
       "      <td>-0.431599</td>\n",
       "      <td>0.205042</td>\n",
       "      <td>0.466354</td>\n",
       "      <td>-0.200373</td>\n",
       "      <td>0.861611</td>\n",
       "      <td>-1.018153</td>\n",
       "      <td>-0.525709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.282478</td>\n",
       "      <td>0.334002</td>\n",
       "      <td>-0.164213</td>\n",
       "      <td>-0.101115</td>\n",
       "      <td>-0.011006</td>\n",
       "      <td>0.422575</td>\n",
       "      <td>0.360514</td>\n",
       "      <td>-0.422611</td>\n",
       "      <td>0.778930</td>\n",
       "      <td>0.046559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>going</th>\n",
       "      <td>-0.748081</td>\n",
       "      <td>0.365348</td>\n",
       "      <td>-0.992013</td>\n",
       "      <td>-0.395927</td>\n",
       "      <td>1.764353</td>\n",
       "      <td>0.497214</td>\n",
       "      <td>-0.220614</td>\n",
       "      <td>0.749055</td>\n",
       "      <td>-0.976055</td>\n",
       "      <td>-0.922865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.834435</td>\n",
       "      <td>-1.254717</td>\n",
       "      <td>0.344368</td>\n",
       "      <td>1.647566</td>\n",
       "      <td>0.311536</td>\n",
       "      <td>-1.058268</td>\n",
       "      <td>0.609624</td>\n",
       "      <td>-0.012224</td>\n",
       "      <td>-1.093170</td>\n",
       "      <td>0.695677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>think</th>\n",
       "      <td>-0.944074</td>\n",
       "      <td>-0.224553</td>\n",
       "      <td>1.127822</td>\n",
       "      <td>-0.703410</td>\n",
       "      <td>-0.045512</td>\n",
       "      <td>-0.785713</td>\n",
       "      <td>0.243878</td>\n",
       "      <td>0.093000</td>\n",
       "      <td>-1.295057</td>\n",
       "      <td>-0.723070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.906260</td>\n",
       "      <td>1.368871</td>\n",
       "      <td>-0.748709</td>\n",
       "      <td>0.997247</td>\n",
       "      <td>0.491360</td>\n",
       "      <td>-0.213437</td>\n",
       "      <td>0.266885</td>\n",
       "      <td>-0.905242</td>\n",
       "      <td>0.018078</td>\n",
       "      <td>-0.039231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>see</th>\n",
       "      <td>0.202748</td>\n",
       "      <td>0.206692</td>\n",
       "      <td>0.522867</td>\n",
       "      <td>-1.143844</td>\n",
       "      <td>-0.094198</td>\n",
       "      <td>-1.149259</td>\n",
       "      <td>-0.371186</td>\n",
       "      <td>0.633747</td>\n",
       "      <td>-1.962483</td>\n",
       "      <td>0.284893</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.216656</td>\n",
       "      <td>0.994439</td>\n",
       "      <td>0.755237</td>\n",
       "      <td>0.106046</td>\n",
       "      <td>-0.206298</td>\n",
       "      <td>0.682962</td>\n",
       "      <td>1.245177</td>\n",
       "      <td>-0.881771</td>\n",
       "      <td>0.783663</td>\n",
       "      <td>0.230833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>would</th>\n",
       "      <td>0.234937</td>\n",
       "      <td>-0.924556</td>\n",
       "      <td>0.900902</td>\n",
       "      <td>-0.925465</td>\n",
       "      <td>1.211878</td>\n",
       "      <td>0.225494</td>\n",
       "      <td>-0.243454</td>\n",
       "      <td>-0.334157</td>\n",
       "      <td>-0.547872</td>\n",
       "      <td>-0.492267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032763</td>\n",
       "      <td>-1.060649</td>\n",
       "      <td>-0.220926</td>\n",
       "      <td>1.374680</td>\n",
       "      <td>-0.720384</td>\n",
       "      <td>0.955177</td>\n",
       "      <td>-0.118896</td>\n",
       "      <td>-0.247413</td>\n",
       "      <td>-0.985856</td>\n",
       "      <td>-1.053836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>really</th>\n",
       "      <td>-1.753632</td>\n",
       "      <td>-0.131246</td>\n",
       "      <td>0.620951</td>\n",
       "      <td>-0.217828</td>\n",
       "      <td>0.426406</td>\n",
       "      <td>0.337676</td>\n",
       "      <td>0.709356</td>\n",
       "      <td>1.437779</td>\n",
       "      <td>-0.833241</td>\n",
       "      <td>-0.438447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.984802</td>\n",
       "      <td>0.119845</td>\n",
       "      <td>-0.140858</td>\n",
       "      <td>0.034552</td>\n",
       "      <td>0.964083</td>\n",
       "      <td>-0.073360</td>\n",
       "      <td>-0.027472</td>\n",
       "      <td>-0.906347</td>\n",
       "      <td>-0.216509</td>\n",
       "      <td>0.453587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get</th>\n",
       "      <td>-1.643041</td>\n",
       "      <td>-1.224293</td>\n",
       "      <td>-0.287421</td>\n",
       "      <td>-1.468470</td>\n",
       "      <td>-0.180019</td>\n",
       "      <td>-0.628351</td>\n",
       "      <td>-0.985874</td>\n",
       "      <td>0.532520</td>\n",
       "      <td>-0.251555</td>\n",
       "      <td>-2.153717</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.692948</td>\n",
       "      <td>-0.093241</td>\n",
       "      <td>-0.466871</td>\n",
       "      <td>0.239595</td>\n",
       "      <td>0.696418</td>\n",
       "      <td>-0.147861</td>\n",
       "      <td>0.415199</td>\n",
       "      <td>0.632127</td>\n",
       "      <td>-1.343451</td>\n",
       "      <td>0.669760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6   \\\n",
       "one     0.027698 -0.040998  0.158571 -0.470428 -0.263714 -1.256787  0.121505   \n",
       "people -1.022522 -0.078259  0.770004  0.171636 -0.395702 -1.017727 -0.611419   \n",
       "like   -0.916031 -0.575384 -1.049485 -2.131569 -0.609538 -0.501790  0.232423   \n",
       "know   -1.230780 -0.982156 -0.222020 -0.431599  0.205042  0.466354 -0.200373   \n",
       "going  -0.748081  0.365348 -0.992013 -0.395927  1.764353  0.497214 -0.220614   \n",
       "think  -0.944074 -0.224553  1.127822 -0.703410 -0.045512 -0.785713  0.243878   \n",
       "see     0.202748  0.206692  0.522867 -1.143844 -0.094198 -1.149259 -0.371186   \n",
       "would   0.234937 -0.924556  0.900902 -0.925465  1.211878  0.225494 -0.243454   \n",
       "really -1.753632 -0.131246  0.620951 -0.217828  0.426406  0.337676  0.709356   \n",
       "get    -1.643041 -1.224293 -0.287421 -1.468470 -0.180019 -0.628351 -0.985874   \n",
       "\n",
       "              7         8         9   ...        90        91        92  \\\n",
       "one     0.704592 -2.485870 -0.654399  ...  0.872553 -0.092913 -0.329300   \n",
       "people  0.840051 -1.823142 -1.775905  ...  1.883874  0.505658 -1.191180   \n",
       "like    0.568657 -1.754133  1.305051  ... -0.252220  1.026599  0.267711   \n",
       "know    0.861611 -1.018153 -0.525709  ...  0.282478  0.334002 -0.164213   \n",
       "going   0.749055 -0.976055 -0.922865  ...  0.834435 -1.254717  0.344368   \n",
       "think   0.093000 -1.295057 -0.723070  ...  0.906260  1.368871 -0.748709   \n",
       "see     0.633747 -1.962483  0.284893  ... -0.216656  0.994439  0.755237   \n",
       "would  -0.334157 -0.547872 -0.492267  ...  0.032763 -1.060649 -0.220926   \n",
       "really  1.437779 -0.833241 -0.438447  ...  0.984802  0.119845 -0.140858   \n",
       "get     0.532520 -0.251555 -2.153717  ... -0.692948 -0.093241 -0.466871   \n",
       "\n",
       "              93        94        95        96        97        98        99  \n",
       "one     0.157683  0.477647 -2.049717 -0.479907 -0.562799  0.759411  1.016732  \n",
       "people -0.094750 -0.187881 -0.461384 -0.655260 -0.315043 -2.428902  1.089525  \n",
       "like   -0.096123  0.027727  1.151274  0.502011  0.107587  0.972407 -0.480801  \n",
       "know   -0.101115 -0.011006  0.422575  0.360514 -0.422611  0.778930  0.046559  \n",
       "going   1.647566  0.311536 -1.058268  0.609624 -0.012224 -1.093170  0.695677  \n",
       "think   0.997247  0.491360 -0.213437  0.266885 -0.905242  0.018078 -0.039231  \n",
       "see     0.106046 -0.206298  0.682962  1.245177 -0.881771  0.783663  0.230833  \n",
       "would   1.374680 -0.720384  0.955177 -0.118896 -0.247413 -0.985856 -1.053836  \n",
       "really  0.034552  0.964083 -0.073360 -0.027472 -0.906347 -0.216509  0.453587  \n",
       "get     0.239595  0.696418 -0.147861  0.415199  0.632127 -1.343451  0.669760  \n",
       "\n",
       "[10 rows x 100 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(model.wv.vectors, index=model.wv.index_to_key).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 임베딩 모델 저장\n",
    "model.wv.save_word2vec_format('ted_en_w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "load_model = KeyedVectors.load_word2vec_format('ted_en_w2v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 유사도 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('woman', 0.9098701477050781),\n",
       " ('daughter', 0.8022341728210449),\n",
       " ('girl', 0.802148699760437),\n",
       " ('son', 0.7825210094451904),\n",
       " ('lady', 0.7789952158927917),\n",
       " ('father', 0.7750177979469299),\n",
       " ('grandfather', 0.772922694683075),\n",
       " ('sister', 0.7586817145347595),\n",
       " ('boy', 0.756505012512207),\n",
       " ('mother', 0.7526086568832397)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('man')\n",
    "#model.most_similar('abracadabra')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.6428944e-01, -5.2279371e-01,  4.5172414e-01,  1.9783969e+00,\n",
       "       -9.0508059e-02, -2.4471526e-01, -3.6044118e-01,  1.9186311e+00,\n",
       "       -6.0436565e-01, -4.2431065e-01, -4.1613805e-01,  2.1701942e-01,\n",
       "       -5.7081386e-02,  9.2797679e-01,  1.2785417e+00, -4.8099005e-01,\n",
       "        6.6846836e-01,  8.6558700e-02, -8.9863938e-01, -6.8079168e-01,\n",
       "        5.6410545e-01,  5.8704174e-01,  1.4090481e-01, -3.0355647e-01,\n",
       "        6.3626438e-01, -4.5757435e-02, -1.1257330e+00, -7.5859845e-01,\n",
       "        1.4859024e-01,  5.2016544e-01, -1.0515171e+00, -1.2073495e+00,\n",
       "       -1.6166815e-01, -1.0051460e+00, -5.7580286e-01,  1.6995008e+00,\n",
       "       -8.1218505e-01, -4.3135694e-01,  9.4421721e-01, -6.7667913e-01,\n",
       "        1.3073893e+00,  1.4663270e-01, -5.4744165e-02,  2.1431743e-01,\n",
       "        2.0057597e+00,  2.9436633e-01, -5.6715423e-01,  3.3403787e-01,\n",
       "        7.4531919e-01,  7.6524942e-04,  8.7607872e-01,  1.6070992e-01,\n",
       "       -5.1491004e-01, -3.1327149e-01,  3.7839991e-01,  5.3718954e-01,\n",
       "        1.6917340e-01,  6.8909913e-01,  3.5852638e-01, -8.3700067e-01,\n",
       "       -3.3849514e-01, -1.4806976e+00, -1.4350376e+00,  6.9250154e-01,\n",
       "       -9.7534162e-01,  6.5228485e-02, -6.5445030e-01,  2.5956470e-01,\n",
       "        1.3582678e+00,  9.2453098e-01, -7.1051711e-01, -6.4359421e-01,\n",
       "        2.9230994e-01, -4.4961578e-01, -2.3176532e-02,  5.1392961e-01,\n",
       "        7.5784065e-02,  3.8808739e-01,  6.0327810e-01, -3.7082054e-02,\n",
       "       -7.1221834e-01,  9.4868886e-01, -1.1087964e+00,  1.1618192e+00,\n",
       "        2.1688804e-02, -6.3541526e-01, -1.6754693e-01, -2.4912202e-01,\n",
       "        4.3082860e-01,  6.3630068e-01,  5.8126700e-01,  7.6566599e-02,\n",
       "       -3.8539252e-01, -1.8779699e+00, -1.9072628e-01,  3.5731959e-01,\n",
       "        7.2388983e-01, -1.8008998e-02,  2.5030181e-01, -1.1329362e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.similarity('man', 'husband')\n",
    "model.wv['man']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('woman', 0.6602159142494202),\n",
       " ('son', 0.5976096391677856),\n",
       " ('father', 0.5930886268615723),\n",
       " ('lady', 0.5888569355010986),\n",
       " ('daughter', 0.5769045948982239),\n",
       " ('di', 0.5628340840339661),\n",
       " ('sister', 0.5516031384468079),\n",
       " ('girl', 0.5451541543006897),\n",
       " ('mother', 0.541283130645752),\n",
       " ('boy', 0.5392701625823975)]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model.most_similar('man')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 임베딩 시각화\n",
    "\n",
    "https://projector.tensorflow.org/\n",
    "\n",
    "- embedding vector(tensor) 파일 (.tsv)\n",
    "- metadata 파일 (.tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/python3: Error while finding module specification for 'gensim.scripts.word2vec2tensor' (ModuleNotFoundError: No module named 'gensim')\n"
     ]
    }
   ],
   "source": [
    "!python3 -m gensim.scripts.word2vec2tensor --input ted_en_w2v --output ted_en_w2v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 한국어 Word Embedding\n",
    "- NSMC (Naver Sentiment Movie Corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('naver_movie_ratings.txt', <http.client.HTTPMessage at 0x1436f9840>)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\n",
    "    \"https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt\",\n",
    "    filename='naver_movie_ratings.txt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 프레임 생성\n",
    "ratings_df = pd.read_csv('naver_movie_ratings.txt',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "document    8\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 결측치 확인 및 처리 (제거)\n",
    "display(ratings_df.isnull().sum())\n",
    "\n",
    "ratings_df = ratings_df.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글이 아닌 데이터 제거\n",
    "ratings_df['document'] = ratings_df['document'].replace(r'[^0-9가-힣ㄱ-ㅎㅏ-ㅣ]', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 199992/199992 [14:09<00:00, 235.38it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "okt = Okt()\n",
    "ko_stopwords = ['은', '는', '이', '가', '을', '를', '와', '과', '들', '도', '에','게', '부터', '까지', '나', '너', '그', '걔', '얘']\n",
    "\n",
    "preprocessed_data = []\n",
    "\n",
    "for sentence in tqdm(ratings_df['document']):\n",
    "    tokens = okt.morphs(sentence, stem=True)\n",
    "    tokens = [token for token in tokens if token not in ko_stopwords]\n",
    "    preprocessed_data.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17614, 100)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Word2Vec(\n",
    "    sentences=preprocessed_data,\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=5,\n",
    "    sg=0\n",
    ")\n",
    "\n",
    "model.wv.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7897541"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('김혜수','유해진')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "model.wv.save_word2vec_format('naver_movie_ratings_w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/python3: Error while finding module specification for 'gensim.scripts.word2vec2tensor' (ModuleNotFoundError: No module named 'gensim')\n"
     ]
    }
   ],
   "source": [
    "!python3 -m gensim.scripts.word2vec2tensor --input naver_movie_ratings_w2v --output naver_movie_ratings_w2v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사전 훈련된 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=11MWLNUBLOJWpJePTbOJwCtcgEryPGKGj\n",
      "From (redirected): https://drive.google.com/uc?id=11MWLNUBLOJWpJePTbOJwCtcgEryPGKGj&confirm=t&uuid=b84c8aa6-7fce-44e0-a31d-265b1c887846\n",
      "To: /Users/isejin/Desktop/세진 폴더/SKN_Family_project/nlp/03_word_embedding/Googlenews_vecs.bin.gz\n",
      "100%|██████████| 1.65G/1.65G [07:36<00:00, 3.61MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Googlenews_vecs.bin.gz'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://drive.google.com/uc?id=11MWLNUBLOJWpJePTbOJwCtcgEryPGKGj'\n",
    "output = 'Googlenews_vecs.bin.gz'\n",
    "\n",
    "gdown.download(url, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000000, 300)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_news_wv = KeyedVectors.load_word2vec_format('Googlenews_vecs.bin.gz', binary=True)\n",
    "google_news_wv.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22942673"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_news_wv.similarity('king', 'man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kings', 0.7138045430183411),\n",
       " ('queen', 0.6510956883430481),\n",
       " ('monarch', 0.6413194537162781),\n",
       " ('crown_prince', 0.6204220056533813),\n",
       " ('prince', 0.6159993410110474),\n",
       " ('sultan', 0.5864824056625366),\n",
       " ('ruler', 0.5797567367553711),\n",
       " ('princes', 0.5646552443504333),\n",
       " ('Prince_Paras', 0.5432944297790527),\n",
       " ('throne', 0.5422105193138123)]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_news_wv.most_similar('king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24791393"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_news_wv.n_similarity(['king', 'queen'], ['man', 'woman'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kings', 0.7138045430183411),\n",
       " ('queen', 0.6510956883430481),\n",
       " ('monarch', 0.6413194537162781),\n",
       " ('crown_prince', 0.6204220056533813),\n",
       " ('prince', 0.6159993410110474)]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_news_wv.similar_by_word('king', topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_news_wv.has_index_for('ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
